{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, csv\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import pickle\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import xlsxwriter\n",
    "import random\n",
    "from random import shuffle\n",
    "from math import log, floor\n",
    "import re\n",
    "import collections\n",
    "from collections import Counter\n",
    "import string\n",
    "import unicodedata as udata\n",
    "# import pause, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from distutils.dir_util import copy_tree\n",
    "import sklearn\n",
    "from sklearn.metrics import *\n",
    "import itertools as it\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "import functools\n",
    "import spacy\n",
    "import swifter\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "import tensorflow.keras.preprocessing.text as T\n",
    "import torch\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>preprocess_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19313</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Kovalev is too talented a player to play for R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19312</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>First of all the Penguins WILL win the cup aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19115</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>You ca n't But good luck trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19224</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>As the subject suggests the Flames were not im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19299</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Well I got ta tell ya last night 's Leafs game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10548</td>\n",
       "      <td>20797</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>When the object of their belief is said to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10549</td>\n",
       "      <td>20537</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Koff You mean that as long as I put you to sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10550</td>\n",
       "      <td>20757</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Mr Connor 's assertion that more complex later...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10551</td>\n",
       "      <td>20677</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>excess stuff deleted I know of a similar incid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10552</td>\n",
       "      <td>20719</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>The System refered to a moral system You shown...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10553 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          category  \\\n",
       "0      19313  rec.sport.hockey   \n",
       "1      19312  rec.sport.hockey   \n",
       "2      19115  rec.sport.hockey   \n",
       "3      19224  rec.sport.hockey   \n",
       "4      19299  rec.sport.hockey   \n",
       "...      ...               ...   \n",
       "10548  20797       alt.atheism   \n",
       "10549  20537       alt.atheism   \n",
       "10550  20757       alt.atheism   \n",
       "10551  20677       alt.atheism   \n",
       "10552  20719       alt.atheism   \n",
       "\n",
       "                                         preprocess_text  \n",
       "0      Kovalev is too talented a player to play for R...  \n",
       "1      First of all the Penguins WILL win the cup aga...  \n",
       "2                        You ca n't But good luck trying  \n",
       "3      As the subject suggests the Flames were not im...  \n",
       "4      Well I got ta tell ya last night 's Leafs game...  \n",
       "...                                                  ...  \n",
       "10548  When the object of their belief is said to be ...  \n",
       "10549  Koff You mean that as long as I put you to sle...  \n",
       "10550  Mr Connor 's assertion that more complex later...  \n",
       "10551  excess stuff deleted I know of a similar incid...  \n",
       "10552  The System refered to a moral system You shown...  \n",
       "\n",
       "[10553 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/20news-bydate-v3/training_df.csv',index_col=False)\n",
    "train_df = train_df.drop(['Unnamed: 0'],axis=1)\n",
    "valid_df = pd.read_csv('./data/20news-bydate-v3/validation_df.csv',index_col=False)\n",
    "valid_df = valid_df.drop(['Unnamed: 0'],axis=1)\n",
    "test_df = pd.read_csv('./data/20news-bydate-v3/test_df.csv',index_col=False)\n",
    "test_df = test_df.drop(['Unnamed: 0'],axis=1)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "category encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'talk.politics.misc': 0,\n",
       " 'talk.politics.mideast': 1,\n",
       " 'comp.sys.ibm.pc.hardware': 2,\n",
       " 'rec.sport.baseball': 3,\n",
       " 'sci.crypt': 4,\n",
       " 'rec.autos': 5,\n",
       " 'sci.med': 6,\n",
       " 'comp.windows.x': 7,\n",
       " 'sci.electronics': 8,\n",
       " 'soc.religion.christian': 9,\n",
       " 'rec.motorcycles': 10,\n",
       " 'talk.politics.guns': 11,\n",
       " 'comp.os.ms-windows.misc': 12,\n",
       " 'alt.atheism': 13,\n",
       " 'talk.religion.misc': 14,\n",
       " 'comp.graphics': 15,\n",
       " 'misc.forsale': 16,\n",
       " 'comp.sys.mac.hardware': 17,\n",
       " 'rec.sport.hockey': 18,\n",
       " 'sci.space': 19}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = set(train_df.category.tolist())\n",
    "print(len(categories))\n",
    "cat_encode = {}\n",
    "for i,cat in enumerate(categories):\n",
    "    cat_encode[cat] = i\n",
    "pickle.dump(obj=cat_encode,file=open('./data/20news-bydate-v3/cat_encode_dict.pkl','wb'))\n",
    "cat_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cat(serie):\n",
    "    '''\n",
    "    trainY轉換為ID: 0~19 (20類)\n",
    "    '''\n",
    "    return cat_encode[serie]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>preprocess_text</th>\n",
       "      <th>cat_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19313</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Kovalev is too talented a player to play for R...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19312</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>First of all the Penguins WILL win the cup aga...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19115</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>You ca n't But good luck trying</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19224</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>As the subject suggests the Flames were not im...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19299</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Well I got ta tell ya last night 's Leafs game...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10548</td>\n",
       "      <td>20797</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>When the object of their belief is said to be ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10549</td>\n",
       "      <td>20537</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Koff You mean that as long as I put you to sle...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10550</td>\n",
       "      <td>20757</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Mr Connor 's assertion that more complex later...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10551</td>\n",
       "      <td>20677</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>excess stuff deleted I know of a similar incid...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10552</td>\n",
       "      <td>20719</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>The System refered to a moral system You shown...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10553 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          category  \\\n",
       "0      19313  rec.sport.hockey   \n",
       "1      19312  rec.sport.hockey   \n",
       "2      19115  rec.sport.hockey   \n",
       "3      19224  rec.sport.hockey   \n",
       "4      19299  rec.sport.hockey   \n",
       "...      ...               ...   \n",
       "10548  20797       alt.atheism   \n",
       "10549  20537       alt.atheism   \n",
       "10550  20757       alt.atheism   \n",
       "10551  20677       alt.atheism   \n",
       "10552  20719       alt.atheism   \n",
       "\n",
       "                                         preprocess_text  cat_id  \n",
       "0      Kovalev is too talented a player to play for R...      18  \n",
       "1      First of all the Penguins WILL win the cup aga...      18  \n",
       "2                        You ca n't But good luck trying      18  \n",
       "3      As the subject suggests the Flames were not im...      18  \n",
       "4      Well I got ta tell ya last night 's Leafs game...      18  \n",
       "...                                                  ...     ...  \n",
       "10548  When the object of their belief is said to be ...      13  \n",
       "10549  Koff You mean that as long as I put you to sle...      13  \n",
       "10550  Mr Connor 's assertion that more complex later...      13  \n",
       "10551  excess stuff deleted I know of a similar incid...      13  \n",
       "10552  The System refered to a moral system You shown...      13  \n",
       "\n",
       "[10553 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['cat_id'] = train_df.category.apply(convert_cat)\n",
    "valid_df['cat_id'] = valid_df.category.apply(convert_cat)\n",
    "test_df['cat_id'] = test_df.category.apply(convert_cat)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/leoqaz12/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz from cache at /home/leoqaz12/.cache/torch/pytorch_fairseq/83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2\n",
      "| dictionary: 50264 types\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (decoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerSentenceEncoder(\n",
       "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (12): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (15): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (16): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (17): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (18): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (19): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (20): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (21): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (22): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (23): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (emb_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\n",
    "roberta.cuda() #gpu\n",
    "# roberta.cpu()\n",
    "roberta.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_text(preprocess_text,max_length=481):\n",
    "    '''\n",
    "    利用RoBERTa tokenizer轉換 (太耗記憶體)\n",
    "    '''\n",
    "    roberta_pad = [0]*1024\n",
    "    doc = roberta.extract_features_aligned_to_words(preprocess_text)\n",
    "    roberta_emb = []\n",
    "    tokens_li = []\n",
    "    for tok in doc:\n",
    "        roberta_emb.append(tok.vector)\n",
    "        tokens_li.append(str(tok))\n",
    "    if len(roberta_emb)<max_length:\n",
    "        for _ in range(max_length-len(roberta_emb)):\n",
    "            roberta_emb.append(roberta_pad)\n",
    "    return np.array(roberta_emb) , tokens_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kovalev is too talented a player to play for Roger needs players who ca n't think for themselves and can only skate in straight lines up and down the ice Dudley and Nielson are the only two coaches bad enough in the league to take talents like Mogilny and Kovalev and not know how to turn them into Bure and Selanne Get Muckler as coach and Kovalev will look like Mogilny The trouble with the Rangers is that Neil Smith went out and got players like Messier Kovalev and Graves who have been schooled in taking the game to their opponent and attacking while hiring coaches who are interested in ropeadope strategies If you want the Roger Nielsons of the world to be your coach you do n't go out and get a Mark Messier who is an old dog who ca n't learn new tricks from a known loser and you do n't waste your draft picks on players like Kovalev Gerald\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>preprocess_text</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>roberta_emb</th>\n",
       "      <th>roberta_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19313</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Kovalev is too talented a player to play for R...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19312</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>First of all the Penguins WILL win the cup aga...</td>\n",
       "      <td>18</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19115</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>You ca n't But good luck trying</td>\n",
       "      <td>18</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19224</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>As the subject suggests the Flames were not im...</td>\n",
       "      <td>18</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19299</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Well I got ta tell ya last night 's Leafs game...</td>\n",
       "      <td>18</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10548</td>\n",
       "      <td>20797</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>When the object of their belief is said to be ...</td>\n",
       "      <td>13</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10549</td>\n",
       "      <td>20537</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Koff You mean that as long as I put you to sle...</td>\n",
       "      <td>13</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10550</td>\n",
       "      <td>20757</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Mr Connor 's assertion that more complex later...</td>\n",
       "      <td>13</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10551</td>\n",
       "      <td>20677</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>excess stuff deleted I know of a similar incid...</td>\n",
       "      <td>13</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10552</td>\n",
       "      <td>20719</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>The System refered to a moral system You shown...</td>\n",
       "      <td>13</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10553 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          category  \\\n",
       "0      19313  rec.sport.hockey   \n",
       "1      19312  rec.sport.hockey   \n",
       "2      19115  rec.sport.hockey   \n",
       "3      19224  rec.sport.hockey   \n",
       "4      19299  rec.sport.hockey   \n",
       "...      ...               ...   \n",
       "10548  20797       alt.atheism   \n",
       "10549  20537       alt.atheism   \n",
       "10550  20757       alt.atheism   \n",
       "10551  20677       alt.atheism   \n",
       "10552  20719       alt.atheism   \n",
       "\n",
       "                                         preprocess_text  cat_id roberta_emb  \\\n",
       "0      Kovalev is too talented a player to play for R...      18           1   \n",
       "1      First of all the Penguins WILL win the cup aga...      18         NAN   \n",
       "2                        You ca n't But good luck trying      18         NAN   \n",
       "3      As the subject suggests the Flames were not im...      18         NAN   \n",
       "4      Well I got ta tell ya last night 's Leafs game...      18         NAN   \n",
       "...                                                  ...     ...         ...   \n",
       "10548  When the object of their belief is said to be ...      13         NAN   \n",
       "10549  Koff You mean that as long as I put you to sle...      13         NAN   \n",
       "10550  Mr Connor 's assertion that more complex later...      13         NAN   \n",
       "10551  excess stuff deleted I know of a similar incid...      13         NAN   \n",
       "10552  The System refered to a moral system You shown...      13         NAN   \n",
       "\n",
       "       roberta_tok  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "10548            0  \n",
       "10549            0  \n",
       "10550            0  \n",
       "10551            0  \n",
       "10552            0  \n",
       "\n",
       "[10553 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['roberta_emb'] = 'NAN'\n",
    "train_df['roberta_tok'] = 0\n",
    "train_df.loc[0,'roberta_emb']=1\n",
    "preprcoess_text_li = train_df.preprocess_text.tolist()\n",
    "print(preprcoess_text_li[0])\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6091it [07:00, 15.05it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprcoess_text_li = train_df.preprocess_text.tolist()\n",
    "roberta_pad = [0]*1024\n",
    "max_length = 498 #改\n",
    "train_df['roberta_emb'] = 0\n",
    "train_df['roberta_tok'] = 0\n",
    "# train_df['glove_emb'] = 0\n",
    "\n",
    "train_df=train_df.astype(object)\n",
    "# glove = pd.read_table('./data/preprocess/glove.840B.300d.txt', sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n",
    "# def glove_convert(tok_li):\n",
    "#     '''\n",
    "#     Deprecated\n",
    "#     Input: list of tokens by RoBERTa\n",
    "#     Return: np array of max_length*300dim\n",
    "#     '''\n",
    "#     max_length = 498 #改\n",
    "#     glove_pad = [0]*300\n",
    "#     glove_emb = []\n",
    "#     for token in tok_li:\n",
    "#         glove_emb.append(glove.loc[token].values)\n",
    "#     if len(glove_emb)<max_length:\n",
    "#         for _ in range(max_length-len(glove_emb)):\n",
    "#             glove_emb.append(glove_pad)\n",
    "#     try:\n",
    "#         assert len(glove_emb) == max_length\n",
    "#     except:\n",
    "#         print(\"maxlength ERR(now,ori):\",len(glove_emb) , max_length)\n",
    "#     return np.array(glove_emb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,text in tqdm(enumerate(preprcoess_text_li)):\n",
    "    doc = roberta.extract_features_aligned_to_words(text)\n",
    "    roberta_emb = []\n",
    "    tokens_li = []\n",
    "    for tok in doc:\n",
    "        roberta_emb.append(tok.vector.cpu().data.numpy())\n",
    "        tokens_li.append(str(tok))\n",
    "    try:        \n",
    "        assert len(tokens_li) == len(roberta_emb)\n",
    "    except:\n",
    "        print('AsserionERR: ',len(tokens_li), len(roberta_emb))\n",
    "    if len(roberta_emb)<max_length:\n",
    "        for _ in range(max_length-len(roberta_emb)):\n",
    "            roberta_emb.append(roberta_pad)\n",
    "    train_df.loc[i,'roberta_emb'] = np.array(roberta_emb)\n",
    "    train_df.loc[i,'roberta_tok'] = tokens_li\n",
    "#     train_df.loc[i,'glove_emb'] = glove_convert(tokens_li) #法1\n",
    "    try:\n",
    "        assert len(np.array(roberta_emb)) == (max_length)\n",
    "    except:\n",
    "        print('max length err(now max length,set max length):',len(np.array(roberta_emb)),(max_length))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding layer init matrix\n",
    "* initial weight\n",
    "* tokens #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_index = {}\n",
    "# f = open('./data/preprocess/glove.840B.300d.txt','r')\n",
    "# for line in f:\n",
    "#     values = line.split()\n",
    "#     word = values[0]\n",
    "#     coefs = np.asarray(values[1:], dtype='float32')\n",
    "#     embeddings_index[word] = coefs\n",
    "# f.close()\n",
    "\n",
    "# print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "glove = pd.read_table('./data/preprocess/glove.840B.300d.txt', sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n",
    "glove.index = glove.index.astype('str')\n",
    "glove_words = glove.index.tolist()\n",
    "print('all_iters#:',len(glove_words))\n",
    "glove_index = {}\n",
    "embedding_matrix = np.zeros((len(glove_words) + 1, 300))\n",
    "\n",
    "\n",
    "for i,word in tqdm(enumerate(glove_words)):\n",
    "    glove_index[word] = i+1\n",
    "    try:\n",
    "        embedding_matrix[i+1] = glove.loc[str(word)].values\n",
    "    except KeyError:\n",
    "        continue\n",
    "    except ValueError:\n",
    "        embedding_matrix[i+1] = glove.loc[str(word)].values[0]\n",
    "\n",
    "\n",
    "pickle.dump(obj=glove_index,file=open('./data/20news-bydate-v3/glove_index.pkl','wb'))\n",
    "pickle.dump(obj=embedding_matrix,file=open('./data/20news-bydate-v3/embedding_matrix.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.7/site-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52251dbfa56d4935960b065296e9e70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=10553, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>preprocess_text</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>roberta_emb</th>\n",
       "      <th>roberta_tok</th>\n",
       "      <th>glove_emb</th>\n",
       "      <th>glove_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19313</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Kovalev is too talented a player to play for R...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.1072988361120224, 0.006329931318759918, -...</td>\n",
       "      <td>[&lt;s&gt;, Kovalev, is, too, talented, a, player, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[566229, 119013, 11, 188, 5061, 7, 983, 5, 331...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19312</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>First of all the Penguins WILL win the cup aga...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.0944674089550972, 0.004107087850570679, -...</td>\n",
       "      <td>[&lt;s&gt;, First, of, all, the, Penguins, WILL, win...</td>\n",
       "      <td>0</td>\n",
       "      <td>[566229, 586, 6, 44, 3, 18799, 5777, 814, 3, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19115</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>You ca n't But good luck trying</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.05532881245017052, 0.02691790461540222, 0...</td>\n",
       "      <td>[&lt;s&gt;, You, ca, n't, But, good, luck, trying, &lt;...</td>\n",
       "      <td>0</td>\n",
       "      <td>[566229, 94, 324, 41, 175, 113, 2455, 553, 437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19224</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>As the subject suggests the Flames were not im...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[0.004719207063317299, 0.036944739520549774, ...</td>\n",
       "      <td>[&lt;s&gt;, As, the, subject, suggests, the, Flames,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[566229, 223, 3, 918, 4650, 3, 20021, 88, 36, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19299</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Well I got ta tell ya last night 's Leafs game...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.0014236271381378174, 0.02442687749862671,...</td>\n",
       "      <td>[&lt;s&gt;, Well, I, got, ta, tell, ya, last, night,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[566229, 700, 13, 219, 19241, 515, 3619, 190, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10548</td>\n",
       "      <td>20797</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>When the object of their belief is said to be ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[0.06133417785167694, 0.10471037030220032, 0....</td>\n",
       "      <td>[&lt;s&gt;, When, the, object, of, their, belief, is...</td>\n",
       "      <td>0</td>\n",
       "      <td>[566229, 257, 3, 2356, 6, 59, 4728, 11, 108, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10549</td>\n",
       "      <td>20537</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Koff You mean that as long as I put you to sle...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[-0.04543164372444153, 0.006741240620613098, ...</td>\n",
       "      <td>[&lt;s&gt;, Koff, You, mean, that, as, long, as, I, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[566229, 304437, 94, 616, 16, 29, 229, 29, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10550</td>\n",
       "      <td>20757</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Mr Connor 's assertion that more complex later...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[-0.027814187109470367, 0.055848635733127594,...</td>\n",
       "      <td>[&lt;s&gt;, Mr, Connor, 's, assertion, that, more, c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[566229, 2558, 17914, 21, 18373, 16, 51, 1988,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10551</td>\n",
       "      <td>20677</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>excess stuff deleted I know of a similar incid...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[0.01678074523806572, 0.029153533279895782, 0...</td>\n",
       "      <td>[&lt;s&gt;, excess, stuff, deleted, I, know, of, a, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[566229, 5814, 809, 6562, 13, 114, 6, 7, 887, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10552</td>\n",
       "      <td>20719</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>The System refered to a moral system You shown...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[-0.018732327967882156, 0.05509016662836075, ...</td>\n",
       "      <td>[&lt;s&gt;, The, System, refered, to, a, moral, syst...</td>\n",
       "      <td>0</td>\n",
       "      <td>[566229, 23, 1140, 79272, 5, 7, 4964, 254, 94,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10553 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          category  \\\n",
       "0      19313  rec.sport.hockey   \n",
       "1      19312  rec.sport.hockey   \n",
       "2      19115  rec.sport.hockey   \n",
       "3      19224  rec.sport.hockey   \n",
       "4      19299  rec.sport.hockey   \n",
       "...      ...               ...   \n",
       "10548  20797       alt.atheism   \n",
       "10549  20537       alt.atheism   \n",
       "10550  20757       alt.atheism   \n",
       "10551  20677       alt.atheism   \n",
       "10552  20719       alt.atheism   \n",
       "\n",
       "                                         preprocess_text cat_id  \\\n",
       "0      Kovalev is too talented a player to play for R...     18   \n",
       "1      First of all the Penguins WILL win the cup aga...     18   \n",
       "2                        You ca n't But good luck trying     18   \n",
       "3      As the subject suggests the Flames were not im...     18   \n",
       "4      Well I got ta tell ya last night 's Leafs game...     18   \n",
       "...                                                  ...    ...   \n",
       "10548  When the object of their belief is said to be ...     13   \n",
       "10549  Koff You mean that as long as I put you to sle...     13   \n",
       "10550  Mr Connor 's assertion that more complex later...     13   \n",
       "10551  excess stuff deleted I know of a similar incid...     13   \n",
       "10552  The System refered to a moral system You shown...     13   \n",
       "\n",
       "                                             roberta_emb  \\\n",
       "0      [[-0.1072988361120224, 0.006329931318759918, -...   \n",
       "1      [[-0.0944674089550972, 0.004107087850570679, -...   \n",
       "2      [[-0.05532881245017052, 0.02691790461540222, 0...   \n",
       "3      [[0.004719207063317299, 0.036944739520549774, ...   \n",
       "4      [[-0.0014236271381378174, 0.02442687749862671,...   \n",
       "...                                                  ...   \n",
       "10548  [[0.06133417785167694, 0.10471037030220032, 0....   \n",
       "10549  [[-0.04543164372444153, 0.006741240620613098, ...   \n",
       "10550  [[-0.027814187109470367, 0.055848635733127594,...   \n",
       "10551  [[0.01678074523806572, 0.029153533279895782, 0...   \n",
       "10552  [[-0.018732327967882156, 0.05509016662836075, ...   \n",
       "\n",
       "                                             roberta_tok glove_emb  \\\n",
       "0      [<s>, Kovalev, is, too, talented, a, player, t...         0   \n",
       "1      [<s>, First, of, all, the, Penguins, WILL, win...         0   \n",
       "2      [<s>, You, ca, n't, But, good, luck, trying, <...         0   \n",
       "3      [<s>, As, the, subject, suggests, the, Flames,...         0   \n",
       "4      [<s>, Well, I, got, ta, tell, ya, last, night,...         0   \n",
       "...                                                  ...       ...   \n",
       "10548  [<s>, When, the, object, of, their, belief, is...         0   \n",
       "10549  [<s>, Koff, You, mean, that, as, long, as, I, ...         0   \n",
       "10550  [<s>, Mr, Connor, 's, assertion, that, more, c...         0   \n",
       "10551  [<s>, excess, stuff, deleted, I, know, of, a, ...         0   \n",
       "10552  [<s>, The, System, refered, to, a, moral, syst...         0   \n",
       "\n",
       "                                               glove_int  \n",
       "0      [566229, 119013, 11, 188, 5061, 7, 983, 5, 331...  \n",
       "1      [566229, 586, 6, 44, 3, 18799, 5777, 814, 3, 2...  \n",
       "2      [566229, 94, 324, 41, 175, 113, 2455, 553, 437...  \n",
       "3      [566229, 223, 3, 918, 4650, 3, 20021, 88, 36, ...  \n",
       "4      [566229, 700, 13, 219, 19241, 515, 3619, 190, ...  \n",
       "...                                                  ...  \n",
       "10548  [566229, 257, 3, 2356, 6, 59, 4728, 11, 108, 5...  \n",
       "10549  [566229, 304437, 94, 616, 16, 29, 229, 29, 13,...  \n",
       "10550  [566229, 2558, 17914, 21, 18373, 16, 51, 1988,...  \n",
       "10551  [566229, 5814, 809, 6562, 13, 114, 6, 7, 887, ...  \n",
       "10552  [566229, 23, 1140, 79272, 5, 7, 4964, 254, 94,...  \n",
       "\n",
       "[10553 rows x 8 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tok2int(tok_li):\n",
    "    '''\n",
    "    Input: tok_list\n",
    "    Return: int_list\n",
    "    '''\n",
    "    max_length = 498 #改\n",
    "    int_pad = 0\n",
    "    int_list = []\n",
    "    for tok in tok_li:\n",
    "        int_list.append(glove_index[str(tok)])\n",
    "    if len(int_list)<max_length:\n",
    "        for _ in range(max_length-len(tok_li)):\n",
    "            int_list.append(int_pad)\n",
    "    try:\n",
    "        assert len(int_list) == max_length\n",
    "    except:\n",
    "        print(\"maxlength ERR(now,ori):\",len(int_list) , max_length)            \n",
    "    return int_list\n",
    "\n",
    "train_df['glove_int'] = 0\n",
    "train_df=train_df.astype(object)\n",
    "train_df['glove_int'] = train_df['roberta_tok'].swifter.apply(tok2int)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>preprocess_text</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>roberta_emb</th>\n",
       "      <th>roberta_tok</th>\n",
       "      <th>glove_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19313</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Kovalev is too talented a player to play for R...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.1072988361120224, 0.006329931318759918, -...</td>\n",
       "      <td>[&lt;s&gt;, Kovalev, is, too, talented, a, player, t...</td>\n",
       "      <td>[566229, 119013, 11, 188, 5061, 7, 983, 5, 331...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19312</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>First of all the Penguins WILL win the cup aga...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.0944674089550972, 0.004107087850570679, -...</td>\n",
       "      <td>[&lt;s&gt;, First, of, all, the, Penguins, WILL, win...</td>\n",
       "      <td>[566229, 586, 6, 44, 3, 18799, 5777, 814, 3, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19115</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>You ca n't But good luck trying</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.05532881245017052, 0.02691790461540222, 0...</td>\n",
       "      <td>[&lt;s&gt;, You, ca, n't, But, good, luck, trying, &lt;...</td>\n",
       "      <td>[566229, 94, 324, 41, 175, 113, 2455, 553, 437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19224</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>As the subject suggests the Flames were not im...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[0.004719207063317299, 0.036944739520549774, ...</td>\n",
       "      <td>[&lt;s&gt;, As, the, subject, suggests, the, Flames,...</td>\n",
       "      <td>[566229, 223, 3, 918, 4650, 3, 20021, 88, 36, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19299</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Well I got ta tell ya last night 's Leafs game...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.0014236271381378174, 0.02442687749862671,...</td>\n",
       "      <td>[&lt;s&gt;, Well, I, got, ta, tell, ya, last, night,...</td>\n",
       "      <td>[566229, 700, 13, 219, 19241, 515, 3619, 190, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10548</td>\n",
       "      <td>20797</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>When the object of their belief is said to be ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[0.06133417785167694, 0.10471037030220032, 0....</td>\n",
       "      <td>[&lt;s&gt;, When, the, object, of, their, belief, is...</td>\n",
       "      <td>[566229, 257, 3, 2356, 6, 59, 4728, 11, 108, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10549</td>\n",
       "      <td>20537</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Koff You mean that as long as I put you to sle...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[-0.04543164372444153, 0.006741240620613098, ...</td>\n",
       "      <td>[&lt;s&gt;, Koff, You, mean, that, as, long, as, I, ...</td>\n",
       "      <td>[566229, 304437, 94, 616, 16, 29, 229, 29, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10550</td>\n",
       "      <td>20757</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Mr Connor 's assertion that more complex later...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[-0.027814187109470367, 0.055848635733127594,...</td>\n",
       "      <td>[&lt;s&gt;, Mr, Connor, 's, assertion, that, more, c...</td>\n",
       "      <td>[566229, 2558, 17914, 21, 18373, 16, 51, 1988,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10551</td>\n",
       "      <td>20677</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>excess stuff deleted I know of a similar incid...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[0.01678074523806572, 0.029153533279895782, 0...</td>\n",
       "      <td>[&lt;s&gt;, excess, stuff, deleted, I, know, of, a, ...</td>\n",
       "      <td>[566229, 5814, 809, 6562, 13, 114, 6, 7, 887, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10552</td>\n",
       "      <td>20719</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>The System refered to a moral system You shown...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[-0.018732327967882156, 0.05509016662836075, ...</td>\n",
       "      <td>[&lt;s&gt;, The, System, refered, to, a, moral, syst...</td>\n",
       "      <td>[566229, 23, 1140, 79272, 5, 7, 4964, 254, 94,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10553 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          category  \\\n",
       "0      19313  rec.sport.hockey   \n",
       "1      19312  rec.sport.hockey   \n",
       "2      19115  rec.sport.hockey   \n",
       "3      19224  rec.sport.hockey   \n",
       "4      19299  rec.sport.hockey   \n",
       "...      ...               ...   \n",
       "10548  20797       alt.atheism   \n",
       "10549  20537       alt.atheism   \n",
       "10550  20757       alt.atheism   \n",
       "10551  20677       alt.atheism   \n",
       "10552  20719       alt.atheism   \n",
       "\n",
       "                                         preprocess_text cat_id  \\\n",
       "0      Kovalev is too talented a player to play for R...     18   \n",
       "1      First of all the Penguins WILL win the cup aga...     18   \n",
       "2                        You ca n't But good luck trying     18   \n",
       "3      As the subject suggests the Flames were not im...     18   \n",
       "4      Well I got ta tell ya last night 's Leafs game...     18   \n",
       "...                                                  ...    ...   \n",
       "10548  When the object of their belief is said to be ...     13   \n",
       "10549  Koff You mean that as long as I put you to sle...     13   \n",
       "10550  Mr Connor 's assertion that more complex later...     13   \n",
       "10551  excess stuff deleted I know of a similar incid...     13   \n",
       "10552  The System refered to a moral system You shown...     13   \n",
       "\n",
       "                                             roberta_emb  \\\n",
       "0      [[-0.1072988361120224, 0.006329931318759918, -...   \n",
       "1      [[-0.0944674089550972, 0.004107087850570679, -...   \n",
       "2      [[-0.05532881245017052, 0.02691790461540222, 0...   \n",
       "3      [[0.004719207063317299, 0.036944739520549774, ...   \n",
       "4      [[-0.0014236271381378174, 0.02442687749862671,...   \n",
       "...                                                  ...   \n",
       "10548  [[0.06133417785167694, 0.10471037030220032, 0....   \n",
       "10549  [[-0.04543164372444153, 0.006741240620613098, ...   \n",
       "10550  [[-0.027814187109470367, 0.055848635733127594,...   \n",
       "10551  [[0.01678074523806572, 0.029153533279895782, 0...   \n",
       "10552  [[-0.018732327967882156, 0.05509016662836075, ...   \n",
       "\n",
       "                                             roberta_tok  \\\n",
       "0      [<s>, Kovalev, is, too, talented, a, player, t...   \n",
       "1      [<s>, First, of, all, the, Penguins, WILL, win...   \n",
       "2      [<s>, You, ca, n't, But, good, luck, trying, <...   \n",
       "3      [<s>, As, the, subject, suggests, the, Flames,...   \n",
       "4      [<s>, Well, I, got, ta, tell, ya, last, night,...   \n",
       "...                                                  ...   \n",
       "10548  [<s>, When, the, object, of, their, belief, is...   \n",
       "10549  [<s>, Koff, You, mean, that, as, long, as, I, ...   \n",
       "10550  [<s>, Mr, Connor, 's, assertion, that, more, c...   \n",
       "10551  [<s>, excess, stuff, deleted, I, know, of, a, ...   \n",
       "10552  [<s>, The, System, refered, to, a, moral, syst...   \n",
       "\n",
       "                                               glove_int  \n",
       "0      [566229, 119013, 11, 188, 5061, 7, 983, 5, 331...  \n",
       "1      [566229, 586, 6, 44, 3, 18799, 5777, 814, 3, 2...  \n",
       "2      [566229, 94, 324, 41, 175, 113, 2455, 553, 437...  \n",
       "3      [566229, 223, 3, 918, 4650, 3, 20021, 88, 36, ...  \n",
       "4      [566229, 700, 13, 219, 19241, 515, 3619, 190, ...  \n",
       "...                                                  ...  \n",
       "10548  [566229, 257, 3, 2356, 6, 59, 4728, 11, 108, 5...  \n",
       "10549  [566229, 304437, 94, 616, 16, 29, 229, 29, 13,...  \n",
       "10550  [566229, 2558, 17914, 21, 18373, 16, 51, 1988,...  \n",
       "10551  [566229, 5814, 809, 6562, 13, 114, 6, 7, 887, ...  \n",
       "10552  [566229, 23, 1140, 79272, 5, 7, 4964, 254, 94,...  \n",
       "\n",
       "[10553 rows x 7 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df = train_df.drop(['glove_emb'],axis=1)\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>preprocess_text</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>roberta_emb</th>\n",
       "      <th>roberta_tok</th>\n",
       "      <th>glove_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19313</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Kovalev is too talented a player to play for R...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.1072988361120224, 0.006329931318759918, -...</td>\n",
       "      <td>[&lt;s&gt;, Kovalev, is, too, talented, a, player, t...</td>\n",
       "      <td>[566229, 119013, 11, 188, 5061, 7, 983, 5, 331...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19312</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>First of all the Penguins WILL win the cup aga...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.0944674089550972, 0.004107087850570679, -...</td>\n",
       "      <td>[&lt;s&gt;, First, of, all, the, Penguins, WILL, win...</td>\n",
       "      <td>[566229, 586, 6, 44, 3, 18799, 5777, 814, 3, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19115</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>You ca n't But good luck trying</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.05532881245017052, 0.02691790461540222, 0...</td>\n",
       "      <td>[&lt;s&gt;, You, ca, n't, But, good, luck, trying, &lt;...</td>\n",
       "      <td>[566229, 94, 324, 41, 175, 113, 2455, 553, 437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19224</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>As the subject suggests the Flames were not im...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[0.004719207063317299, 0.036944739520549774, ...</td>\n",
       "      <td>[&lt;s&gt;, As, the, subject, suggests, the, Flames,...</td>\n",
       "      <td>[566229, 223, 3, 918, 4650, 3, 20021, 88, 36, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19299</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Well I got ta tell ya last night 's Leafs game...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.0014236271381378174, 0.02442687749862671,...</td>\n",
       "      <td>[&lt;s&gt;, Well, I, got, ta, tell, ya, last, night,...</td>\n",
       "      <td>[566229, 700, 13, 219, 19241, 515, 3619, 190, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10548</td>\n",
       "      <td>20797</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>When the object of their belief is said to be ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[0.06133417785167694, 0.10471037030220032, 0....</td>\n",
       "      <td>[&lt;s&gt;, When, the, object, of, their, belief, is...</td>\n",
       "      <td>[566229, 257, 3, 2356, 6, 59, 4728, 11, 108, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10549</td>\n",
       "      <td>20537</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Koff You mean that as long as I put you to sle...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[-0.04543164372444153, 0.006741240620613098, ...</td>\n",
       "      <td>[&lt;s&gt;, Koff, You, mean, that, as, long, as, I, ...</td>\n",
       "      <td>[566229, 304437, 94, 616, 16, 29, 229, 29, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10550</td>\n",
       "      <td>20757</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Mr Connor 's assertion that more complex later...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[-0.027814187109470367, 0.055848635733127594,...</td>\n",
       "      <td>[&lt;s&gt;, Mr, Connor, 's, assertion, that, more, c...</td>\n",
       "      <td>[566229, 2558, 17914, 21, 18373, 16, 51, 1988,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10551</td>\n",
       "      <td>20677</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>excess stuff deleted I know of a similar incid...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[0.01678074523806572, 0.029153533279895782, 0...</td>\n",
       "      <td>[&lt;s&gt;, excess, stuff, deleted, I, know, of, a, ...</td>\n",
       "      <td>[566229, 5814, 809, 6562, 13, 114, 6, 7, 887, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10552</td>\n",
       "      <td>20719</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>The System refered to a moral system You shown...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[-0.018732327967882156, 0.05509016662836075, ...</td>\n",
       "      <td>[&lt;s&gt;, The, System, refered, to, a, moral, syst...</td>\n",
       "      <td>[566229, 23, 1140, 79272, 5, 7, 4964, 254, 94,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10553 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          category  \\\n",
       "0      19313  rec.sport.hockey   \n",
       "1      19312  rec.sport.hockey   \n",
       "2      19115  rec.sport.hockey   \n",
       "3      19224  rec.sport.hockey   \n",
       "4      19299  rec.sport.hockey   \n",
       "...      ...               ...   \n",
       "10548  20797       alt.atheism   \n",
       "10549  20537       alt.atheism   \n",
       "10550  20757       alt.atheism   \n",
       "10551  20677       alt.atheism   \n",
       "10552  20719       alt.atheism   \n",
       "\n",
       "                                         preprocess_text cat_id  \\\n",
       "0      Kovalev is too talented a player to play for R...     18   \n",
       "1      First of all the Penguins WILL win the cup aga...     18   \n",
       "2                        You ca n't But good luck trying     18   \n",
       "3      As the subject suggests the Flames were not im...     18   \n",
       "4      Well I got ta tell ya last night 's Leafs game...     18   \n",
       "...                                                  ...    ...   \n",
       "10548  When the object of their belief is said to be ...     13   \n",
       "10549  Koff You mean that as long as I put you to sle...     13   \n",
       "10550  Mr Connor 's assertion that more complex later...     13   \n",
       "10551  excess stuff deleted I know of a similar incid...     13   \n",
       "10552  The System refered to a moral system You shown...     13   \n",
       "\n",
       "                                             roberta_emb  \\\n",
       "0      [[-0.1072988361120224, 0.006329931318759918, -...   \n",
       "1      [[-0.0944674089550972, 0.004107087850570679, -...   \n",
       "2      [[-0.05532881245017052, 0.02691790461540222, 0...   \n",
       "3      [[0.004719207063317299, 0.036944739520549774, ...   \n",
       "4      [[-0.0014236271381378174, 0.02442687749862671,...   \n",
       "...                                                  ...   \n",
       "10548  [[0.06133417785167694, 0.10471037030220032, 0....   \n",
       "10549  [[-0.04543164372444153, 0.006741240620613098, ...   \n",
       "10550  [[-0.027814187109470367, 0.055848635733127594,...   \n",
       "10551  [[0.01678074523806572, 0.029153533279895782, 0...   \n",
       "10552  [[-0.018732327967882156, 0.05509016662836075, ...   \n",
       "\n",
       "                                             roberta_tok  \\\n",
       "0      [<s>, Kovalev, is, too, talented, a, player, t...   \n",
       "1      [<s>, First, of, all, the, Penguins, WILL, win...   \n",
       "2      [<s>, You, ca, n't, But, good, luck, trying, <...   \n",
       "3      [<s>, As, the, subject, suggests, the, Flames,...   \n",
       "4      [<s>, Well, I, got, ta, tell, ya, last, night,...   \n",
       "...                                                  ...   \n",
       "10548  [<s>, When, the, object, of, their, belief, is...   \n",
       "10549  [<s>, Koff, You, mean, that, as, long, as, I, ...   \n",
       "10550  [<s>, Mr, Connor, 's, assertion, that, more, c...   \n",
       "10551  [<s>, excess, stuff, deleted, I, know, of, a, ...   \n",
       "10552  [<s>, The, System, refered, to, a, moral, syst...   \n",
       "\n",
       "                                               glove_int  \n",
       "0      [566229, 119013, 11, 188, 5061, 7, 983, 5, 331...  \n",
       "1      [566229, 586, 6, 44, 3, 18799, 5777, 814, 3, 2...  \n",
       "2      [566229, 94, 324, 41, 175, 113, 2455, 553, 437...  \n",
       "3      [566229, 223, 3, 918, 4650, 3, 20021, 88, 36, ...  \n",
       "4      [566229, 700, 13, 219, 19241, 515, 3619, 190, ...  \n",
       "...                                                  ...  \n",
       "10548  [566229, 257, 3, 2356, 6, 59, 4728, 11, 108, 5...  \n",
       "10549  [566229, 304437, 94, 616, 16, 29, 229, 29, 13,...  \n",
       "10550  [566229, 2558, 17914, 21, 18373, 16, 51, 1988,...  \n",
       "10551  [566229, 5814, 809, 6562, 13, 114, 6, 7, 887, ...  \n",
       "10552  [566229, 23, 1140, 79272, 5, 7, 4964, 254, 94,...  \n",
       "\n",
       "[10553 rows x 7 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.to_csv('./data/20news-bydate-v3/train_df.csv',index=False)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dimension normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.roberta_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = train_df.roberta_emb.tolist()\n",
    "np.array(kk).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated & Test\n",
    "* Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "法2\n",
    "* deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = pd.read_table('./data/preprocess/glove.840B.300d.txt', sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n",
    "# train_df['glove_emb'] = 0\n",
    "# train_df=train_df.astype(object)\n",
    "\n",
    "def vec(w):\n",
    "    return glove.loc[w].values\n",
    "\n",
    "def glove_convert(tok_li):\n",
    "    '''\n",
    "    Input: list of tokens by RoBERTa\n",
    "    Return: np array of max_length*300dim\n",
    "    '''\n",
    "    max_length = 498 #改\n",
    "    glove_pad = [0]*300\n",
    "    glove_emb = []\n",
    "    for token in tok_li:\n",
    "        glove_emb.append(glove.loc[token].values)\n",
    "    if len(glove_emb)<max_length:\n",
    "        for _ in range(max_length-len(glove_emb)):\n",
    "            glove_emb.append(glove_pad)\n",
    "    try:\n",
    "        assert len(glove_emb) == max_length\n",
    "    except:\n",
    "        print(\"maxlength ERR(now,ori):\",len(glove_emb) , max_length)\n",
    "    return np.array(glove_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e35b43fdcc04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'glove_emb'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roberta_tok'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_convert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   3823\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3824\u001b[0m         \"\"\"\n\u001b[0;32m-> 3825\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3826\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-d4cd50b1ddb5>\u001b[0m in \u001b[0;36mglove_convert\u001b[0;34m(tok_li)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mglove_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtok_li\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mglove_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3735\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3736\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3737\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 )\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_df['glove_emb'] = train_df['roberta_tok'].swifter.apply(glove_convert)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Metadata inference failed in `lambda`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nAttributeError(\"'Series' object has no attribute 'compute'\")\n\nTraceback:\n---------\n  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py\", line 170, in raise_on_meta_error\n    exc_type, exc_value, exc_traceback = sys.exc_info()\n  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/dask/dataframe/core.py\", line 4726, in _emulate\n    @insert_meta_param_description\n  File \"<ipython-input-16-9c1047120920>\", line 2, in <lambda>\n    res = ddata.map_partitions(lambda df: df['roberta_tok'].apply(glove_convert).compute(get=get))\n  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\", line 5179, in __getattr__\n    return object.__getattribute__(self, name)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py\u001b[0m in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_tb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m_emulate\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4726\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0minsert_meta_param_description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4727\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmap_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-9c1047120920>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mddata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roberta_tok'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_convert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'compute'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9c1047120920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mddata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roberta_tok'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_convert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36mmap_partitions\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0mParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36mmap_partitions\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4766\u001b[0m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4767\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4768\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScalar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4769\u001b[0m         layer = {\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m_emulate\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4726\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0minsert_meta_param_description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4727\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmap_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4728\u001b[0m     \"\"\" Apply Python function on each DataFrame partition.\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py\u001b[0m in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0mUNKNOWN_CATEGORIES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"__UNKNOWN_CATEGORIES__\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Metadata inference failed in `lambda`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nAttributeError(\"'Series' object has no attribute 'compute'\")\n\nTraceback:\n---------\n  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py\", line 170, in raise_on_meta_error\n    exc_type, exc_value, exc_traceback = sys.exc_info()\n  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/dask/dataframe/core.py\", line 4726, in _emulate\n    @insert_meta_param_description\n  File \"<ipython-input-16-9c1047120920>\", line 2, in <lambda>\n    res = ddata.map_partitions(lambda df: df['roberta_tok'].apply(glove_convert).compute(get=get))\n  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\", line 5179, in __getattr__\n    return object.__getattribute__(self, name)\n"
     ]
    }
   ],
   "source": [
    "# ddata = dd.from_pandas(train_df, npartitions=70)\n",
    "# res = ddata.map_partitions(lambda df: df['roberta_tok'].apply(glove_convert).compute(get=get))\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New pandarallel memory created - Size: 8192 MB\n",
      "Pandarallel will run on 36 workers\n"
     ]
    },
    {
     "ename": "ArrowIOError",
     "evalue": "Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandarallel/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandarallel/series.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(series, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mplasma_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_worker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mresult_worker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             ], copy=False)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArrowIOError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-207cb51dd4b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpandarallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshm_size_mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#shm_size_mb=8192,progress_bar=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'glove_emb'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roberta_tok'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_convert\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#swifter.apply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandarallel/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyarrow/_plasma.pyx\u001b[0m in \u001b[0;36mpyarrow._plasma.PlasmaClient.list\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowIOError\u001b[0m: Connection reset by peer"
     ]
    }
   ],
   "source": [
    "# train_df['glove_emb'] = 0\n",
    "# train_df=train_df.astype(object)\n",
    "# pandarallel.initialize(shm_size_mb=8192) #shm_size_mb=8192,progress_bar=True\n",
    "# train_df['glove_emb'] = train_df['roberta_tok'].parallel_apply(glove_convert) #swifter.apply\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>preprocess_text</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>roberta_emb</th>\n",
       "      <th>roberta_tok</th>\n",
       "      <th>glove_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19313</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Kovalev is too talented a player to play for R...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.1072988361120224, 0.006329931318759918, -...</td>\n",
       "      <td>[&lt;s&gt;, Kovalev, is, too, talented, a, player, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19312</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>First of all the Penguins WILL win the cup aga...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.0944674089550972, 0.004107087850570679, -...</td>\n",
       "      <td>[&lt;s&gt;, First, of, all, the, Penguins, WILL, win...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19115</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>You ca n't But good luck trying</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.05532881245017052, 0.02691790461540222, 0...</td>\n",
       "      <td>[&lt;s&gt;, You, ca, n't, But, good, luck, trying, &lt;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19224</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>As the subject suggests the Flames were not im...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[0.004719207063317299, 0.036944739520549774, ...</td>\n",
       "      <td>[&lt;s&gt;, As, the, subject, suggests, the, Flames,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19299</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Well I got ta tell ya last night 's Leafs game...</td>\n",
       "      <td>18</td>\n",
       "      <td>[[-0.0014236271381378174, 0.02442687749862671,...</td>\n",
       "      <td>[&lt;s&gt;, Well, I, got, ta, tell, ya, last, night,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10548</td>\n",
       "      <td>20797</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>When the object of their belief is said to be ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[0.06133417785167694, 0.10471037030220032, 0....</td>\n",
       "      <td>[&lt;s&gt;, When, the, object, of, their, belief, is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10549</td>\n",
       "      <td>20537</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Koff You mean that as long as I put you to sle...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[-0.04543164372444153, 0.006741240620613098, ...</td>\n",
       "      <td>[&lt;s&gt;, Koff, You, mean, that, as, long, as, I, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10550</td>\n",
       "      <td>20757</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Mr Connor 's assertion that more complex later...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[-0.027814187109470367, 0.055848635733127594,...</td>\n",
       "      <td>[&lt;s&gt;, Mr, Connor, 's, assertion, that, more, c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10551</td>\n",
       "      <td>20677</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>excess stuff deleted I know of a similar incid...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[0.01678074523806572, 0.029153533279895782, 0...</td>\n",
       "      <td>[&lt;s&gt;, excess, stuff, deleted, I, know, of, a, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10552</td>\n",
       "      <td>20719</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>The System refered to a moral system You shown...</td>\n",
       "      <td>13</td>\n",
       "      <td>[[-0.018732327967882156, 0.05509016662836075, ...</td>\n",
       "      <td>[&lt;s&gt;, The, System, refered, to, a, moral, syst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10553 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          category  \\\n",
       "0      19313  rec.sport.hockey   \n",
       "1      19312  rec.sport.hockey   \n",
       "2      19115  rec.sport.hockey   \n",
       "3      19224  rec.sport.hockey   \n",
       "4      19299  rec.sport.hockey   \n",
       "...      ...               ...   \n",
       "10548  20797       alt.atheism   \n",
       "10549  20537       alt.atheism   \n",
       "10550  20757       alt.atheism   \n",
       "10551  20677       alt.atheism   \n",
       "10552  20719       alt.atheism   \n",
       "\n",
       "                                         preprocess_text cat_id  \\\n",
       "0      Kovalev is too talented a player to play for R...     18   \n",
       "1      First of all the Penguins WILL win the cup aga...     18   \n",
       "2                        You ca n't But good luck trying     18   \n",
       "3      As the subject suggests the Flames were not im...     18   \n",
       "4      Well I got ta tell ya last night 's Leafs game...     18   \n",
       "...                                                  ...    ...   \n",
       "10548  When the object of their belief is said to be ...     13   \n",
       "10549  Koff You mean that as long as I put you to sle...     13   \n",
       "10550  Mr Connor 's assertion that more complex later...     13   \n",
       "10551  excess stuff deleted I know of a similar incid...     13   \n",
       "10552  The System refered to a moral system You shown...     13   \n",
       "\n",
       "                                             roberta_emb  \\\n",
       "0      [[-0.1072988361120224, 0.006329931318759918, -...   \n",
       "1      [[-0.0944674089550972, 0.004107087850570679, -...   \n",
       "2      [[-0.05532881245017052, 0.02691790461540222, 0...   \n",
       "3      [[0.004719207063317299, 0.036944739520549774, ...   \n",
       "4      [[-0.0014236271381378174, 0.02442687749862671,...   \n",
       "...                                                  ...   \n",
       "10548  [[0.06133417785167694, 0.10471037030220032, 0....   \n",
       "10549  [[-0.04543164372444153, 0.006741240620613098, ...   \n",
       "10550  [[-0.027814187109470367, 0.055848635733127594,...   \n",
       "10551  [[0.01678074523806572, 0.029153533279895782, 0...   \n",
       "10552  [[-0.018732327967882156, 0.05509016662836075, ...   \n",
       "\n",
       "                                             roberta_tok glove_emb  \n",
       "0      [<s>, Kovalev, is, too, talented, a, player, t...         0  \n",
       "1      [<s>, First, of, all, the, Penguins, WILL, win...         0  \n",
       "2      [<s>, You, ca, n't, But, good, luck, trying, <...         0  \n",
       "3      [<s>, As, the, subject, suggests, the, Flames,...         0  \n",
       "4      [<s>, Well, I, got, ta, tell, ya, last, night,...         0  \n",
       "...                                                  ...       ...  \n",
       "10548  [<s>, When, the, object, of, their, belief, is...         0  \n",
       "10549  [<s>, Koff, You, mean, that, as, long, as, I, ...         0  \n",
       "10550  [<s>, Mr, Connor, 's, assertion, that, more, c...         0  \n",
       "10551  [<s>, excess, stuff, deleted, I, know, of, a, ...         0  \n",
       "10552  [<s>, The, System, refered, to, a, moral, syst...         0  \n",
       "\n",
       "[10553 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-71:\n",
      "Process ForkPoolWorker-72:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/multiprocess/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/multiprocess/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/multiprocess/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/multiprocess/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/multiprocess/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/multiprocess/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/multiprocess/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/multiprocess/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/multiprocess/synchronize.py\", line 102, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.7/site-packages/multiprocess/synchronize.py\", line 102, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df=train_df.astype(object)\n",
    "# train_df['roberta_emb'] = train_df.roberta_emb.astype(object)\n",
    "train_df.loc[i,'roberta_emb'] = np.array(roberta_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 1024)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.roberta_emb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df.id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['roberta_emb'], train_df['roberta_tok'] = zip(*train_df['preprocess_text'].map(tokenize_text))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ef797c2b3b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
