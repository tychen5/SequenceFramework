{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.text import *\n",
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import pickle\n",
    "import gc\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_statistics(all_length):\n",
    "    '''\n",
    "    input: length list of elements e.g.[1,1,1,3,5,9,4,2,1,3,54,78,5...]\n",
    "    output1: mean、std、mode、min、q1、median(q2)、q3、max、iqr、outlier、far out\n",
    "    output2: statistics graph、10%~90% form\n",
    "    '''\n",
    "    stat_dict = {}\n",
    "    stat_dict['mean'] = np.mean(all_length)\n",
    "    stat_dict['std'] = np.std(all_length)\n",
    "    stat_dict['mode'] = np.argmax(np.bincount(all_length))\n",
    "    stat_dict['min'] = np.min(all_length)\n",
    "    stat_dict['q1'] = np.quantile(all_length,0.25)\n",
    "    stat_dict['median'] = np.quantile(all_length,0.5)\n",
    "    stat_dict['q3'] = np.quantile(all_length,0.75)\n",
    "    stat_dict['max'] = np.max(all_length)\n",
    "    stat_dict['iqr'] = stat_dict['q3'] - stat_dict['q1']\n",
    "    stat_dict['outlier'] = stat_dict['q3'] + 1.5*stat_dict['iqr']\n",
    "    stat_dict['far_out'] = stat_dict['q3'] + 3*stat_dict['iqr']\n",
    "    for i in [10,20,30,40,50,60,70,80,90,100]:\n",
    "        stat_dict[str(i)+'%'] = np.percentile(all_length,i)\n",
    "    return pd.DataFrame.from_dict(stat_dict,orient='index',columns=['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 8352#8352 #Top most frequent words to consider. Any less frequent word will appear as oov_char value in the sequence data.\n",
    "max_length = 360#360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_words#: 30979\n",
      "8260 train sequences\n",
      "2066 test sequences\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "print('all_words#:',len(word_index))\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,maxlen=max_length,\n",
    "                                                         test_split=0.2,seed=830913)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>145.964197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>145.878476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q1</th>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q3</th>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2376.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iqr</th>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlier</th>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_out</th>\n",
       "      <td>540.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>154.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>206.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>315.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100%</th>\n",
       "      <td>2376.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              length\n",
       "mean      145.964197\n",
       "std       145.878476\n",
       "mode       17.000000\n",
       "min         2.000000\n",
       "q1         60.000000\n",
       "median     95.000000\n",
       "q3        180.000000\n",
       "max      2376.000000\n",
       "iqr       120.000000\n",
       "outlier   360.000000\n",
       "far_out   540.000000\n",
       "10%        35.000000\n",
       "20%        53.000000\n",
       "30%        67.000000\n",
       "40%        81.000000\n",
       "50%        95.000000\n",
       "60%       112.000000\n",
       "70%       154.000000\n",
       "80%       206.000000\n",
       "90%       315.000000\n",
       "100%     2376.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_len = [len(x) for x in x_train]\n",
    "# test_len = [len(x) for x in x_test]\n",
    "# all_len = train_len\n",
    "# all_len.extend(test_len)\n",
    "# basic_statistics(all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(all_len)\n",
    "# df.to_excel('./results/length_dist.xlsx', header=False, index=False)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 11228,\n",
       "         53: 4213,\n",
       "         352: 647,\n",
       "         26: 8451,\n",
       "         14: 15015,\n",
       "         279: 801,\n",
       "         39: 5818,\n",
       "         72: 3091,\n",
       "         4497: 26,\n",
       "         18: 11039,\n",
       "         83: 2597,\n",
       "         5291: 21,\n",
       "         88: 2381,\n",
       "         5397: 20,\n",
       "         11: 20141,\n",
       "         3412: 37,\n",
       "         19: 10755,\n",
       "         151: 1363,\n",
       "         230: 962,\n",
       "         831: 253,\n",
       "         15: 13329,\n",
       "         165: 1232,\n",
       "         318: 707,\n",
       "         3780: 33,\n",
       "         124: 1676,\n",
       "         1527: 117,\n",
       "         1424: 128,\n",
       "         35: 6588,\n",
       "         5302: 20,\n",
       "         12: 16668,\n",
       "         17: 11191,\n",
       "         486: 459,\n",
       "         341: 663,\n",
       "         142: 1466,\n",
       "         255: 870,\n",
       "         219: 997,\n",
       "         429: 528,\n",
       "         68: 3363,\n",
       "         146: 1402,\n",
       "         252: 882,\n",
       "         191: 1098,\n",
       "         15448: 3,\n",
       "         3631: 35,\n",
       "         2283: 65,\n",
       "         71: 3120,\n",
       "         10: 29581,\n",
       "         342: 660,\n",
       "         49: 4565,\n",
       "         1977: 80,\n",
       "         324: 695,\n",
       "         27: 8311,\n",
       "         9222: 8,\n",
       "         672: 330,\n",
       "         450: 506,\n",
       "         5: 42393,\n",
       "         547: 406,\n",
       "         40: 5593,\n",
       "         471: 476,\n",
       "         4810: 24,\n",
       "         149: 1371,\n",
       "         26639: 1,\n",
       "         794: 266,\n",
       "         734: 300,\n",
       "         8976: 8,\n",
       "         8975: 8,\n",
       "         4007: 31,\n",
       "         9: 29956,\n",
       "         25113: 1,\n",
       "         247: 904,\n",
       "         8: 29978,\n",
       "         1299: 144,\n",
       "         381: 618,\n",
       "         34: 7010,\n",
       "         385: 604,\n",
       "         13: 15224,\n",
       "         109: 1810,\n",
       "         167: 1224,\n",
       "         4: 82723,\n",
       "         60: 3654,\n",
       "         130: 1617,\n",
       "         1461: 123,\n",
       "         3366: 38,\n",
       "         1896: 86,\n",
       "         204: 1046,\n",
       "         33: 7037,\n",
       "         3512: 36,\n",
       "         888: 234,\n",
       "         25: 8579,\n",
       "         423: 535,\n",
       "         256: 866,\n",
       "         7: 33157,\n",
       "         1075: 185,\n",
       "         329: 685,\n",
       "         769: 281,\n",
       "         302: 742,\n",
       "         113: 1749,\n",
       "         446: 508,\n",
       "         107: 1841,\n",
       "         226: 979,\n",
       "         240: 923,\n",
       "         817: 258,\n",
       "         101: 1923,\n",
       "         36: 6436,\n",
       "         189: 1107,\n",
       "         6501: 15,\n",
       "         57: 3756,\n",
       "         6: 40350,\n",
       "         481: 464,\n",
       "         239: 927,\n",
       "         118: 1704,\n",
       "         246: 905,\n",
       "         424: 535,\n",
       "         386: 601,\n",
       "         415: 545,\n",
       "         1677: 103,\n",
       "         24: 9022,\n",
       "         291: 767,\n",
       "         662: 337,\n",
       "         85: 2474,\n",
       "         2243: 67,\n",
       "         880: 236,\n",
       "         224: 988,\n",
       "         1077: 184,\n",
       "         54: 3858,\n",
       "         29: 7797,\n",
       "         530: 419,\n",
       "         30: 7627,\n",
       "         1500: 119,\n",
       "         4175: 29,\n",
       "         69: 3203,\n",
       "         12040: 5,\n",
       "         84: 2506,\n",
       "         442: 509,\n",
       "         31: 7288,\n",
       "         373: 628,\n",
       "         159: 1298,\n",
       "         7370: 12,\n",
       "         41: 5553,\n",
       "         351: 648,\n",
       "         343: 656,\n",
       "         6880: 14,\n",
       "         21: 10377,\n",
       "         840: 249,\n",
       "         184: 1129,\n",
       "         5463: 20,\n",
       "         526: 420,\n",
       "         87: 2405,\n",
       "         108: 1812,\n",
       "         140: 1471,\n",
       "         168: 1207,\n",
       "         231: 961,\n",
       "         286: 779,\n",
       "         1351: 138,\n",
       "         397: 574,\n",
       "         105: 1866,\n",
       "         3497: 36,\n",
       "         120: 1694,\n",
       "         1456: 124,\n",
       "         161: 1272,\n",
       "         64: 3453,\n",
       "         1909: 84,\n",
       "         762: 283,\n",
       "         550: 403,\n",
       "         325: 694,\n",
       "         1766: 95,\n",
       "         613: 365,\n",
       "         548: 406,\n",
       "         3205: 41,\n",
       "         16: 12395,\n",
       "         5700: 18,\n",
       "         15663: 3,\n",
       "         51: 4256,\n",
       "         562: 396,\n",
       "         299: 753,\n",
       "         45: 5081,\n",
       "         306: 733,\n",
       "         194: 1086,\n",
       "         572: 388,\n",
       "         1222: 156,\n",
       "         3586: 35,\n",
       "         7718: 11,\n",
       "         22: 9345,\n",
       "         3297: 39,\n",
       "         3380: 38,\n",
       "         66: 3380,\n",
       "         2794: 50,\n",
       "         1163: 167,\n",
       "         178: 1160,\n",
       "         74: 3060,\n",
       "         865: 242,\n",
       "         46: 4836,\n",
       "         353: 645,\n",
       "         134: 1564,\n",
       "         70: 3184,\n",
       "         4596: 25,\n",
       "         86: 2434,\n",
       "         47: 4688,\n",
       "         4315: 27,\n",
       "         597: 377,\n",
       "         688: 323,\n",
       "         5242: 21,\n",
       "         32: 7100,\n",
       "         4215: 28,\n",
       "         63: 3492,\n",
       "         180: 1143,\n",
       "         183: 1133,\n",
       "         61: 3652,\n",
       "         2979: 46,\n",
       "         59: 3689,\n",
       "         4999: 22,\n",
       "         123: 1680,\n",
       "         235: 946,\n",
       "         131: 1607,\n",
       "         891: 233,\n",
       "         4088: 30,\n",
       "         98: 2063,\n",
       "         1025: 196,\n",
       "         633: 351,\n",
       "         2543: 58,\n",
       "         150: 1366,\n",
       "         710: 313,\n",
       "         220: 994,\n",
       "         48: 4574,\n",
       "         864: 243,\n",
       "         276: 809,\n",
       "         360: 641,\n",
       "         211: 1026,\n",
       "         1004: 203,\n",
       "         128: 1619,\n",
       "         10485: 6,\n",
       "         5769: 18,\n",
       "         651: 343,\n",
       "         574: 387,\n",
       "         400: 571,\n",
       "         3673: 34,\n",
       "         6189: 16,\n",
       "         186: 1121,\n",
       "         3879: 32,\n",
       "         968: 212,\n",
       "         90: 2331,\n",
       "         1081: 183,\n",
       "         5604: 19,\n",
       "         4167: 29,\n",
       "         14223: 3,\n",
       "         265: 850,\n",
       "         861: 244,\n",
       "         483: 461,\n",
       "         2858: 48,\n",
       "         3044: 44,\n",
       "         2576: 56,\n",
       "         551: 401,\n",
       "         50: 4383,\n",
       "         5702: 18,\n",
       "         1594: 110,\n",
       "         2161: 71,\n",
       "         111: 1753,\n",
       "         304: 735,\n",
       "         44: 5082,\n",
       "         2128: 72,\n",
       "         3632: 35,\n",
       "         62: 3646,\n",
       "         4200: 29,\n",
       "         2535: 58,\n",
       "         160: 1298,\n",
       "         294: 764,\n",
       "         76: 3019,\n",
       "         67: 3374,\n",
       "         1872: 87,\n",
       "         915: 227,\n",
       "         89: 2371,\n",
       "         135: 1519,\n",
       "         312: 715,\n",
       "         117: 1705,\n",
       "         225: 979,\n",
       "         206: 1042,\n",
       "         152: 1363,\n",
       "         372: 629,\n",
       "         680: 325,\n",
       "         37: 6266,\n",
       "         38: 6157,\n",
       "         387: 600,\n",
       "         516: 431,\n",
       "         500: 447,\n",
       "         729: 301,\n",
       "         838: 250,\n",
       "         52: 4244,\n",
       "         846: 247,\n",
       "         458: 487,\n",
       "         757: 286,\n",
       "         1605: 109,\n",
       "         3963: 31,\n",
       "         317: 708,\n",
       "         55: 3838,\n",
       "         528: 420,\n",
       "         2457: 60,\n",
       "         16383: 2,\n",
       "         260: 859,\n",
       "         2735: 51,\n",
       "         681: 325,\n",
       "         1195: 159,\n",
       "         4779: 24,\n",
       "         1204: 158,\n",
       "         28: 8056,\n",
       "         196: 1072,\n",
       "         1735: 97,\n",
       "         523: 424,\n",
       "         145: 1407,\n",
       "         2068: 75,\n",
       "         420: 538,\n",
       "         73: 3061,\n",
       "         418: 541,\n",
       "         525: 421,\n",
       "         8255: 10,\n",
       "         102: 1921,\n",
       "         289: 772,\n",
       "         1474: 121,\n",
       "         93: 2246,\n",
       "         1926: 83,\n",
       "         273: 819,\n",
       "         542: 410,\n",
       "         202: 1049,\n",
       "         876: 237,\n",
       "         331: 684,\n",
       "         208: 1034,\n",
       "         147: 1400,\n",
       "         126: 1644,\n",
       "         28507: 1,\n",
       "         661: 339,\n",
       "         16629: 2,\n",
       "         768: 281,\n",
       "         3186: 42,\n",
       "         77: 3011,\n",
       "         238: 931,\n",
       "         43: 5369,\n",
       "         133: 1566,\n",
       "         91: 2277,\n",
       "         410: 550,\n",
       "         132: 1586,\n",
       "         663: 337,\n",
       "         233: 950,\n",
       "         5900: 18,\n",
       "         6404: 16,\n",
       "         4855: 23,\n",
       "         625: 355,\n",
       "         42: 5379,\n",
       "         438: 516,\n",
       "         80: 2749,\n",
       "         1901: 85,\n",
       "         158: 1318,\n",
       "         20: 10746,\n",
       "         355: 645,\n",
       "         6529: 15,\n",
       "         56: 3810,\n",
       "         17636: 2,\n",
       "         938: 220,\n",
       "         316: 709,\n",
       "         100: 1956,\n",
       "         261: 856,\n",
       "         439: 516,\n",
       "         7675: 11,\n",
       "         1286: 145,\n",
       "         29406: 1,\n",
       "         5073: 22,\n",
       "         4755: 24,\n",
       "         2827: 49,\n",
       "         19901: 2,\n",
       "         12035: 5,\n",
       "         9454: 7,\n",
       "         1452: 124,\n",
       "         986: 207,\n",
       "         148: 1374,\n",
       "         732: 301,\n",
       "         310: 724,\n",
       "         281: 793,\n",
       "         200: 1050,\n",
       "         11347: 5,\n",
       "         19454: 2,\n",
       "         1649: 105,\n",
       "         21032: 1,\n",
       "         903: 230,\n",
       "         963: 214,\n",
       "         675: 326,\n",
       "         21760: 1,\n",
       "         4254: 28,\n",
       "         18761: 2,\n",
       "         187: 1121,\n",
       "         188: 1114,\n",
       "         4163: 29,\n",
       "         3114: 43,\n",
       "         546: 406,\n",
       "         3611: 35,\n",
       "         5630: 19,\n",
       "         502: 445,\n",
       "         11066: 5,\n",
       "         701: 316,\n",
       "         765: 281,\n",
       "         1354: 136,\n",
       "         251: 882,\n",
       "         335: 670,\n",
       "         79: 2883,\n",
       "         4117: 29,\n",
       "         22496: 1,\n",
       "         6845: 14,\n",
       "         894: 232,\n",
       "         2302: 65,\n",
       "         205: 1045,\n",
       "         2430: 61,\n",
       "         362: 640,\n",
       "         524: 424,\n",
       "         78: 2905,\n",
       "         3063: 44,\n",
       "         863: 243,\n",
       "         582: 382,\n",
       "         832: 252,\n",
       "         323: 699,\n",
       "         195: 1081,\n",
       "         18932: 2,\n",
       "         22172: 1,\n",
       "         8947: 8,\n",
       "         1178: 162,\n",
       "         144: 1430,\n",
       "         671: 332,\n",
       "         396: 577,\n",
       "         6379: 16,\n",
       "         175: 1176,\n",
       "         1041: 193,\n",
       "         1379: 134,\n",
       "         735: 300,\n",
       "         788: 271,\n",
       "         2763: 51,\n",
       "         270: 826,\n",
       "         23: 9113,\n",
       "         515: 432,\n",
       "         472: 474,\n",
       "         272: 823,\n",
       "         4242: 28,\n",
       "         284: 783,\n",
       "         750: 291,\n",
       "         6115: 17,\n",
       "         5201: 21,\n",
       "         462: 484,\n",
       "         482: 464,\n",
       "         780: 275,\n",
       "         122: 1690,\n",
       "         1047: 191,\n",
       "         138: 1500,\n",
       "         2885: 48,\n",
       "         2528: 58,\n",
       "         4455: 26,\n",
       "         1069: 186,\n",
       "         207: 1038,\n",
       "         2938: 47,\n",
       "         8418: 9,\n",
       "         726: 302,\n",
       "         3711: 34,\n",
       "         2276: 66,\n",
       "         1402: 131,\n",
       "         1088: 181,\n",
       "         203: 1047,\n",
       "         5473: 20,\n",
       "         258: 861,\n",
       "         2819: 49,\n",
       "         3688: 34,\n",
       "         162: 1267,\n",
       "         1643: 105,\n",
       "         5553: 19,\n",
       "         4328: 27,\n",
       "         5453: 20,\n",
       "         921: 225,\n",
       "         139: 1491,\n",
       "         245: 906,\n",
       "         1271: 147,\n",
       "         1555: 114,\n",
       "         156: 1323,\n",
       "         2933: 47,\n",
       "         7392: 12,\n",
       "         749: 291,\n",
       "         6077: 17,\n",
       "         4313: 27,\n",
       "         875: 238,\n",
       "         314: 714,\n",
       "         2080: 74,\n",
       "         5237: 21,\n",
       "         2132: 72,\n",
       "         5529: 19,\n",
       "         1415: 129,\n",
       "         2178: 70,\n",
       "         296: 760,\n",
       "         5405: 20,\n",
       "         3806: 32,\n",
       "         1044: 192,\n",
       "         3952: 31,\n",
       "         363: 640,\n",
       "         842: 248,\n",
       "         852: 246,\n",
       "         4601: 25,\n",
       "         127: 1629,\n",
       "         591: 379,\n",
       "         262: 856,\n",
       "         5030: 22,\n",
       "         13989: 3,\n",
       "         5182: 21,\n",
       "         7018: 13,\n",
       "         3126: 43,\n",
       "         5569: 19,\n",
       "         5963: 17,\n",
       "         11427: 5,\n",
       "         1480: 120,\n",
       "         141: 1468,\n",
       "         2425: 61,\n",
       "         1038: 194,\n",
       "         851: 246,\n",
       "         311: 718,\n",
       "         512: 435,\n",
       "         519: 430,\n",
       "         2385: 62,\n",
       "         497: 450,\n",
       "         580: 383,\n",
       "         6682: 15,\n",
       "         332: 678,\n",
       "         1161: 167,\n",
       "         798: 265,\n",
       "         121: 1693,\n",
       "         1358: 136,\n",
       "         232: 956,\n",
       "         6360: 16,\n",
       "         829: 253,\n",
       "         6082: 17,\n",
       "         356: 643,\n",
       "         179: 1148,\n",
       "         14601: 3,\n",
       "         1139: 173,\n",
       "         2131: 72,\n",
       "         7590: 12,\n",
       "         1094: 180,\n",
       "         1458: 124,\n",
       "         1843: 89,\n",
       "         6084: 17,\n",
       "         7151: 13,\n",
       "         13785: 4,\n",
       "         7931: 11,\n",
       "         645: 346,\n",
       "         2510: 59,\n",
       "         1841: 89,\n",
       "         371: 630,\n",
       "         8891: 8,\n",
       "         297: 759,\n",
       "         900: 231,\n",
       "         3130: 42,\n",
       "         1064: 187,\n",
       "         988: 207,\n",
       "         679: 326,\n",
       "         278: 809,\n",
       "         65: 3440,\n",
       "         2753: 51,\n",
       "         401: 569,\n",
       "         5722: 18,\n",
       "         4821: 24,\n",
       "         201: 1050,\n",
       "         12192: 4,\n",
       "         1384: 132,\n",
       "         2732: 52,\n",
       "         699: 316,\n",
       "         4662: 25,\n",
       "         2307: 65,\n",
       "         9116: 8,\n",
       "         17694: 2,\n",
       "         652: 343,\n",
       "         6989: 13,\n",
       "         1109: 178,\n",
       "         155: 1328,\n",
       "         4957: 22,\n",
       "         1714: 99,\n",
       "         1895: 86,\n",
       "         1545: 115,\n",
       "         1485: 120,\n",
       "         778: 277,\n",
       "         354: 645,\n",
       "         1200: 158,\n",
       "         215: 1017,\n",
       "         181: 1140,\n",
       "         907: 229,\n",
       "         106: 1859,\n",
       "         1669: 104,\n",
       "         464: 482,\n",
       "         359: 643,\n",
       "         222: 990,\n",
       "         480: 464,\n",
       "         4216: 28,\n",
       "         3451: 37,\n",
       "         895: 232,\n",
       "         567: 392,\n",
       "         985: 207,\n",
       "         1434: 127,\n",
       "         18534: 2,\n",
       "         15146: 3,\n",
       "         16226: 3,\n",
       "         824: 256,\n",
       "         669: 333,\n",
       "         670: 333,\n",
       "         114: 1737,\n",
       "         1533: 116,\n",
       "         1365: 135,\n",
       "         1056: 188,\n",
       "         569: 391,\n",
       "         2594: 56,\n",
       "         250: 884,\n",
       "         1393: 131,\n",
       "         2291: 65,\n",
       "         12908: 4,\n",
       "         870: 240,\n",
       "         13684: 4,\n",
       "         19776: 2,\n",
       "         1022: 196,\n",
       "         5331: 20,\n",
       "         3080: 44,\n",
       "         422: 535,\n",
       "         337: 666,\n",
       "         1348: 138,\n",
       "         3207: 41,\n",
       "         15548: 3,\n",
       "         15395: 3,\n",
       "         8487: 9,\n",
       "         13131: 4,\n",
       "         2743: 51,\n",
       "         1679: 103,\n",
       "         1657: 105,\n",
       "         691: 321,\n",
       "         24421: 1,\n",
       "         249: 892,\n",
       "         5901: 18,\n",
       "         979: 208,\n",
       "         1304: 143,\n",
       "         4958: 22,\n",
       "         1449: 125,\n",
       "         4492: 26,\n",
       "         529: 419,\n",
       "         5356: 20,\n",
       "         1601: 109,\n",
       "         1446: 126,\n",
       "         1008: 201,\n",
       "         4040: 30,\n",
       "         104: 1883,\n",
       "         7775: 11,\n",
       "         257: 862,\n",
       "         217: 1001,\n",
       "         553: 400,\n",
       "         2781: 50,\n",
       "         5821: 18,\n",
       "         110: 1758,\n",
       "         8016: 10,\n",
       "         4185: 29,\n",
       "         777: 277,\n",
       "         4034: 30,\n",
       "         1215: 156,\n",
       "         193: 1093,\n",
       "         9162: 8,\n",
       "         58: 3710,\n",
       "         27814: 1,\n",
       "         1614: 108,\n",
       "         3326: 39,\n",
       "         1324: 141,\n",
       "         6046: 17,\n",
       "         709: 313,\n",
       "         16640: 2,\n",
       "         8808: 8,\n",
       "         4374: 27,\n",
       "         4932: 23,\n",
       "         4766: 24,\n",
       "         2005: 79,\n",
       "         9694: 7,\n",
       "         3533: 36,\n",
       "         3388: 38,\n",
       "         3343: 39,\n",
       "         27085: 1,\n",
       "         1833: 89,\n",
       "         321: 703,\n",
       "         9451: 7,\n",
       "         19750: 2,\n",
       "         1745: 96,\n",
       "         1965: 81,\n",
       "         2662: 54,\n",
       "         1262: 149,\n",
       "         2019: 78,\n",
       "         29713: 1,\n",
       "         3467: 37,\n",
       "         3860: 32,\n",
       "         599: 376,\n",
       "         182: 1137,\n",
       "         3138: 42,\n",
       "         1046: 191,\n",
       "         479: 466,\n",
       "         236: 945,\n",
       "         564: 395,\n",
       "         1997: 79,\n",
       "         1209: 157,\n",
       "         736: 299,\n",
       "         2148: 71,\n",
       "         9184: 8,\n",
       "         12187: 4,\n",
       "         308: 730,\n",
       "         1607: 109,\n",
       "         1082: 182,\n",
       "         328: 687,\n",
       "         1226: 155,\n",
       "         210: 1027,\n",
       "         961: 214,\n",
       "         4985: 22,\n",
       "         2023: 77,\n",
       "         1016: 199,\n",
       "         448: 506,\n",
       "         724: 305,\n",
       "         303: 736,\n",
       "         909: 229,\n",
       "         223: 989,\n",
       "         2040: 76,\n",
       "         3016: 45,\n",
       "         11303: 5,\n",
       "         287: 776,\n",
       "         8269: 10,\n",
       "         3227: 41,\n",
       "         198: 1058,\n",
       "         3235: 41,\n",
       "         1898: 85,\n",
       "         1024: 196,\n",
       "         1974: 80,\n",
       "         12497: 4,\n",
       "         11381: 5,\n",
       "         2563: 57,\n",
       "         478: 467,\n",
       "         9633: 7,\n",
       "         97: 2077,\n",
       "         305: 734,\n",
       "         1066: 186,\n",
       "         585: 380,\n",
       "         177: 1166,\n",
       "         6794: 14,\n",
       "         4759: 24,\n",
       "         253: 877,\n",
       "         228: 964,\n",
       "         1457: 124,\n",
       "         1927: 83,\n",
       "         112: 1753,\n",
       "         1349: 138,\n",
       "         616: 363,\n",
       "         1873: 87,\n",
       "         214: 1022,\n",
       "         212: 1025,\n",
       "         75: 3040,\n",
       "         1572: 112,\n",
       "         2505: 59,\n",
       "         190: 1100,\n",
       "         447: 507,\n",
       "         508: 437,\n",
       "         1171: 165,\n",
       "         358: 643,\n",
       "         1414: 129,\n",
       "         654: 343,\n",
       "         1218: 156,\n",
       "         967: 212,\n",
       "         457: 489,\n",
       "         1136: 173,\n",
       "         1622: 107,\n",
       "         1007: 202,\n",
       "         1237: 153,\n",
       "         3447: 37,\n",
       "         9263: 8,\n",
       "         657: 342,\n",
       "         820: 257,\n",
       "         1673: 103,\n",
       "         6851: 14,\n",
       "         1521: 117,\n",
       "         95: 2162,\n",
       "         23859: 1,\n",
       "         711: 312,\n",
       "         444: 508,\n",
       "         744: 294,\n",
       "         1515: 117,\n",
       "         2009: 78,\n",
       "         6847: 14,\n",
       "         3850: 32,\n",
       "         378: 621,\n",
       "         2825: 49,\n",
       "         958: 215,\n",
       "         1207: 157,\n",
       "         129: 1617,\n",
       "         485: 460,\n",
       "         154: 1331,\n",
       "         3030: 45,\n",
       "         992: 205,\n",
       "         1242: 152,\n",
       "         816: 258,\n",
       "         2985: 45,\n",
       "         571: 388,\n",
       "         520: 427,\n",
       "         725: 304,\n",
       "         115: 1737,\n",
       "         14289: 3,\n",
       "         10148: 6,\n",
       "         6768: 14,\n",
       "         11543: 5,\n",
       "         1524: 117,\n",
       "         7321: 12,\n",
       "         608: 369,\n",
       "         1176: 162,\n",
       "         3596: 35,\n",
       "         173: 1182,\n",
       "         563: 395,\n",
       "         488: 458,\n",
       "         4533: 26,\n",
       "         1413: 129,\n",
       "         1807: 91,\n",
       "         2666: 53,\n",
       "         408: 552,\n",
       "         164: 1243,\n",
       "         586: 380,\n",
       "         2335: 63,\n",
       "         1111: 178,\n",
       "         1666: 104,\n",
       "         1322: 141,\n",
       "         1290: 145,\n",
       "         4756: 24,\n",
       "         404: 563,\n",
       "         908: 229,\n",
       "         740: 295,\n",
       "         621: 359,\n",
       "         1316: 142,\n",
       "         15632: 3,\n",
       "         3815: 32,\n",
       "         650: 343,\n",
       "         1825: 90,\n",
       "         4234: 28,\n",
       "         673: 330,\n",
       "         3145: 42,\n",
       "         192: 1095,\n",
       "         510: 436,\n",
       "         604: 371,\n",
       "         2147: 71,\n",
       "         506: 440,\n",
       "         443: 508,\n",
       "         469: 476,\n",
       "         11887: 5,\n",
       "         2564: 57,\n",
       "         125: 1665,\n",
       "         454: 493,\n",
       "         19191: 2,\n",
       "         1152: 169,\n",
       "         96: 2097,\n",
       "         25255: 1,\n",
       "         6087: 17,\n",
       "         847: 247,\n",
       "         3530: 36,\n",
       "         3427: 37,\n",
       "         2852: 49,\n",
       "         1107: 178,\n",
       "         1742: 96,\n",
       "         81: 2664,\n",
       "         5207: 21,\n",
       "         2542: 58,\n",
       "         1450: 125,\n",
       "         116: 1706,\n",
       "         1498: 119,\n",
       "         2256: 66,\n",
       "         1467: 122,\n",
       "         1476: 121,\n",
       "         5163: 21,\n",
       "         1435: 127,\n",
       "         395: 578,\n",
       "         4568: 25,\n",
       "         4214: 28,\n",
       "         3031: 44,\n",
       "         6719: 14,\n",
       "         4341: 27,\n",
       "         1009: 200,\n",
       "         716: 307,\n",
       "         1578: 112,\n",
       "         4616: 25,\n",
       "         738: 297,\n",
       "         5060: 22,\n",
       "         3857: 32,\n",
       "         1423: 128,\n",
       "         507: 439,\n",
       "         384: 605,\n",
       "         1281: 146,\n",
       "         615: 363,\n",
       "         1540: 115,\n",
       "         1026: 196,\n",
       "         899: 231,\n",
       "         715: 307,\n",
       "         602: 373,\n",
       "         290: 769,\n",
       "         349: 653,\n",
       "         737: 297,\n",
       "         614: 365,\n",
       "         850: 246,\n",
       "         452: 496,\n",
       "         552: 401,\n",
       "         170: 1196,\n",
       "         5668: 19,\n",
       "         2582: 56,\n",
       "         761: 283,\n",
       "         266: 842,\n",
       "         3244: 40,\n",
       "         941: 219,\n",
       "         242: 920,\n",
       "         1225: 155,\n",
       "         477: 467,\n",
       "         2575: 56,\n",
       "         24857: 1,\n",
       "         12612: 4,\n",
       "         7005: 13,\n",
       "         2673: 53,\n",
       "         4081: 30,\n",
       "         4131: 29,\n",
       "         1360: 135,\n",
       "         884: 235,\n",
       "         8520: 9,\n",
       "         13719: 4,\n",
       "         12262: 4,\n",
       "         2888: 48,\n",
       "         339: 665,\n",
       "         609: 368,\n",
       "         812: 259,\n",
       "         13737: 4,\n",
       "         419: 539,\n",
       "         434: 520,\n",
       "         277: 809,\n",
       "         295: 761,\n",
       "         92: 2248,\n",
       "         7315: 12,\n",
       "         3748: 33,\n",
       "         280: 798,\n",
       "         209: 1033,\n",
       "         2142: 72,\n",
       "         12833: 4,\n",
       "         390: 589,\n",
       "         473: 474,\n",
       "         248: 901,\n",
       "         1362: 135,\n",
       "         20092: 2,\n",
       "         747: 291,\n",
       "         218: 998,\n",
       "         5589: 19,\n",
       "         1475: 121,\n",
       "         2669: 53,\n",
       "         476: 469,\n",
       "         800: 264,\n",
       "         3522: 36,\n",
       "         6930: 14,\n",
       "         4296: 28,\n",
       "         3367: 38,\n",
       "         487: 459,\n",
       "         594: 378,\n",
       "         6929: 14,\n",
       "         14191: 3,\n",
       "         810: 260,\n",
       "         7949: 11,\n",
       "         1061: 187,\n",
       "         1158: 168,\n",
       "         3505: 36,\n",
       "         2918: 47,\n",
       "         3026: 45,\n",
       "         3218: 41,\n",
       "         559: 397,\n",
       "         2014: 78,\n",
       "         1129: 175,\n",
       "         7346: 12,\n",
       "         853: 245,\n",
       "         15507: 3,\n",
       "         581: 382,\n",
       "         103: 1911,\n",
       "         10487: 6,\n",
       "         1208: 157,\n",
       "         7764: 11,\n",
       "         719: 307,\n",
       "         13098: 4,\n",
       "         6696: 14,\n",
       "         166: 1226,\n",
       "         730: 301,\n",
       "         15939: 3,\n",
       "         6122: 17,\n",
       "         3272: 40,\n",
       "         94: 2181,\n",
       "         1159: 167,\n",
       "         793: 267,\n",
       "         4252: 28,\n",
       "         176: 1172,\n",
       "         1112: 177,\n",
       "         791: 267,\n",
       "         3520: 36,\n",
       "         2248: 66,\n",
       "         1327: 141,\n",
       "         8776: 9,\n",
       "         605: 370,\n",
       "         172: 1182,\n",
       "         1202: 158,\n",
       "         897: 232,\n",
       "         1516: 117,\n",
       "         1059: 188,\n",
       "         157: 1319,\n",
       "         ...})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_words = []\n",
    "# for x in x_train:\n",
    "#     train_words.extend(x)\n",
    "# test_words = []\n",
    "# for x in x_test:\n",
    "#     test_words.extend(x)\n",
    "# all_words = train_words\n",
    "# all_words.extend(test_words)\n",
    "# all_statistcs = Counter(all_words)\n",
    "# all_statistcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24452</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18567</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27222</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26864</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24794</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30980 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "1      11228\n",
       "53      4213\n",
       "352      647\n",
       "26      8451\n",
       "14     15015\n",
       "...      ...\n",
       "24452      1\n",
       "18567      2\n",
       "27222      1\n",
       "26864      1\n",
       "24794      1\n",
       "\n",
       "[30980 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame.from_dict(dict(all_statistcs), orient = 'index')\n",
    "# df.to_excel('./results/words_dist2.xlsx', header=False, index=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8260, 360) (2066, 360)\n"
     ]
    }
   ],
   "source": [
    "trainX = tf.keras.preprocessing.sequence.pad_sequences(x_train,maxlen=max_length,padding='post',value=0)\n",
    "testX = tf.keras.preprocessing.sequence.pad_sequences(x_test,maxlen=max_length,padding='post',value=0)\n",
    "print(trainX.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "# do = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph execution\n",
    "### Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_id = Input(shape=(max_length,), dtype='int32', name='int_ids') # 輸入的api funvtion name ID\n",
    "int_ids = Masking(mask_value=0)(int_id)\n",
    "sent_emb = Embedding(max_words, hidden_dim,input_length=max_length\n",
    "                    ,trainable=True,name='glove_emb')(int_ids) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = GRU(int(hidden_dim/2),return_sequences=True,return_state=False,name='common_extract'\n",
    "                      ,trainable=True)(sent_emb)\n",
    "rnn = BatchNormalization(name='bn')(rnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = TimeDistributed(Dense(1,activation='sigmoid',\n",
    "                             name='filter_out'),name='TD2')(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = Multiply()([fil,sent_emb])\n",
    "clf = LSTM(int(hidden_dim/2),dropout=do,recurrent_dropout=do,name='lstm')(mul)\n",
    "clf = BatchNormalization(name='bn3')(clf)\n",
    "clf = Dense(max(y_train)+1,activation='softmax',name='clf')(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "int_ids (InputLayer)            [(None, 358)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 358)          0           int_ids[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "glove_emb (Embedding)           (None, 358, 128)     1280000     masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "common_extract (GRU)            (None, 358, 64)      37248       glove_emb[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 358, 64)      256         common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "TD2 (TimeDistributed)           (None, 358, 1)       65          bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 358, 128)     0           TD2[0][0]                        \n",
      "                                                                 glove_emb[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           49408       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 64)           256         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "clf (Dense)                     (None, 46)           2990        bn3[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 1,370,223\n",
      "Trainable params: 1,369,967\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=int_id, outputs = clf)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-189e30c4af05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     return K.sum(layer.output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# kk = tf.keras.backend.ea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TD2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       self._track_trackable(\n\u001b[1;32m    294\u001b[0m           self.optimizer, name='optimizer', overwrite=True)\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weight_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \"\"\"\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_bool_casting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m       \u001b[0;31m# Default: V1-style Graph execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"using a `tf.Tensor` as a Python `bool`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_in_graph_mode\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    521\u001b[0m     raise errors.OperatorNotAllowedInGraphError(\n\u001b[1;32m    522\u001b[0m         \u001b[0;34m\"{} is not allowed in Graph execution. Use Eager execution or decorate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \" this function with @tf.function.\".format(task))\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
     ]
    }
   ],
   "source": [
    "# loss\n",
    "import keras.backend as K\n",
    "def custom_objective(layer):\n",
    "    return K.sum(layer.output)\n",
    "#     return K.sum(layer.output)\n",
    "# kk = tf.keras.backend.ea\n",
    "model.compile(loss=custom_objective(model.get_layer(name='TD2')),optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole model\n",
    "do = 0\n",
    "init = tensorflow.keras.initializers.Ones()\n",
    "class base_model(Model):\n",
    "    def __init__(self):\n",
    "        super(base_model, self).__init__()\n",
    "        self.mask = Masking(mask_value=0)\n",
    "        self.emb = Embedding(max_words, hidden_dim,input_length=max_length\n",
    "                    ,trainable=True,name='glove_emb')\n",
    "        self.rnn1 = GRU(int(hidden_dim/2),return_sequences=True,return_state=False,name='common_extract'\n",
    "                      ,trainable=True)\n",
    "        self.bn1 = BatchNormalization(name='bn1')\n",
    "        self.fil = Dense(1,activation='hard_sigmoid',kernel_initializer=init,bias_initializer=init,name='filter_out')\n",
    "        #self.fil = TimeDistributed(Dense(1,activation='sigmoid', name='filter_out'),name='TD2')\n",
    "        self.mul = Multiply()\n",
    "        self.rnn2 = Bidirectional(GRU(int(hidden_dim/2),dropout=do,recurrent_dropout=do,name='lstm'))\n",
    "        self.rnn3 = LSTM(int(hidden_dim/2))\n",
    "        self.bn2 = BatchNormalization(name='bn2')\n",
    "        self.out = Dense(max(y_train)+1,activation='softmax',name='clf')\n",
    "    def transform(self,x):\n",
    "        return tf.math.round(x)\n",
    "    def call(self,x):\n",
    "        x = self.mask(x)\n",
    "        x1 = self.emb(x)\n",
    "        x = self.rnn1(x1)\n",
    "        x = self.bn1(x)\n",
    "        y = self.fil(x)\n",
    "        y1 = self.transform(y)\n",
    "        x2 = self.mul([y1,x1])\n",
    "        x = self.rnn2(x2) #x\n",
    "        x = self.bn2(x)\n",
    "        y2 = self.out(x)\n",
    "        return y,y1,y2\n",
    "        #return y,y1,y2,x2\n",
    "        \n",
    "model = base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).att\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).emb.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).fil.layer.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).fil.layer.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "# partial1 model\n",
    "init_w = tensorflow.keras.initializers.Constant(value=2.0) #portyion=0.6, w=0.9, b = 0.8-0.85 (0.83從0開始)\n",
    "init_b = tensorflow.keras.initializers.Constant(value=2.0) #w=1 ; b=0.499, portion=1\n",
    "def onezero(x):\n",
    "    portion = 1.0#0.6#0.6 #0.6~1\n",
    "    z = tf.where(x>=1.0, x - x + 1.0, x)\n",
    "    y = tf.where(z<=0.0, z - z + 0.0, portion*z)\n",
    "    return y\n",
    "\n",
    "class base_model_1(Model):\n",
    "    def __init__(self):\n",
    "        super(base_model_1, self).__init__()\n",
    "        self.mask = Masking(mask_value=0)\n",
    "        self.emb = Embedding(max_words, hidden_dim,input_length=max_length\n",
    "                    ,trainable=True,name='glove_emb')\n",
    "        self.rnn1 = GRU(int(hidden_dim/4),return_sequences=True,return_state=False,name='common_extract'\n",
    "                      ,trainable=True)\n",
    "        #self.att = Attention(name='selfatt')\n",
    "        self.bn1 = BatchNormalization(name='bn1')\n",
    "        #self.fil = Dense(1,activation=onezero,name='filter_out')\n",
    "        self.fil = TimeDistributed(Dense(1,activation=onezero,kernel_initializer=init_w,bias_initializer=init_b, name='filter_out'),name='TD2') #relu/linear/step function\n",
    "\n",
    "    def call(self,x):\n",
    "        x = self.mask(x)\n",
    "        x1 = self.emb(x)\n",
    "        #x = self.att([x1,x1])\n",
    "        x = self.rnn1(x1)\n",
    "        x = self.bn1(x)\n",
    "        y = self.fil(x)\n",
    "        return x1,y\n",
    "\n",
    "model1 = base_model_1()\n",
    "#phase2\n",
    "# model3 = load_model(saveP)\n",
    "\n",
    "model3 = base_model_1()\n",
    "model3.load_weights('./model/2019110501/model1')#,by_name=True)\n",
    "model1.emb.set_weights(model3.emb.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial2 model\n",
    "class base_model_2(Model):\n",
    "    def __init__(self):\n",
    "        super(base_model_2, self).__init__()\n",
    "        self.mul = Multiply()\n",
    "        self.rnn2 = Bidirectional(GRU(int(hidden_dim/2),dropout=do,recurrent_dropout=do,name='lstm'))\n",
    "        self.rnn3 = GRU(int(hidden_dim/2))\n",
    "        self.bn2 = BatchNormalization(name='bn2')\n",
    "        self.out = Dense(max(y_train)+1,activation='softmax',name='clf')\n",
    "\n",
    "    def call(self,x1,y1):\n",
    "        x2 = self.mul([y1,x1])\n",
    "        x = self.rnn3(x2) #x2 #y1=weight|binary\n",
    "        x = self.bn2(x)\n",
    "        y2 = self.out(x)\n",
    "        return y2\n",
    "    \n",
    "model2 = base_model_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5770753, shape=(32, 4), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# TEST\n",
    "x = tf.random.uniform((32, 6))\n",
    "out1,out2 = model1(x)\n",
    "out2 = tf.squeeze(out2,axis=-1)\n",
    "# out2 = out2.astype('float32')\n",
    "# out2 = tf.dtypes.cast(out2, tf.float8)\n",
    "# print(out2.shape)\n",
    "yy = tf.matmul(out2,kk)\n",
    "print(yy[0].shape)\n",
    "tf.where(yy[0]==0,1,0)\n",
    "\n",
    "gg = tf.range(-5,5)\n",
    "gg = tf.expand_dims(gg,axis=0)\n",
    "gg = tf.keras.backend.repeat_elements(gg,rep=32,axis=0)\n",
    "tf.where(gg==1,gg,0)\n",
    "\n",
    "kk = tf.Variable(np.array([[1.0,1.0,1.0,0.0,0.0,0.0],[0.0,1.0,1.0,1.0,0.0,0.0],[0.0,0.0,1.0,1.0,1.0,0.0],\n",
    "                           [0.0,0.0,0.0,1.0,1.0,1.0]]).T,dtype='float32')\n",
    "kk = tf.expand_dims(kk,axis=0)\n",
    "kk = tf.keras.backend.repeat_elements(kk,rep=1,axis=0)\n",
    "kk.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "記得要跑到一個好的data\n",
    "# batch_size = 128 #,reshuffle_each_iteration=True\n",
    "# train_ds = tf.data.Dataset.from_tensor_slices((trainX,y_train)).shuffle(trainX.shape[0]).batch(batch_size)\n",
    "# valid_ds = tf.data.Dataset.from_tensor_slices((testX,y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=12571214, shape=(1, 360, 359), dtype=float32, numpy=\n",
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 960,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_num = 2 #連續幾個才叫做連續，要改modify_idx看有幾個\n",
    "\n",
    "arr_len = max_length - seq_num + 1\n",
    "seq_arr = []\n",
    "for i in range(arr_len):\n",
    "    ori_np = np.array([0]*max_length)\n",
    "    modify_idx = [i,i+1] #要跟著seq_num改\n",
    "    ori_np[modify_idx]=1\n",
    "    seq_arr.append(ori_np)\n",
    "seq_arr = np.array(seq_arr)\n",
    "seq_mask = tf.Variable(seq_arr.T,dtype='float32')\n",
    "seq_mask = tf.expand_dims(seq_mask,axis=0)\n",
    "seq_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_object1(predictions): #filter loss\n",
    "    mask = tf.math.logical_not(tf.math.equal(predictions, 0))\n",
    "    loss_ = tf.reduce_mean(predictions)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "def one_percentage(predictions): #1 num\n",
    "    mask = tf.math.logical_not(tf.math.equal(predictions, 0))\n",
    "    loss_ = tf.reduce_mean(predictions)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "def seq_loss(predictions):\n",
    "    mask = tf.math.logical_not(tf.math.equal(predictions, 0))\n",
    "    predictions = tf.squeeze(predictions,axis=-1)\n",
    "    results = tf.matmul(predictions,seq_mask)\n",
    "    results = tf.where(results==seq_num,1.0,0.0)\n",
    "    loss_ = tf.reduce_mean(results)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "loss_object2 = tf.keras.losses.SparseCategoricalCrossentropy() #clf loss\n",
    "\n",
    "optimizer1 = tf.keras.optimizers.RMSprop()\n",
    "optimizer2 = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss') #total_loss\n",
    "train_accloss = tf.keras.metrics.Mean(name='train_accloss')#loss_acc\n",
    "train_filloss = tf.keras.metrics.Mean(name='train_filloss') #loss_filter\n",
    "train_seqloss = tf.keras.metrics.Mean(name='train_seqloss') #loss_seq\n",
    "train_ones = tf.keras.metrics.Mean(name='train_ones') #ones_num\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy') #acc_rate\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss') #total_loss\n",
    "test_accloss = tf.keras.metrics.Mean(name='test_accloss')#loss_acc\n",
    "test_filloss = tf.keras.metrics.Mean(name='test_filloss') #loss_filter\n",
    "test_seqloss = tf.keras.metrics.Mean(name='test_seqloss')\n",
    "test_ones = tf.keras.metrics.Mean(name='test_ones') #ones_num\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate partial model\n",
    "alpha = 0.00001 #pahse1: -0.1 / 0.0 ; phase2: 0.01~0.05~0.1 有1-就是希望1越多，沒1-就是希望0越多1越少\n",
    "beta = 1.0 #clf loss 越大越要求分好\n",
    "gamma = 0.0 #seqloss 越大越要求連續\n",
    "#-0.001 / 1.0 / 1.0\n",
    "\n",
    "@tf.function\n",
    "def train_step(x,yc):\n",
    "    with tf.GradientTape(persistent=False) as tape:\n",
    "        emb, pred_imp = model1(x)\n",
    "        #loss1 = alpha*loss_object1(pred_imp) #phase1\n",
    "        #pred_imp2 = tf.math.round(pred_imp)\n",
    "        #pred_imp3 = tf.clip_by_value(pred_imp,clip_value_max=1,clip_value_min=0)\n",
    "        pred_imp2 = tf.math.round(pred_imp)\n",
    "        loss1 = loss_object1(pred_imp) #有1-就是希望1越多，沒1-就是希望0越多1越少 #pahse2:alpha*loss_object1(pred_imp) ; phase1: alpha*(1-loss_object1(pred_imp))\n",
    "        pred_cat = model2(emb,pred_imp2) #pahse1: pred_imp; phase2; pred_imp2\n",
    "        loss2 = loss_object2(yc, pred_cat)\n",
    "        loss3 = 1-seq_loss(pred_imp2)\n",
    "        loss = alpha*loss1 + beta*loss2 + gamma*loss3\n",
    "    trainable_variable = model1.trainable_variables\n",
    "    trainable_variable.extend(model2.trainable_variables)\n",
    "    gradients = tape.gradient(loss,trainable_variable)\n",
    "    optimizer1.apply_gradients(zip(gradients,trainable_variable))\n",
    "    \n",
    "    train_loss(loss) #total_loss\n",
    "    train_filloss(loss1)\n",
    "    train_accloss(loss2)\n",
    "    train_seqloss(loss3) #loss_seq\n",
    "    train_accuracy(yc, pred_cat) #acc_rate\n",
    "    ones = one_percentage(pred_imp2) #pred_imp2\n",
    "    train_ones(ones) #ones_num\n",
    "    \n",
    "    \n",
    "@tf.function\n",
    "def test_step(x,yc):\n",
    "    emb, pred_imp = model1(x)\n",
    "    #loss1 = alpha*loss_object1(pred_imp) #phase1\n",
    "    #pred_imp2 = tf.math.round(pred_imp)\n",
    "    #pred_imp3 = tf.clip_by_value(pred_imp,clip_value_max=1,clip_value_min=0)\n",
    "    pred_imp2 = tf.math.round(pred_imp)\n",
    "    loss1 = loss_object1(pred_imp) #phase2\n",
    "    pred_cat = model2(emb,pred_imp2) #phase1: pred_imp ; phase2:pred_imp2\n",
    "    loss2 = loss_object2(yc, pred_cat)\n",
    "    loss3 = 1-seq_loss(pred_imp2)\n",
    "    #t_loss = loss1 + loss2\n",
    "    t_loss = alpha*loss1 + beta*loss2 + gamma*loss3\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_filloss(loss1)\n",
    "    test_accloss(loss2)\n",
    "    test_seqloss(loss3)\n",
    "    test_accuracy(yc, pred_cat)\n",
    "    t_ones = one_percentage(pred_imp2) #pred_imp2\n",
    "    test_ones(t_ones)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#AIO\n",
    "alpha = 0.1\n",
    "beta = 1\n",
    "gamma = 0\n",
    "@tf.function\n",
    "def train_step(x,yc):\n",
    "    with tf.GradientTape(persistent=True) as tape: #persistent=True\n",
    "        pred_imp,pred_round , pred_cat = model(x)\n",
    "#         pred_cat = model(x)\n",
    "#         loss = alpha*loss_object1(pred_imp) + loss_object2(yc,pred_cat)\n",
    "        loss1 = alpha*loss_object1(pred_imp)\n",
    "        loss2 = beta*loss_object2(yc,pred_cat)\n",
    "        loss = loss_object2(yc,pred_cat)\n",
    "#     gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    grad1 = tape.gradient(loss1, model.trainable_variables)\n",
    "    grad2 = tape.gradient(loss2, model.trainable_variables)\n",
    "#     optimizer1.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    optimizer1.apply_gradients(zip(grad1, model.trainable_variables))\n",
    "    optimizer2.apply_gradients(zip(grad2, model.trainable_variables))\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         pred_imp , pred_cat = model(x)\n",
    "#         loss2 = loss_object2(yc,pred_cat)\n",
    "#         loss = alpha*loss_object1(pred_imp) + loss_object2(yc,pred_cat)\n",
    "#     grad2 = tape.gradient(loss2, model.trainable_variables)\n",
    "#     optimizer2.apply_gradients(zip(grad2, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(yc, pred_cat)\n",
    "    ones = one_percentage(pred_round)\n",
    "    train_ones(ones)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(x,yc):\n",
    "    pred_imp,pred_round, pred_cat = model(x)\n",
    "#     pred_cat = model(x)\n",
    "    t_loss = alpha*loss_object1(pred_imp) + loss_object2(yc,pred_cat) \n",
    "#     t_loss = loss_object2(yc,pred_cat)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(yc, pred_cat)\n",
    "    t_ones = one_percentage(pred_round)\n",
    "    test_ones(t_ones)\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Total Loss: 2.5168564319610596, Clf Loss: 2.516845703125, Filter Loss: 1.0, Seq Loss: 0.0, Accuracy Rate: 36.89%, Ones Portion: 1.0,             Test_Total_Loss: 2.407064437866211, Test_Clf_Loss: 2.4070541858673096, Test_Filter_Loss: 1.0, TEST_Seq_Loss: 0.0, Test_Accuracy_Rate: 22.41%, Test_Ones_Portion: 1.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110801/model1 ./model/2019110801/model2\n",
      "Epoch 2, Total Loss: 2.330303907394409, Clf Loss: 2.3302934169769287, Filter Loss: 1.0, Seq Loss: 0.0, Accuracy Rate: 37.45%, Ones Portion: 1.0,             Test_Total_Loss: 2.2936646938323975, Test_Clf_Loss: 2.2936549186706543, Test_Filter_Loss: 1.0, TEST_Seq_Loss: 0.0, Test_Accuracy_Rate: 48.84%, Test_Ones_Portion: 1.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110801/model1 ./model/2019110801/model2\n",
      "Epoch 3, Total Loss: 2.0387141704559326, Clf Loss: 2.0387041568756104, Filter Loss: 1.0, Seq Loss: 0.0, Accuracy Rate: 49.93%, Ones Portion: 1.0,             Test_Total_Loss: 1.9128453731536865, Test_Clf_Loss: 1.9128352403640747, Test_Filter_Loss: 1.0, TEST_Seq_Loss: 0.0, Test_Accuracy_Rate: 55.13%, Test_Ones_Portion: 1.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110801/model1 ./model/2019110801/model2\n",
      "Epoch 4, Total Loss: 1.8714076280593872, Clf Loss: 1.8713968992233276, Filter Loss: 1.0, Seq Loss: 0.0, Accuracy Rate: 55.22%, Ones Portion: 1.0,             Test_Total_Loss: 1.8683606386184692, Test_Clf_Loss: 1.8683505058288574, Test_Filter_Loss: 1.0, TEST_Seq_Loss: 0.0, Test_Accuracy_Rate: 55.52%, Test_Ones_Portion: 1.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110801/model1 ./model/2019110801/model2\n",
      "Epoch 5, Total Loss: 1.8327966928482056, Clf Loss: 1.8327869176864624, Filter Loss: 1.0, Seq Loss: 0.0, Accuracy Rate: 54.59%, Ones Portion: 1.0,             Test_Total_Loss: 1.8587230443954468, Test_Clf_Loss: 1.8587130308151245, Test_Filter_Loss: 1.0, TEST_Seq_Loss: 0.0, Test_Accuracy_Rate: 51.26%, Test_Ones_Portion: 1.0\n",
      "Epoch 6, Total Loss: 1.7556746006011963, Clf Loss: 1.7556644678115845, Filter Loss: 1.0, Seq Loss: 0.0, Accuracy Rate: 55.21%, Ones Portion: 1.0,             Test_Total_Loss: 1.8013681173324585, Test_Clf_Loss: 1.8013582229614258, Test_Filter_Loss: 1.0, TEST_Seq_Loss: 0.0, Test_Accuracy_Rate: 55.95%, Test_Ones_Portion: 1.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110801/model1 ./model/2019110801/model2\n",
      "Epoch 7, Total Loss: 1.6794475317001343, Clf Loss: 1.679437279701233, Filter Loss: 1.0, Seq Loss: 0.0, Accuracy Rate: 57.48%, Ones Portion: 1.0,             Test_Total_Loss: 1.7183945178985596, Test_Clf_Loss: 1.7183847427368164, Test_Filter_Loss: 1.0, TEST_Seq_Loss: 0.0, Test_Accuracy_Rate: 57.99%, Test_Ones_Portion: 1.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110801/model1 ./model/2019110801/model2\n",
      "Epoch 8, Total Loss: 1.6238362789154053, Clf Loss: 1.623826265335083, Filter Loss: 1.0, Seq Loss: 0.0, Accuracy Rate: 59.12%, Ones Portion: 1.0,             Test_Total_Loss: 1.6880650520324707, Test_Clf_Loss: 1.6880552768707275, Test_Filter_Loss: 1.0, TEST_Seq_Loss: 0.0, Test_Accuracy_Rate: 58.08%, Test_Ones_Portion: 1.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110801/model1 ./model/2019110801/model2\n",
      "Epoch 9, Total Loss: 1.579904317855835, Clf Loss: 1.5798943042755127, Filter Loss: 1.0, Seq Loss: 0.0, Accuracy Rate: 60.11%, Ones Portion: 1.0,             Test_Total_Loss: 1.6774452924728394, Test_Clf_Loss: 1.6774351596832275, Test_Filter_Loss: 1.0, TEST_Seq_Loss: 0.0, Test_Accuracy_Rate: 58.23%, Test_Ones_Portion: 1.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110801/model1 ./model/2019110801/model2\n",
      "Epoch 10, Total Loss: 1.5312645435333252, Clf Loss: 1.5312546491622925, Filter Loss: 1.0, Seq Loss: 0.0, Accuracy Rate: 61.36%, Ones Portion: 1.0,             Test_Total_Loss: 1.7248200178146362, Test_Clf_Loss: 1.7248098850250244, Test_Filter_Loss: 1.0, TEST_Seq_Loss: 0.0, Test_Accuracy_Rate: 58.95%, Test_Ones_Portion: 1.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110801/model1 ./model/2019110801/model2\n",
      "Epoch 11, Total Loss: 1.5027718544006348, Clf Loss: 1.5027616024017334, Filter Loss: 1.0, Seq Loss: 0.0, Accuracy Rate: 62.63%, Ones Portion: 1.0,             Test_Total_Loss: 1.637414813041687, Test_Clf_Loss: 1.6374046802520752, Test_Filter_Loss: 1.0, TEST_Seq_Loss: 0.0, Test_Accuracy_Rate: 60.12%, Test_Ones_Portion: 1.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110801/model1 ./model/2019110801/model2\n",
      "Epoch 12, Total Loss: 1.4638378620147705, Clf Loss: 1.4638276100158691, Filter Loss: 1.0, Seq Loss: 0.0, Accuracy Rate: 63.61%, Ones Portion: 1.0,             Test_Total_Loss: 1.6029236316680908, Test_Clf_Loss: 1.6029136180877686, Test_Filter_Loss: 1.0, TEST_Seq_Loss: 0.0, Test_Accuracy_Rate: 60.50%, Test_Ones_Portion: 1.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110801/model1 ./model/2019110801/model2\n",
      "Epoch 13, Total Loss: 1.483351230621338, Clf Loss: 1.4833420515060425, Filter Loss: 0.943634569644928, Seq Loss: 0.056336138397455215, Accuracy Rate: 63.34%, Ones Portion: 0.943840742111206,             Test_Total_Loss: 2.3582377433776855, Test_Clf_Loss: 2.35823655128479, Test_Filter_Loss: 0.09056267887353897, TEST_Seq_Loss: 0.9133503437042236, Test_Accuracy_Rate: 55.42%, Test_Ones_Portion: 0.0893368199467659\n",
      "Epoch 14, Total Loss: 2.2550482749938965, Clf Loss: 2.2550480365753174, Filter Loss: 0.017139052972197533, Seq Loss: 0.9877039790153503, Accuracy Rate: 41.82%, Ones Portion: 0.013654375448822975,             Test_Total_Loss: 2.2370574474334717, Test_Clf_Loss: 2.2370574474334717, Test_Filter_Loss: 0.00035921623930335045, TEST_Seq_Loss: 0.9999364018440247, Test_Accuracy_Rate: 37.42%, Test_Ones_Portion: 0.00013342108286451548\n",
      "Epoch 15, Total Loss: 2.227822780609131, Clf Loss: 2.227822780609131, Filter Loss: 0.00017328040848951787, Seq Loss: 0.9999675750732422, Accuracy Rate: 38.17%, Ones Portion: 7.526553963543847e-05,             Test_Total_Loss: 2.3593814373016357, Test_Clf_Loss: 2.3593814373016357, Test_Filter_Loss: 0.0001022232900140807, TEST_Seq_Loss: 0.9999805688858032, Test_Accuracy_Rate: 36.45%, Test_Ones_Portion: 4.937300764140673e-05\n",
      "Epoch 16, Total Loss: 2.162421226501465, Clf Loss: 2.162421226501465, Filter Loss: 7.582806574646384e-05, Seq Loss: 0.9999867081642151, Accuracy Rate: 39.58%, Ones Portion: 3.614245724747889e-05,             Test_Total_Loss: 2.1308839321136475, Test_Clf_Loss: 2.1308839321136475, Test_Filter_Loss: 6.505088094854727e-05, TEST_Seq_Loss: 0.9999896883964539, Test_Accuracy_Rate: 39.98%, Test_Ones_Portion: 2.9616283427458256e-05\n",
      "Epoch 17, Total Loss: 2.139455795288086, Clf Loss: 2.139455795288086, Filter Loss: 5.184590918361209e-05, Seq Loss: 0.9999927282333374, Accuracy Rate: 40.04%, Ones Portion: 2.2988353521213867e-05,             Test_Total_Loss: 2.1529452800750732, Test_Clf_Loss: 2.1529452800750732, Test_Filter_Loss: 4.6727545850444585e-05, TEST_Seq_Loss: 0.9999937415122986, Test_Accuracy_Rate: 40.17%, Test_Ones_Portion: 1.963368777069263e-05\n",
      "Epoch 18, Total Loss: 2.0920462608337402, Clf Loss: 2.0920462608337402, Filter Loss: 4.008820906165056e-05, Seq Loss: 0.9999950528144836, Accuracy Rate: 40.98%, Ones Portion: 1.7220276276930235e-05,             Test_Total_Loss: 2.0876259803771973, Test_Clf_Loss: 2.0876259803771973, Test_Filter_Loss: 3.911812382284552e-05, TEST_Seq_Loss: 0.9999949336051941, Test_Accuracy_Rate: 40.42%, Test_Ones_Portion: 1.6428421076852828e-05\n",
      "Epoch 19, Total Loss: 2.0727827548980713, Clf Loss: 2.0727827548980713, Filter Loss: 3.3532418456161395e-05, Seq Loss: 0.9999954104423523, Accuracy Rate: 41.42%, Ones Portion: 1.4964382899051998e-05,             Test_Total_Loss: 2.1021459102630615, Test_Clf_Loss: 2.1021459102630615, Test_Filter_Loss: 3.269187072874047e-05, TEST_Seq_Loss: 0.9999954104423523, Test_Accuracy_Rate: 40.32%, Test_Ones_Portion: 1.4233520232664887e-05\n",
      "Epoch 20, Total Loss: 2.0691733360290527, Clf Loss: 2.0691733360290527, Filter Loss: 2.9803000870742835e-05, Seq Loss: 0.9999958872795105, Accuracy Rate: 41.56%, Ones Portion: 1.3002749255974777e-05,             Test_Total_Loss: 2.12054705619812, Test_Clf_Loss: 2.12054705619812, Test_Filter_Loss: 3.0508630516123958e-05, TEST_Seq_Loss: 0.9999956488609314, Test_Accuracy_Rate: 40.27%, Test_Ones_Portion: 1.2724013686238322e-05\n",
      "Epoch 21, Total Loss: 2.0676465034484863, Clf Loss: 2.0676465034484863, Filter Loss: 2.564762507972773e-05, Seq Loss: 0.9999967217445374, Accuracy Rate: 41.09%, Ones Portion: 1.0250458217342384e-05,             Test_Total_Loss: 2.147493600845337, Test_Clf_Loss: 2.147493600845337, Test_Filter_Loss: 2.4448369003948756e-05, TEST_Seq_Loss: 0.9999964237213135, Test_Accuracy_Rate: 40.56%, Test_Ones_Portion: 1.051497474691132e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Total Loss: 2.068540096282959, Clf Loss: 2.068540096282959, Filter Loss: 2.0950203179381788e-05, Seq Loss: 0.9999971985816956, Accuracy Rate: 41.38%, Ones Portion: 8.210616215365008e-06,             Test_Total_Loss: 2.130150318145752, Test_Clf_Loss: 2.130150318145752, Test_Filter_Loss: 2.0399251297931187e-05, TEST_Seq_Loss: 0.999997079372406, Test_Accuracy_Rate: 39.98%, Test_Ones_Portion: 8.517554306308739e-06\n",
      "Epoch 23, Total Loss: 2.0676822662353516, Clf Loss: 2.0676822662353516, Filter Loss: 1.7593471056898125e-05, Seq Loss: 0.9999977946281433, Accuracy Rate: 41.50%, Ones Portion: 6.9800662458874285e-06,             Test_Total_Loss: 2.0957794189453125, Test_Clf_Loss: 2.0957794189453125, Test_Filter_Loss: 1.6593950931564905e-05, TEST_Seq_Loss: 0.999997615814209, Test_Accuracy_Rate: 40.66%, Test_Ones_Portion: 7.110312708391575e-06\n",
      "Epoch 24, Total Loss: 2.063262701034546, Clf Loss: 2.063262701034546, Filter Loss: 1.3776911146123894e-05, Seq Loss: 0.9999983310699463, Accuracy Rate: 41.73%, Ones Portion: 5.36806737727602e-06,             Test_Total_Loss: 2.074883460998535, Test_Clf_Loss: 2.074883460998535, Test_Filter_Loss: 1.4036142601980828e-05, TEST_Seq_Loss: 0.9999978542327881, Test_Accuracy_Rate: 41.05%, Test_Ones_Portion: 5.934472028457094e-06\n",
      "Epoch 25, Total Loss: 2.0523152351379395, Clf Loss: 2.0523152351379395, Filter Loss: 1.1452541912149172e-05, Seq Loss: 0.9999988079071045, Accuracy Rate: 41.85%, Ones Portion: 4.35289075539913e-06,             Test_Total_Loss: 2.0892510414123535, Test_Clf_Loss: 2.0892510414123535, Test_Filter_Loss: 1.1499670108605642e-05, TEST_Seq_Loss: 0.9999983310699463, Test_Accuracy_Rate: 41.29%, Test_Ones_Portion: 4.961099875799846e-06\n",
      "Epoch 26, Total Loss: 2.0583224296569824, Clf Loss: 2.0583224296569824, Filter Loss: 9.253707503376063e-06, Seq Loss: 0.9999991655349731, Accuracy Rate: 42.62%, Ones Portion: 3.5011189538636245e-06,             Test_Total_Loss: 2.0893688201904297, Test_Clf_Loss: 2.0893688201904297, Test_Filter_Loss: 9.66338029684266e-06, TEST_Seq_Loss: 0.9999986290931702, Test_Accuracy_Rate: 27.30%, Test_Ones_Portion: 4.067205736646429e-06\n",
      "Epoch 27, Total Loss: 2.0446248054504395, Clf Loss: 2.0446248054504395, Filter Loss: 7.86360033089295e-06, Seq Loss: 0.9999992847442627, Accuracy Rate: 42.76%, Ones Portion: 3.0416670142585644e-06,             Test_Total_Loss: 2.056518077850342, Test_Clf_Loss: 2.056518077850342, Test_Filter_Loss: 8.376959158340469e-06, TEST_Seq_Loss: 0.9999987483024597, Test_Accuracy_Rate: 41.97%, Test_Ones_Portion: 3.6599449231289327e-06\n",
      "Epoch 28, Total Loss: 2.0471246242523193, Clf Loss: 2.0471246242523193, Filter Loss: 6.359986400639173e-06, Seq Loss: 0.9999995231628418, Accuracy Rate: 43.09%, Ones Portion: 2.563419457146665e-06,             Test_Total_Loss: 2.0660717487335205, Test_Clf_Loss: 2.0660717487335205, Test_Filter_Loss: 7.113173069228651e-06, TEST_Seq_Loss: 0.9999988675117493, Test_Accuracy_Rate: 42.01%, Test_Ones_Portion: 3.1986239719117293e-06\n",
      "Epoch 29, Total Loss: 2.0988047122955322, Clf Loss: 2.0988047122955322, Filter Loss: 5.527356279344531e-06, Seq Loss: 0.9999995231628418, Accuracy Rate: 42.46%, Ones Portion: 2.262535417685285e-06,             Test_Total_Loss: 2.058744430541992, Test_Clf_Loss: 2.058744430541992, Test_Filter_Loss: 6.325728463707492e-06, TEST_Seq_Loss: 0.9999991059303284, Test_Accuracy_Rate: 42.11%, Test_Ones_Portion: 2.721206556088873e-06\n",
      "Epoch 30, Total Loss: 2.043585777282715, Clf Loss: 2.043585777282715, Filter Loss: 5.006585070077563e-06, Seq Loss: 0.9999996423721313, Accuracy Rate: 43.12%, Ones Portion: 2.0459399365790887e-06,             Test_Total_Loss: 2.070530652999878, Test_Clf_Loss: 2.070530652999878, Test_Filter_Loss: 5.866880655958084e-06, TEST_Seq_Loss: 0.9999991059303284, Test_Accuracy_Rate: 42.11%, Test_Ones_Portion: 2.540361492719967e-06\n",
      "Epoch 31, Total Loss: 2.0421292781829834, Clf Loss: 2.0421292781829834, Filter Loss: 4.439029908098746e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 43.39%, Ones Portion: 1.8288898218088434e-06,             Test_Total_Loss: 2.0697691440582275, Test_Clf_Loss: 2.0697691440582275, Test_Filter_Loss: 5.271720510791056e-06, TEST_Seq_Loss: 0.9999991059303284, Test_Accuracy_Rate: 42.40%, Test_Ones_Portion: 2.3108975710783852e-06\n",
      "Epoch 32, Total Loss: 2.037691831588745, Clf Loss: 2.037691831588745, Filter Loss: 4.090319180249935e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 43.67%, Ones Portion: 1.6624416048216517e-06,             Test_Total_Loss: 2.049711227416992, Test_Clf_Loss: 2.049711227416992, Test_Filter_Loss: 5.159412012289977e-06, TEST_Seq_Loss: 0.9999991059303284, Test_Accuracy_Rate: 42.50%, Test_Ones_Portion: 2.269010792588233e-06\n",
      "Epoch 33, Total Loss: 2.030419111251831, Clf Loss: 2.030419111251831, Filter Loss: 4.274592356523499e-06, Seq Loss: 0.9999996423721313, Accuracy Rate: 43.80%, Ones Portion: 1.7767642930266447e-06,             Test_Total_Loss: 2.0391464233398438, Test_Clf_Loss: 2.0391464233398438, Test_Filter_Loss: 5.076786692370661e-06, TEST_Seq_Loss: 0.9999991059303284, Test_Accuracy_Rate: 42.74%, Test_Ones_Portion: 2.2734709546057275e-06\n",
      "Epoch 34, Total Loss: 2.0252959728240967, Clf Loss: 2.0252959728240967, Filter Loss: 3.822554845100967e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 43.97%, Ones Portion: 1.6354640592908254e-06,             Test_Total_Loss: 2.084010601043701, Test_Clf_Loss: 2.084010601043701, Test_Filter_Loss: 4.8715182856540196e-06, TEST_Seq_Loss: 0.9999992251396179, Test_Accuracy_Rate: 42.21%, Test_Ones_Portion: 2.1825533167429967e-06\n",
      "Epoch 35, Total Loss: 2.0241317749023438, Clf Loss: 2.0241317749023438, Filter Loss: 4.01282932216418e-06, Seq Loss: 0.9999996423721313, Accuracy Rate: 43.93%, Ones Portion: 1.7355386034978437e-06,             Test_Total_Loss: 2.0773379802703857, Test_Clf_Loss: 2.0773379802703857, Test_Filter_Loss: 4.822513801627792e-06, TEST_Seq_Loss: 0.9999992251396179, Test_Accuracy_Rate: 42.30%, Test_Ones_Portion: 2.1862929315830115e-06\n",
      "Epoch 36, Total Loss: 2.0186259746551514, Clf Loss: 2.0186259746551514, Filter Loss: 3.8120838325994555e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.03%, Ones Portion: 1.6472979496029438e-06,             Test_Total_Loss: 2.0482282638549805, Test_Clf_Loss: 2.0482282638549805, Test_Filter_Loss: 4.735816219181288e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.37%, Test_Ones_Portion: 2.1731618744524894e-06\n",
      "Epoch 37, Total Loss: 2.011916160583496, Clf Loss: 2.011916160583496, Filter Loss: 3.6864048524876125e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.09%, Ones Portion: 1.640618847886799e-06,             Test_Total_Loss: 2.0512475967407227, Test_Clf_Loss: 2.0512475967407227, Test_Filter_Loss: 4.578138032229617e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.13%, Test_Ones_Portion: 2.0332968233560678e-06\n",
      "Epoch 38, Total Loss: 2.015681743621826, Clf Loss: 2.015681743621826, Filter Loss: 3.71310989066842e-06, Seq Loss: 0.9999995231628418, Accuracy Rate: 44.01%, Ones Portion: 1.6374724509660155e-06,             Test_Total_Loss: 2.0344297885894775, Test_Clf_Loss: 2.0344297885894775, Test_Filter_Loss: 4.574248578137485e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.27%, Test_Ones_Portion: 2.0327427137090126e-06\n",
      "Epoch 39, Total Loss: 2.015942096710205, Clf Loss: 2.015942096710205, Filter Loss: 3.4318800317123532e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 43.97%, Ones Portion: 1.468044956709491e-06,             Test_Total_Loss: 2.0287837982177734, Test_Clf_Loss: 2.0287837982177734, Test_Filter_Loss: 4.327238457335625e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.37%, Test_Ones_Portion: 1.9620556486188434e-06\n",
      "Epoch 40, Total Loss: 2.0097503662109375, Clf Loss: 2.0097503662109375, Filter Loss: 3.558154958227533e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.19%, Ones Portion: 1.5789880762895336e-06,             Test_Total_Loss: 2.0217275619506836, Test_Clf_Loss: 2.0217275619506836, Test_Filter_Loss: 4.280993380234577e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.47%, Test_Ones_Portion: 1.920848490044591e-06\n",
      "Epoch 41, Total Loss: 2.008200168609619, Clf Loss: 2.008200168609619, Filter Loss: 3.3821831948444014e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.07%, Ones Portion: 1.518567046332464e-06,             Test_Total_Loss: 2.016777992248535, Test_Clf_Loss: 2.016777992248535, Test_Filter_Loss: 4.134072241868125e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.80%, Test_Ones_Portion: 1.8963499996971223e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Total Loss: 2.007746696472168, Clf Loss: 2.007746696472168, Filter Loss: 3.358519279572647e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.41%, Ones Portion: 1.5327132132370025e-06,             Test_Total_Loss: 2.0109758377075195, Test_Clf_Loss: 2.0109758377075195, Test_Filter_Loss: 3.986023784818826e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.61%, Test_Ones_Portion: 1.863438683358254e-06\n",
      "Epoch 43, Total Loss: 2.010176420211792, Clf Loss: 2.010176420211792, Filter Loss: 3.278037866039085e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.26%, Ones Portion: 1.4772714393984643e-06,             Test_Total_Loss: 2.019054651260376, Test_Clf_Loss: 2.019054651260376, Test_Filter_Loss: 3.949987785745179e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.42%, Test_Ones_Portion: 1.90824380297272e-06\n",
      "Epoch 44, Total Loss: 2.0085437297821045, Clf Loss: 2.0085437297821045, Filter Loss: 3.201583695044974e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.30%, Ones Portion: 1.4788741964366636e-06,             Test_Total_Loss: 2.0115761756896973, Test_Clf_Loss: 2.0115761756896973, Test_Filter_Loss: 3.880634267261485e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.56%, Test_Ones_Portion: 1.9011516769751324e-06\n",
      "Epoch 45, Total Loss: 2.0098066329956055, Clf Loss: 2.0098066329956055, Filter Loss: 3.1730201044410933e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.32%, Ones Portion: 1.4451287597694318e-06,             Test_Total_Loss: 2.0097062587738037, Test_Clf_Loss: 2.0097062587738037, Test_Filter_Loss: 3.947685854654992e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.76%, Test_Ones_Portion: 1.8829508690032526e-06\n",
      "Epoch 46, Total Loss: 2.0114169120788574, Clf Loss: 2.0114169120788574, Filter Loss: 3.2061707315733656e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.29%, Ones Portion: 1.4657632618764183e-06,             Test_Total_Loss: 2.010272979736328, Test_Clf_Loss: 2.010272979736328, Test_Filter_Loss: 3.9821297832531855e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.42%, Test_Ones_Portion: 1.9357100882189116e-06\n",
      "Epoch 47, Total Loss: 2.015662908554077, Clf Loss: 2.015662908554077, Filter Loss: 3.251826456107665e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.32%, Ones Portion: 1.42519309065392e-06,             Test_Total_Loss: 2.0053329467773438, Test_Clf_Loss: 2.0053329467773438, Test_Filter_Loss: 3.9763340282661375e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.42%, Test_Ones_Portion: 1.8032621937891236e-06\n",
      "Epoch 48, Total Loss: 2.02203106880188, Clf Loss: 2.02203106880188, Filter Loss: 3.2777697924757376e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.24%, Ones Portion: 1.4780091532884398e-06,             Test_Total_Loss: 2.008962631225586, Test_Clf_Loss: 2.008962631225586, Test_Filter_Loss: 3.91811090594274e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 44.00%, Test_Ones_Portion: 1.8714725911195274e-06\n",
      "Epoch 49, Total Loss: 2.0191445350646973, Clf Loss: 2.0191445350646973, Filter Loss: 3.4121419503208017e-06, Seq Loss: 0.9999996423721313, Accuracy Rate: 44.36%, Ones Portion: 1.56113026150706e-06,             Test_Total_Loss: 2.0105507373809814, Test_Clf_Loss: 2.0105507373809814, Test_Filter_Loss: 3.8843195397930685e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.71%, Test_Ones_Portion: 1.8546289766163682e-06\n",
      "Epoch 50, Total Loss: 2.0174224376678467, Clf Loss: 2.0174224376678467, Filter Loss: 3.3404005534976022e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.36%, Ones Portion: 1.5167348692557425e-06,             Test_Total_Loss: 2.0055291652679443, Test_Clf_Loss: 2.0055291652679443, Test_Filter_Loss: 3.993323389295256e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.90%, Test_Ones_Portion: 1.8991571550941444e-06\n",
      "Epoch 51, Total Loss: 2.011669635772705, Clf Loss: 2.011669635772705, Filter Loss: 3.3034916668839287e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.42%, Ones Portion: 1.4878323781886138e-06,             Test_Total_Loss: 1.9981335401535034, Test_Clf_Loss: 1.9981335401535034, Test_Filter_Loss: 4.083000021637417e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.66%, Test_Ones_Portion: 1.940517449838808e-06\n",
      "Epoch 52, Total Loss: 2.015162706375122, Clf Loss: 2.015162706375122, Filter Loss: 3.3940091270778794e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.43%, Ones Portion: 1.481785830037552e-06,             Test_Total_Loss: 2.012143611907959, Test_Clf_Loss: 2.012143611907959, Test_Filter_Loss: 4.030222953588236e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.80%, Test_Ones_Portion: 1.9251147023169324e-06\n",
      "Epoch 53, Total Loss: 2.0128824710845947, Clf Loss: 2.0128824710845947, Filter Loss: 3.3751121009117924e-06, Seq Loss: 0.9999996423721313, Accuracy Rate: 44.50%, Ones Portion: 1.5115402902665664e-06,             Test_Total_Loss: 2.0121140480041504, Test_Clf_Loss: 2.0121140480041504, Test_Filter_Loss: 3.965228643210139e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.66%, Test_Ones_Portion: 1.8977904119310551e-06\n",
      "Epoch 54, Total Loss: 2.009007215499878, Clf Loss: 2.009007215499878, Filter Loss: 3.3590772545721848e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.60%, Ones Portion: 1.560690407131915e-06,             Test_Total_Loss: 2.0097765922546387, Test_Clf_Loss: 2.0097765922546387, Test_Filter_Loss: 3.927278612536611e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.51%, Test_Ones_Portion: 1.944617906701751e-06\n",
      "Epoch 55, Total Loss: 2.012056827545166, Clf Loss: 2.012056827545166, Filter Loss: 3.2757654935267055e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.55%, Ones Portion: 1.5120821217351477e-06,             Test_Total_Loss: 2.0112497806549072, Test_Clf_Loss: 2.0112497806549072, Test_Filter_Loss: 3.958252818847541e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.71%, Test_Ones_Portion: 1.9009152083526715e-06\n",
      "Epoch 56, Total Loss: 2.008408546447754, Clf Loss: 2.008408546447754, Filter Loss: 3.263361577410251e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.56%, Ones Portion: 1.5150872059166431e-06,             Test_Total_Loss: 2.0166454315185547, Test_Clf_Loss: 2.0166454315185547, Test_Filter_Loss: 3.944696800317615e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.76%, Test_Ones_Portion: 1.84226814781141e-06\n",
      "Epoch 57, Total Loss: 2.008527994155884, Clf Loss: 2.008527994155884, Filter Loss: 3.167795057379408e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.60%, Ones Portion: 1.4708823528053472e-06,             Test_Total_Loss: 2.0072121620178223, Test_Clf_Loss: 2.0072121620178223, Test_Filter_Loss: 3.910253781214124e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.71%, Test_Ones_Portion: 1.8402182604404516e-06\n",
      "Epoch 58, Total Loss: 2.0082952976226807, Clf Loss: 2.0082952976226807, Filter Loss: 3.3048072509700432e-06, Seq Loss: 0.9999996423721313, Accuracy Rate: 44.54%, Ones Portion: 1.5563502984150546e-06,             Test_Total_Loss: 2.013427257537842, Test_Clf_Loss: 2.013427257537842, Test_Filter_Loss: 3.8348503039742354e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.56%, Test_Ones_Portion: 1.8059496369460248e-06\n",
      "Epoch 59, Total Loss: 2.008941173553467, Clf Loss: 2.008941173553467, Filter Loss: 3.185155719620525e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.55%, Ones Portion: 1.5081099036251544e-06,             Test_Total_Loss: 2.0165460109710693, Test_Clf_Loss: 2.0165460109710693, Test_Filter_Loss: 3.7897677884757286e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.42%, Test_Ones_Portion: 1.79295693669701e-06\n",
      "Epoch 60, Total Loss: 2.0098390579223633, Clf Loss: 2.0098390579223633, Filter Loss: 3.312140279376763e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.67%, Ones Portion: 1.5792049907759065e-06,             Test_Total_Loss: 2.008835554122925, Test_Clf_Loss: 2.008835554122925, Test_Filter_Loss: 3.848487267532619e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.56%, Test_Ones_Portion: 1.8389717979516718e-06\n",
      "Epoch 61, Total Loss: 2.0051839351654053, Clf Loss: 2.0051839351654053, Filter Loss: 3.4076781503245e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.58%, Ones Portion: 1.5981551086952095e-06,             Test_Total_Loss: 2.0013813972473145, Test_Clf_Loss: 2.0013813972473145, Test_Filter_Loss: 3.907174686901271e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.61%, Test_Ones_Portion: 1.870829919425887e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Total Loss: 2.006505012512207, Clf Loss: 2.006505012512207, Filter Loss: 3.4911086004285607e-06, Seq Loss: 0.9999996423721313, Accuracy Rate: 44.62%, Ones Portion: 1.638032131268119e-06,             Test_Total_Loss: 2.0177066326141357, Test_Clf_Loss: 2.0177066326141357, Test_Filter_Loss: 3.965902124036802e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.76%, Test_Ones_Portion: 1.8577040918899002e-06\n",
      "Epoch 63, Total Loss: 2.0104706287384033, Clf Loss: 2.0104706287384033, Filter Loss: 3.3922665352292825e-06, Seq Loss: 0.9999996423721313, Accuracy Rate: 44.59%, Ones Portion: 1.5511805031565018e-06,             Test_Total_Loss: 2.0037965774536133, Test_Clf_Loss: 2.0037965774536133, Test_Filter_Loss: 4.0845557123248e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.90%, Test_Ones_Portion: 1.9319759303471074e-06\n",
      "Epoch 64, Total Loss: 2.0101494789123535, Clf Loss: 2.0101494789123535, Filter Loss: 3.579975100365118e-06, Seq Loss: 0.9999996423721313, Accuracy Rate: 44.62%, Ones Portion: 1.6127654589581653e-06,             Test_Total_Loss: 2.0151166915893555, Test_Clf_Loss: 2.0151166915893555, Test_Filter_Loss: 4.0326444832317065e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.76%, Test_Ones_Portion: 1.8629954183779773e-06\n",
      "Epoch 65, Total Loss: 2.0101890563964844, Clf Loss: 2.0101890563964844, Filter Loss: 3.481117801129585e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.64%, Ones Portion: 1.5550276657450013e-06,             Test_Total_Loss: 2.002370595932007, Test_Clf_Loss: 2.002370595932007, Test_Filter_Loss: 4.0419768083665986e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.71%, Test_Ones_Portion: 1.857975689745217e-06\n",
      "Epoch 66, Total Loss: 2.0060858726501465, Clf Loss: 2.0060858726501465, Filter Loss: 3.5444415971142007e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.59%, Ones Portion: 1.5636422858733567e-06,             Test_Total_Loss: 2.0050551891326904, Test_Clf_Loss: 2.0050551891326904, Test_Filter_Loss: 4.180590622127056e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.56%, Test_Ones_Portion: 1.8762041236186633e-06\n",
      "Epoch 67, Total Loss: 2.009996175765991, Clf Loss: 2.009996175765991, Filter Loss: 3.6432172692002496e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.55%, Ones Portion: 1.5434566194016952e-06,             Test_Total_Loss: 2.010634422302246, Test_Clf_Loss: 2.010634422302246, Test_Filter_Loss: 4.229361366014928e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.80%, Test_Ones_Portion: 1.8995725667991792e-06\n",
      "Epoch 68, Total Loss: 2.0135858058929443, Clf Loss: 2.0135858058929443, Filter Loss: 3.710540340762236e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.39%, Ones Portion: 1.6017305597415543e-06,             Test_Total_Loss: 2.0060951709747314, Test_Clf_Loss: 2.0060951709747314, Test_Filter_Loss: 4.361590526968939e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.71%, Test_Ones_Portion: 2.012336608459009e-06\n",
      "Epoch 69, Total Loss: 2.011765718460083, Clf Loss: 2.011765718460083, Filter Loss: 3.746417860384099e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.50%, Ones Portion: 1.5726722040199093e-06,             Test_Total_Loss: 2.010903835296631, Test_Clf_Loss: 2.010903835296631, Test_Filter_Loss: 4.293141955713509e-06, TEST_Seq_Loss: 0.9999993443489075, Test_Accuracy_Rate: 43.61%, Test_Ones_Portion: 1.9605045054049697e-06\n",
      "Epoch 70, Total Loss: 2.010298490524292, Clf Loss: 2.010298490524292, Filter Loss: 3.827822638413636e-06, Seq Loss: 0.9999996423721313, Accuracy Rate: 44.58%, Ones Portion: 1.5737899730083882e-06,             Test_Total_Loss: 2.0147738456726074, Test_Clf_Loss: 2.0147738456726074, Test_Filter_Loss: 4.393757990328595e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.56%, Test_Ones_Portion: 1.9314441033202456e-06\n",
      "Epoch 71, Total Loss: 2.0120232105255127, Clf Loss: 2.0120232105255127, Filter Loss: 3.846975232590921e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.66%, Ones Portion: 1.5296297988243168e-06,             Test_Total_Loss: 2.0354857444763184, Test_Clf_Loss: 2.0354857444763184, Test_Filter_Loss: 4.33384821008076e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.61%, Test_Ones_Portion: 1.9264023194409674e-06\n",
      "Epoch 72, Total Loss: 2.013728141784668, Clf Loss: 2.013728141784668, Filter Loss: 3.7061745388200507e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.54%, Ones Portion: 1.512191829533549e-06,             Test_Total_Loss: 2.015626907348633, Test_Clf_Loss: 2.015626907348633, Test_Filter_Loss: 4.309647010813933e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.61%, Test_Ones_Portion: 1.8432100432619336e-06\n",
      "Epoch 73, Total Loss: 2.0145187377929688, Clf Loss: 2.0145187377929688, Filter Loss: 3.6590336094377562e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.46%, Ones Portion: 1.4277999298428767e-06,             Test_Total_Loss: 2.019014835357666, Test_Clf_Loss: 2.019014835357666, Test_Filter_Loss: 4.3188970266783144e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.51%, Test_Ones_Portion: 1.7972507748709177e-06\n",
      "Epoch 74, Total Loss: 2.0140931606292725, Clf Loss: 2.0140931606292725, Filter Loss: 3.7806976251886226e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.52%, Ones Portion: 1.4616147154811188e-06,             Test_Total_Loss: 2.0177929401397705, Test_Clf_Loss: 2.0177929401397705, Test_Filter_Loss: 4.161592642049072e-06, TEST_Seq_Loss: 0.999999463558197, Test_Accuracy_Rate: 43.42%, Test_Ones_Portion: 1.7447129039283027e-06\n",
      "Epoch 75, Total Loss: 2.009207010269165, Clf Loss: 2.009207010269165, Filter Loss: 3.741590944628115e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.64%, Ones Portion: 1.4544302757713012e-06,             Test_Total_Loss: 2.0235536098480225, Test_Clf_Loss: 2.0235536098480225, Test_Filter_Loss: 4.00584258386516e-06, TEST_Seq_Loss: 0.9999995231628418, Test_Accuracy_Rate: 43.51%, Test_Ones_Portion: 1.7110260159824975e-06\n",
      "Epoch 76, Total Loss: 2.0117735862731934, Clf Loss: 2.0117735862731934, Filter Loss: 3.6936617107130587e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.64%, Ones Portion: 1.4706348565596272e-06,             Test_Total_Loss: 2.0120391845703125, Test_Clf_Loss: 2.0120391845703125, Test_Filter_Loss: 4.1610192056396045e-06, TEST_Seq_Loss: 0.9999995231628418, Test_Accuracy_Rate: 43.71%, Test_Ones_Portion: 1.7131593494923436e-06\n",
      "Epoch 77, Total Loss: 2.0110762119293213, Clf Loss: 2.0110762119293213, Filter Loss: 3.676888582049287e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.75%, Ones Portion: 1.4215310102372314e-06,             Test_Total_Loss: 2.0186939239501953, Test_Clf_Loss: 2.0186939239501953, Test_Filter_Loss: 3.9418482629116625e-06, TEST_Seq_Loss: 0.9999995231628418, Test_Accuracy_Rate: 43.32%, Test_Ones_Portion: 1.6547744507988682e-06\n",
      "Epoch 78, Total Loss: 2.01552152633667, Clf Loss: 2.01552152633667, Filter Loss: 3.402609763725195e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.54%, Ones Portion: 1.2874799040218932e-06,             Test_Total_Loss: 2.0158026218414307, Test_Clf_Loss: 2.0158026218414307, Test_Filter_Loss: 3.929692411475116e-06, TEST_Seq_Loss: 0.9999996423721313, Test_Accuracy_Rate: 43.76%, Test_Ones_Portion: 1.5933164831949398e-06\n",
      "Epoch 79, Total Loss: 2.012650966644287, Clf Loss: 2.012650966644287, Filter Loss: 3.4787060485541588e-06, Seq Loss: 0.9999997615814209, Accuracy Rate: 44.72%, Ones Portion: 1.332175656898471e-06,             Test_Total_Loss: 2.0104286670684814, Test_Clf_Loss: 2.0104286670684814, Test_Filter_Loss: 3.6744163480761927e-06, TEST_Seq_Loss: 0.9999995231628418, Test_Accuracy_Rate: 43.80%, Test_Ones_Portion: 1.4928007203707239e-06\n",
      "Epoch 80, Total Loss: 2.018127679824829, Clf Loss: 2.018127679824829, Filter Loss: 3.270190518378513e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.55%, Ones Portion: 1.2308438499530894e-06,             Test_Total_Loss: 2.01242995262146, Test_Clf_Loss: 2.01242995262146, Test_Filter_Loss: 3.569824002624955e-06, TEST_Seq_Loss: 0.9999996423721313, Test_Accuracy_Rate: 43.76%, Test_Ones_Portion: 1.4405198953681975e-06\n",
      "Epoch 81, Total Loss: 2.0170185565948486, Clf Loss: 2.0170185565948486, Filter Loss: 3.2615946565783815e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.67%, Ones Portion: 1.2025470823573414e-06,             Test_Total_Loss: 2.0132217407226562, Test_Clf_Loss: 2.0132217407226562, Test_Filter_Loss: 3.6155804536974756e-06, TEST_Seq_Loss: 0.9999996423721313, Test_Accuracy_Rate: 43.71%, Test_Ones_Portion: 1.4211001371222665e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, Total Loss: 2.0140247344970703, Clf Loss: 2.0140247344970703, Filter Loss: 3.3084870665334165e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.59%, Ones Portion: 1.177769149762753e-06,             Test_Total_Loss: 2.018075942993164, Test_Clf_Loss: 2.018075942993164, Test_Filter_Loss: 3.695504574352526e-06, TEST_Seq_Loss: 0.9999996423721313, Test_Accuracy_Rate: 43.66%, Test_Ones_Portion: 1.4441267239817535e-06\n",
      "Epoch 83, Total Loss: 2.0162880420684814, Clf Loss: 2.0162880420684814, Filter Loss: 3.1749009394843597e-06, Seq Loss: 1.0, Accuracy Rate: 44.54%, Ones Portion: 1.1390500276320381e-06,             Test_Total_Loss: 2.017179250717163, Test_Clf_Loss: 2.017179250717163, Test_Filter_Loss: 3.20597541758616e-06, TEST_Seq_Loss: 0.9999996423721313, Test_Accuracy_Rate: 43.66%, Test_Ones_Portion: 1.2570712897286285e-06\n",
      "Epoch 84, Total Loss: 2.0178990364074707, Clf Loss: 2.0178990364074707, Filter Loss: 2.947851726275985e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.53%, Ones Portion: 1.1092711247329134e-06,             Test_Total_Loss: 2.0510292053222656, Test_Clf_Loss: 2.0510292053222656, Test_Filter_Loss: 3.2620459933241364e-06, TEST_Seq_Loss: 0.9999996423721313, Test_Accuracy_Rate: 43.42%, Test_Ones_Portion: 1.2549105576908914e-06\n",
      "Epoch 85, Total Loss: 2.0213048458099365, Clf Loss: 2.0213048458099365, Filter Loss: 2.8435117656044895e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.46%, Ones Portion: 1.058460043168452e-06,             Test_Total_Loss: 2.048072099685669, Test_Clf_Loss: 2.048072099685669, Test_Filter_Loss: 3.073044354096055e-06, TEST_Seq_Loss: 0.9999997615814209, Test_Accuracy_Rate: 43.56%, Test_Ones_Portion: 1.132617285293236e-06\n",
      "Epoch 86, Total Loss: 2.0240304470062256, Clf Loss: 2.0240304470062256, Filter Loss: 2.7275154934613965e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.41%, Ones Portion: 9.99061398943013e-07,             Test_Total_Loss: 2.0587410926818848, Test_Clf_Loss: 2.0587410926818848, Test_Filter_Loss: 3.0001665436429903e-06, TEST_Seq_Loss: 0.9999997615814209, Test_Accuracy_Rate: 43.18%, Test_Ones_Portion: 1.0988196663674898e-06\n",
      "Epoch 87, Total Loss: 2.025758981704712, Clf Loss: 2.025758981704712, Filter Loss: 2.5461483801336726e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.41%, Ones Portion: 9.488924206380034e-07,             Test_Total_Loss: 2.0538697242736816, Test_Clf_Loss: 2.0538697242736816, Test_Filter_Loss: 2.8060317163181026e-06, TEST_Seq_Loss: 0.9999997615814209, Test_Accuracy_Rate: 43.32%, Test_Ones_Portion: 1.06103288999293e-06\n",
      "Epoch 88, Total Loss: 2.027425765991211, Clf Loss: 2.027425765991211, Filter Loss: 2.4008618311199825e-06, Seq Loss: 1.0, Accuracy Rate: 44.31%, Ones Portion: 9.117904937738786e-07,             Test_Total_Loss: 2.0589792728424072, Test_Clf_Loss: 2.0589792728424072, Test_Filter_Loss: 2.66865413323103e-06, TEST_Seq_Loss: 0.9999997615814209, Test_Accuracy_Rate: 43.03%, Test_Ones_Portion: 1.0019148248829879e-06\n",
      "Epoch 89, Total Loss: 2.033583402633667, Clf Loss: 2.033583402633667, Filter Loss: 2.471322204655735e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.23%, Ones Portion: 9.455532108404441e-07,             Test_Total_Loss: 2.056385040283203, Test_Clf_Loss: 2.056385040283203, Test_Filter_Loss: 2.502443976482027e-06, TEST_Seq_Loss: 0.9999997615814209, Test_Accuracy_Rate: 43.32%, Test_Ones_Portion: 9.580609230397386e-07\n",
      "Epoch 90, Total Loss: 2.034309148788452, Clf Loss: 2.034309148788452, Filter Loss: 2.2015133254171815e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.13%, Ones Portion: 8.58202099607297e-07,             Test_Total_Loss: 2.056417465209961, Test_Clf_Loss: 2.056417465209961, Test_Filter_Loss: 2.5831466246017953e-06, TEST_Seq_Loss: 0.9999997615814209, Test_Accuracy_Rate: 43.18%, Test_Ones_Portion: 9.731591035233578e-07\n",
      "Epoch 91, Total Loss: 2.0349655151367188, Clf Loss: 2.0349655151367188, Filter Loss: 2.2282995360001223e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.19%, Ones Portion: 8.545737841814116e-07,             Test_Total_Loss: 2.0664615631103516, Test_Clf_Loss: 2.0664615631103516, Test_Filter_Loss: 2.495225544407731e-06, TEST_Seq_Loss: 0.9999997615814209, Test_Accuracy_Rate: 43.42%, Test_Ones_Portion: 9.458717045163212e-07\n",
      "Epoch 92, Total Loss: 2.035100221633911, Clf Loss: 2.035100221633911, Filter Loss: 2.139677235390991e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.25%, Ones Portion: 8.234239885496208e-07,             Test_Total_Loss: 2.065366744995117, Test_Clf_Loss: 2.065366744995117, Test_Filter_Loss: 2.404913630016381e-06, TEST_Seq_Loss: 0.9999997615814209, Test_Accuracy_Rate: 43.18%, Test_Ones_Portion: 9.124896109824476e-07\n",
      "Epoch 93, Total Loss: 2.0396533012390137, Clf Loss: 2.0396533012390137, Filter Loss: 2.106230795106967e-06, Seq Loss: 1.0, Accuracy Rate: 44.16%, Ones Portion: 8.063871064223349e-07,             Test_Total_Loss: 2.076049566268921, Test_Clf_Loss: 2.076049566268921, Test_Filter_Loss: 2.222106559202075e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.64%, Test_Ones_Portion: 8.604357617514324e-07\n",
      "Epoch 94, Total Loss: 2.040609836578369, Clf Loss: 2.040609836578369, Filter Loss: 1.9564363356039394e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.95%, Ones Portion: 7.539736657236062e-07,             Test_Total_Loss: 2.0631022453308105, Test_Clf_Loss: 2.0631022453308105, Test_Filter_Loss: 2.260077508253744e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 43.32%, Test_Ones_Portion: 8.554491728318681e-07\n",
      "Epoch 95, Total Loss: 2.0372023582458496, Clf Loss: 2.0372023582458496, Filter Loss: 2.0096267689950764e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.07%, Ones Portion: 7.593116606585681e-07,             Test_Total_Loss: 2.070859909057617, Test_Clf_Loss: 2.070859909057617, Test_Filter_Loss: 2.347662984902854e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 43.03%, Test_Ones_Portion: 8.811574616629514e-07\n",
      "Epoch 96, Total Loss: 2.040146589279175, Clf Loss: 2.040146589279175, Filter Loss: 2.1354683212848613e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.10%, Ones Portion: 7.863508244554396e-07,             Test_Total_Loss: 2.068254232406616, Test_Clf_Loss: 2.068254232406616, Test_Filter_Loss: 2.196157538492116e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 43.08%, Test_Ones_Portion: 8.430382649748935e-07\n",
      "Epoch 97, Total Loss: 2.039876699447632, Clf Loss: 2.039876699447632, Filter Loss: 1.9748028989852173e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.08%, Ones Portion: 7.523930776187626e-07,             Test_Total_Loss: 2.0744497776031494, Test_Clf_Loss: 2.0744497776031494, Test_Filter_Loss: 2.2015613012627e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 43.08%, Test_Ones_Portion: 8.499640671288944e-07\n",
      "Epoch 98, Total Loss: 2.0424985885620117, Clf Loss: 2.0424985885620117, Filter Loss: 2.065728267552913e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 44.01%, Ones Portion: 7.924656983959721e-07,             Test_Total_Loss: 2.0983097553253174, Test_Clf_Loss: 2.0983097553253174, Test_Filter_Loss: 2.1477724203577964e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.88%, Test_Ones_Portion: 7.976742040227691e-07\n",
      "Epoch 99, Total Loss: 2.041800022125244, Clf Loss: 2.041800022125244, Filter Loss: 1.9112635527562816e-06, Seq Loss: 1.0, Accuracy Rate: 43.97%, Ones Portion: 6.993194574533845e-07,             Test_Total_Loss: 2.1017439365386963, Test_Clf_Loss: 2.1017439365386963, Test_Filter_Loss: 2.082028458971763e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.84%, Test_Ones_Portion: 7.467561999874306e-07\n",
      "Epoch 100, Total Loss: 2.0422284603118896, Clf Loss: 2.0422284603118896, Filter Loss: 1.9908252397726756e-06, Seq Loss: 1.0, Accuracy Rate: 44.00%, Ones Portion: 7.083985451572516e-07,             Test_Total_Loss: 2.097853660583496, Test_Clf_Loss: 2.097853660583496, Test_Filter_Loss: 1.9890846942871576e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.64%, Test_Ones_Portion: 7.186099537648261e-07\n",
      "Epoch 101, Total Loss: 2.048083543777466, Clf Loss: 2.048083543777466, Filter Loss: 1.8827623762263102e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.91%, Ones Portion: 6.555410436703824e-07,             Test_Total_Loss: 2.106316089630127, Test_Clf_Loss: 2.106316089630127, Test_Filter_Loss: 1.9998683455924038e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.74%, Test_Ones_Portion: 6.897434445818362e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102, Total Loss: 2.051609992980957, Clf Loss: 2.051609992980957, Filter Loss: 1.9516214706527535e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.93%, Ones Portion: 6.60308614897076e-07,             Test_Total_Loss: 2.108915328979492, Test_Clf_Loss: 2.108915328979492, Test_Filter_Loss: 2.083849494738388e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.64%, Test_Ones_Portion: 6.694542662444292e-07\n",
      "Epoch 103, Total Loss: 2.052340030670166, Clf Loss: 2.052340030670166, Filter Loss: 1.855986056398251e-06, Seq Loss: 1.0, Accuracy Rate: 43.96%, Ones Portion: 6.100966061239887e-07,             Test_Total_Loss: 2.1129770278930664, Test_Clf_Loss: 2.1129770278930664, Test_Filter_Loss: 2.0273168956919108e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.88%, Test_Ones_Portion: 6.727892696289928e-07\n",
      "Epoch 104, Total Loss: 2.0594606399536133, Clf Loss: 2.0594606399536133, Filter Loss: 1.8338238305659615e-06, Seq Loss: 1.0, Accuracy Rate: 43.75%, Ones Portion: 6.011830464558443e-07,             Test_Total_Loss: 2.1131904125213623, Test_Clf_Loss: 2.1131904125213623, Test_Filter_Loss: 1.9450578747637337e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.79%, Test_Ones_Portion: 6.250464252843813e-07\n",
      "Epoch 105, Total Loss: 2.059962511062622, Clf Loss: 2.059962511062622, Filter Loss: 1.7332683910353808e-06, Seq Loss: 1.0, Accuracy Rate: 43.75%, Ones Portion: 5.650968546433432e-07,             Test_Total_Loss: 2.1124582290649414, Test_Clf_Loss: 2.1124582290649414, Test_Filter_Loss: 1.8628993530001026e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.79%, Test_Ones_Portion: 6.157488883218321e-07\n",
      "Epoch 106, Total Loss: 2.062554359436035, Clf Loss: 2.062554359436035, Filter Loss: 1.7163692973554134e-06, Seq Loss: 1.0, Accuracy Rate: 43.72%, Ones Portion: 5.358289740797773e-07,             Test_Total_Loss: 2.1180546283721924, Test_Clf_Loss: 2.1180546283721924, Test_Filter_Loss: 1.8466594156052452e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.21%, Test_Ones_Portion: 5.73186582641938e-07\n",
      "Epoch 107, Total Loss: 2.075594902038574, Clf Loss: 2.075594902038574, Filter Loss: 1.6235413795584464e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.41%, Ones Portion: 4.743343993141025e-07,             Test_Total_Loss: 2.119459629058838, Test_Clf_Loss: 2.119459629058838, Test_Filter_Loss: 1.7765737538866233e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.55%, Test_Ones_Portion: 5.505808644556964e-07\n",
      "Epoch 108, Total Loss: 2.0769708156585693, Clf Loss: 2.0769708156585693, Filter Loss: 1.5920580835881992e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.52%, Ones Portion: 4.857988642470445e-07,             Test_Total_Loss: 2.1218197345733643, Test_Clf_Loss: 2.1218197345733643, Test_Filter_Loss: 1.6844237507029902e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.69%, Test_Ones_Portion: 5.18085300882376e-07\n",
      "Epoch 109, Total Loss: 2.0835483074188232, Clf Loss: 2.0835483074188232, Filter Loss: 1.5511553783653653e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.39%, Ones Portion: 4.6967514322204806e-07,             Test_Total_Loss: 2.1192102432250977, Test_Clf_Loss: 2.1192102432250977, Test_Filter_Loss: 1.6855902913448517e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.88%, Test_Ones_Portion: 5.453556468637544e-07\n",
      "Epoch 110, Total Loss: 2.080620765686035, Clf Loss: 2.080620765686035, Filter Loss: 1.572778501213179e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.32%, Ones Portion: 4.909859967483499e-07,             Test_Total_Loss: 2.1204309463500977, Test_Clf_Loss: 2.1204309463500977, Test_Filter_Loss: 1.6674715652698069e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.40%, Test_Ones_Portion: 5.300636303218198e-07\n",
      "Epoch 111, Total Loss: 2.0852818489074707, Clf Loss: 2.0852818489074707, Filter Loss: 1.5125322079256875e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.24%, Ones Portion: 4.6669180164826685e-07,             Test_Total_Loss: 2.1170289516448975, Test_Clf_Loss: 2.1170289516448975, Test_Filter_Loss: 1.5856880963838194e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.55%, Test_Ones_Portion: 5.088879220238596e-07\n",
      "Epoch 112, Total Loss: 2.0894575119018555, Clf Loss: 2.0894575119018555, Filter Loss: 1.5496004834858468e-06, Seq Loss: 1.0, Accuracy Rate: 43.09%, Ones Portion: 4.6272833742477815e-07,             Test_Total_Loss: 2.1212158203125, Test_Clf_Loss: 2.1212158203125, Test_Filter_Loss: 1.672450139267312e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.55%, Test_Ones_Portion: 5.098852966511913e-07\n",
      "Epoch 113, Total Loss: 2.0860323905944824, Clf Loss: 2.0860323905944824, Filter Loss: 1.4703357464895817e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.23%, Ones Portion: 4.3255025161670346e-07,             Test_Total_Loss: 2.1180315017700195, Test_Clf_Loss: 2.1180315017700195, Test_Filter_Loss: 1.6379181033698842e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.64%, Test_Ones_Portion: 5.250493586572702e-07\n",
      "Epoch 114, Total Loss: 2.081743001937866, Clf Loss: 2.081743001937866, Filter Loss: 1.4700698329761508e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.35%, Ones Portion: 4.6332812075888796e-07,             Test_Total_Loss: 2.1230297088623047, Test_Clf_Loss: 2.1230297088623047, Test_Filter_Loss: 1.5123832781682722e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.30%, Test_Ones_Portion: 4.846755814469361e-07\n",
      "Epoch 115, Total Loss: 2.0933144092559814, Clf Loss: 2.0933144092559814, Filter Loss: 1.4017996363691054e-06, Seq Loss: 1.0, Accuracy Rate: 43.18%, Ones Portion: 4.053120505886909e-07,             Test_Total_Loss: 2.122579336166382, Test_Clf_Loss: 2.122579336166382, Test_Filter_Loss: 1.4997036714703427e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.40%, Test_Ones_Portion: 4.869301619692123e-07\n",
      "Epoch 116, Total Loss: 2.0893821716308594, Clf Loss: 2.0893821716308594, Filter Loss: 1.3885693306292524e-06, Seq Loss: 1.0, Accuracy Rate: 43.21%, Ones Portion: 4.072437889135472e-07,             Test_Total_Loss: 2.1275720596313477, Test_Clf_Loss: 2.1275720596313477, Test_Filter_Loss: 1.5062274769661599e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.40%, Test_Ones_Portion: 4.997842779630446e-07\n",
      "Epoch 117, Total Loss: 2.097886323928833, Clf Loss: 2.097886323928833, Filter Loss: 1.378226443193853e-06, Seq Loss: 1.0, Accuracy Rate: 43.03%, Ones Portion: 4.069602823619789e-07,             Test_Total_Loss: 2.129976511001587, Test_Clf_Loss: 2.129976511001587, Test_Filter_Loss: 1.5335368743762956e-06, TEST_Seq_Loss: 0.9999998807907104, Test_Accuracy_Rate: 42.40%, Test_Ones_Portion: 4.7619846554880496e-07\n",
      "Epoch 118, Total Loss: 2.0903899669647217, Clf Loss: 2.0903899669647217, Filter Loss: 1.3624633083964e-06, Seq Loss: 1.0, Accuracy Rate: 43.12%, Ones Portion: 4.098418173725804e-07,             Test_Total_Loss: 2.1326334476470947, Test_Clf_Loss: 2.1326334476470947, Test_Filter_Loss: 1.4664465197711252e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.16%, Test_Ones_Portion: 4.6755511107221537e-07\n",
      "Epoch 119, Total Loss: 2.093658208847046, Clf Loss: 2.093658208847046, Filter Loss: 1.3635534514833125e-06, Seq Loss: 1.0, Accuracy Rate: 43.05%, Ones Portion: 4.2297693880755105e-07,             Test_Total_Loss: 2.134671211242676, Test_Clf_Loss: 2.134671211242676, Test_Filter_Loss: 1.4773578413951327e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.11%, Test_Ones_Portion: 4.791626793121395e-07\n",
      "Epoch 120, Total Loss: 2.093334674835205, Clf Loss: 2.093334674835205, Filter Loss: 1.2887779803349986e-06, Seq Loss: 1.0, Accuracy Rate: 43.05%, Ones Portion: 3.9905370385895367e-07,             Test_Total_Loss: 2.136077404022217, Test_Clf_Loss: 2.136077404022217, Test_Filter_Loss: 1.4557336953657796e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.06%, Test_Ones_Portion: 4.67250401925412e-07\n",
      "Epoch 121, Total Loss: 2.0947036743164062, Clf Loss: 2.0947036743164062, Filter Loss: 1.2920637573188287e-06, Seq Loss: 1.0, Accuracy Rate: 43.01%, Ones Portion: 3.9851494193499093e-07,             Test_Total_Loss: 2.1344034671783447, Test_Clf_Loss: 2.1344034671783447, Test_Filter_Loss: 1.4287993508332875e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.11%, Test_Ones_Portion: 4.400460795750405e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122, Total Loss: 2.093470573425293, Clf Loss: 2.093470573425293, Filter Loss: 1.2849777704104781e-06, Seq Loss: 1.0, Accuracy Rate: 42.99%, Ones Portion: 4.0229073761111067e-07,             Test_Total_Loss: 2.126749277114868, Test_Clf_Loss: 2.126749277114868, Test_Filter_Loss: 1.3538400480683777e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.16%, Test_Ones_Portion: 4.477475386011065e-07\n",
      "Epoch 123, Total Loss: 2.087232828140259, Clf Loss: 2.087232828140259, Filter Loss: 1.1926988463528687e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.08%, Ones Portion: 3.9582377553415427e-07,             Test_Total_Loss: 2.1323699951171875, Test_Clf_Loss: 2.1323699951171875, Test_Filter_Loss: 1.3809101346851094e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.35%, Test_Ones_Portion: 4.4278866084823676e-07\n",
      "Epoch 124, Total Loss: 2.091646909713745, Clf Loss: 2.091646909713745, Filter Loss: 1.2223380281284335e-06, Seq Loss: 1.0, Accuracy Rate: 43.01%, Ones Portion: 3.873401226428541e-07,             Test_Total_Loss: 2.1341946125030518, Test_Clf_Loss: 2.1341946125030518, Test_Filter_Loss: 1.294739377044607e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.16%, Test_Ones_Portion: 4.4771982743441185e-07\n",
      "Epoch 125, Total Loss: 2.091951608657837, Clf Loss: 2.091951608657837, Filter Loss: 1.2152353292549378e-06, Seq Loss: 1.0, Accuracy Rate: 43.03%, Ones Portion: 3.9005595908747637e-07,             Test_Total_Loss: 2.123391628265381, Test_Clf_Loss: 2.123391628265381, Test_Filter_Loss: 1.30115711272083e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.40%, Test_Ones_Portion: 4.3708186581170594e-07\n",
      "Epoch 126, Total Loss: 2.0918123722076416, Clf Loss: 2.0918123722076416, Filter Loss: 1.1961886912104092e-06, Seq Loss: 1.0, Accuracy Rate: 43.04%, Ones Portion: 4.0051591554401966e-07,             Test_Total_Loss: 2.1277503967285156, Test_Clf_Loss: 2.1277503967285156, Test_Filter_Loss: 1.3352134828892304e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.21%, Test_Ones_Portion: 4.549502818917972e-07\n",
      "Epoch 127, Total Loss: 2.0842785835266113, Clf Loss: 2.0842785835266113, Filter Loss: 1.174831254502351e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.18%, Ones Portion: 3.876215828313434e-07,             Test_Total_Loss: 2.125894069671631, Test_Clf_Loss: 2.125894069671631, Test_Filter_Loss: 1.3386580803853576e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.11%, Test_Ones_Portion: 4.51792146805019e-07\n",
      "Epoch 128, Total Loss: 2.087894916534424, Clf Loss: 2.087894916534424, Filter Loss: 1.181015363727056e-06, Seq Loss: 1.0, Accuracy Rate: 43.11%, Ones Portion: 3.942921296129498e-07,             Test_Total_Loss: 2.127439022064209, Test_Clf_Loss: 2.127439022064209, Test_Filter_Loss: 1.3056821899226634e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.16%, Test_Ones_Portion: 4.5157054273659014e-07\n",
      "Epoch 129, Total Loss: 2.0920352935791016, Clf Loss: 2.0920352935791016, Filter Loss: 1.2677941185756936e-06, Seq Loss: 1.0, Accuracy Rate: 43.00%, Ones Portion: 4.0379003962698334e-07,             Test_Total_Loss: 2.1354281902313232, Test_Clf_Loss: 2.1354281902313232, Test_Filter_Loss: 1.3380728205447667e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.21%, Test_Ones_Portion: 4.4345355831865163e-07\n",
      "Epoch 130, Total Loss: 2.0903239250183105, Clf Loss: 2.0903239250183105, Filter Loss: 1.2660957509069704e-06, Seq Loss: 1.0, Accuracy Rate: 43.09%, Ones Portion: 3.970598072555731e-07,             Test_Total_Loss: 2.144678831100464, Test_Clf_Loss: 2.144678831100464, Test_Filter_Loss: 1.3088892956147902e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.97%, Test_Ones_Portion: 4.2848714087995177e-07\n",
      "Epoch 131, Total Loss: 2.0902864933013916, Clf Loss: 2.0902864933013916, Filter Loss: 1.227118787028303e-06, Seq Loss: 1.0, Accuracy Rate: 43.09%, Ones Portion: 3.8686707171109447e-07,             Test_Total_Loss: 2.1459434032440186, Test_Clf_Loss: 2.1459434032440186, Test_Filter_Loss: 1.3002833156861016e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.11%, Test_Ones_Portion: 4.1302888575955876e-07\n",
      "Epoch 132, Total Loss: 2.092137336730957, Clf Loss: 2.092137336730957, Filter Loss: 1.2421523933880962e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.05%, Ones Portion: 3.8933819723752094e-07,             Test_Total_Loss: 2.142993688583374, Test_Clf_Loss: 2.142993688583374, Test_Filter_Loss: 1.3369083262659842e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.30%, Test_Ones_Portion: 4.2336208139204246e-07\n",
      "Epoch 133, Total Loss: 2.091550588607788, Clf Loss: 2.091550588607788, Filter Loss: 1.1923588090212434e-06, Seq Loss: 1.0, Accuracy Rate: 43.04%, Ones Portion: 3.532995833666064e-07,             Test_Total_Loss: 2.1396491527557373, Test_Clf_Loss: 2.1396491527557373, Test_Filter_Loss: 1.3251427617433365e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.30%, Test_Ones_Portion: 4.248856839694781e-07\n",
      "Epoch 134, Total Loss: 2.0912163257598877, Clf Loss: 2.0912163257598877, Filter Loss: 1.2466849739212194e-06, Seq Loss: 1.0, Accuracy Rate: 43.18%, Ones Portion: 3.5306584322825074e-07,             Test_Total_Loss: 2.1430246829986572, Test_Clf_Loss: 2.1430246829986572, Test_Filter_Loss: 1.3217835430623381e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.21%, Test_Ones_Portion: 4.016429500097729e-07\n",
      "Epoch 135, Total Loss: 2.0947935581207275, Clf Loss: 2.0947935581207275, Filter Loss: 1.1946915492444532e-06, Seq Loss: 1.0, Accuracy Rate: 43.14%, Ones Portion: 3.611073395859421e-07,             Test_Total_Loss: 2.14682936668396, Test_Clf_Loss: 2.14682936668396, Test_Filter_Loss: 1.2183212447780534e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.16%, Test_Ones_Portion: 3.865725659579766e-07\n",
      "Epoch 136, Total Loss: 2.0923120975494385, Clf Loss: 2.0923120975494385, Filter Loss: 1.0915221082541393e-06, Seq Loss: 1.0, Accuracy Rate: 43.05%, Ones Portion: 3.401255241897161e-07,             Test_Total_Loss: 2.141964912414551, Test_Clf_Loss: 2.141964912414551, Test_Filter_Loss: 1.1721533610398183e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.16%, Test_Ones_Portion: 3.742447347576672e-07\n",
      "Epoch 137, Total Loss: 2.092294931411743, Clf Loss: 2.092294931411743, Filter Loss: 1.0781661785586039e-06, Seq Loss: 0.9999998807907104, Accuracy Rate: 43.01%, Ones Portion: 3.3539436117280275e-07,             Test_Total_Loss: 2.1447601318359375, Test_Clf_Loss: 2.1447601318359375, Test_Filter_Loss: 1.131718818214722e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.11%, Test_Ones_Portion: 3.5039249723922694e-07\n",
      "Epoch 138, Total Loss: 2.094733476638794, Clf Loss: 2.094733476638794, Filter Loss: 1.1386430287529947e-06, Seq Loss: 1.0, Accuracy Rate: 43.03%, Ones Portion: 3.3866197668430686e-07,             Test_Total_Loss: 2.140092611312866, Test_Clf_Loss: 2.140092611312866, Test_Filter_Loss: 1.2204118320369162e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.21%, Test_Ones_Portion: 3.740785530226276e-07\n",
      "Epoch 139, Total Loss: 2.0951504707336426, Clf Loss: 2.0951504707336426, Filter Loss: 1.1238828392379219e-06, Seq Loss: 1.0, Accuracy Rate: 43.09%, Ones Portion: 3.455420483078342e-07,             Test_Total_Loss: 2.142045497894287, Test_Clf_Loss: 2.142045497894287, Test_Filter_Loss: 1.2594042573255138e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.11%, Test_Ones_Portion: 3.750481312181364e-07\n",
      "Epoch 140, Total Loss: 2.088287591934204, Clf Loss: 2.088287591934204, Filter Loss: 1.1640690900094341e-06, Seq Loss: 1.0, Accuracy Rate: 43.10%, Ones Portion: 3.375692472218361e-07,             Test_Total_Loss: 2.1427955627441406, Test_Clf_Loss: 2.1427955627441406, Test_Filter_Loss: 1.1841303830806282e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.21%, Test_Ones_Portion: 3.517222069149284e-07\n",
      "Epoch 141, Total Loss: 2.0956926345825195, Clf Loss: 2.0956926345825195, Filter Loss: 1.0613174481477472e-06, Seq Loss: 1.0, Accuracy Rate: 42.97%, Ones Portion: 3.0644588377981563e-07,             Test_Total_Loss: 2.1505138874053955, Test_Clf_Loss: 2.1505138874053955, Test_Filter_Loss: 1.1240344974794425e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.92%, Test_Ones_Portion: 3.420816199195542e-07\n",
      "Epoch 142, Total Loss: 2.095261335372925, Clf Loss: 2.095261335372925, Filter Loss: 1.0374029670856544e-06, Seq Loss: 1.0, Accuracy Rate: 42.89%, Ones Portion: 3.150685472519399e-07,             Test_Total_Loss: 2.147040605545044, Test_Clf_Loss: 2.147040605545044, Test_Filter_Loss: 1.0665147556210286e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.92%, Test_Ones_Portion: 3.3715048175508855e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143, Total Loss: 2.096904993057251, Clf Loss: 2.096904993057251, Filter Loss: 9.959245517165982e-07, Seq Loss: 1.0, Accuracy Rate: 42.89%, Ones Portion: 3.0359464631146693e-07,             Test_Total_Loss: 2.147115707397461, Test_Clf_Loss: 2.147115707397461, Test_Filter_Loss: 1.0698213372961618e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.92%, Test_Ones_Portion: 3.366241401181469e-07\n",
      "Epoch 144, Total Loss: 2.0985567569732666, Clf Loss: 2.0985567569732666, Filter Loss: 9.798266091820551e-07, Seq Loss: 1.0, Accuracy Rate: 42.97%, Ones Portion: 2.9102997700647393e-07,             Test_Total_Loss: 2.1463871002197266, Test_Clf_Loss: 2.1463871002197266, Test_Filter_Loss: 1.0701241990318522e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.06%, Test_Ones_Portion: 3.3922819397957937e-07\n",
      "Epoch 145, Total Loss: 2.10115909576416, Clf Loss: 2.10115909576416, Filter Loss: 1.0205225180470734e-06, Seq Loss: 1.0, Accuracy Rate: 42.86%, Ones Portion: 3.022158807652886e-07,             Test_Total_Loss: 2.1457173824310303, Test_Clf_Loss: 2.1457173824310303, Test_Filter_Loss: 1.0850002354345634e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.06%, Test_Ones_Portion: 3.345741106386413e-07\n",
      "Epoch 146, Total Loss: 2.099609851837158, Clf Loss: 2.099609851837158, Filter Loss: 9.778389085113304e-07, Seq Loss: 1.0, Accuracy Rate: 42.91%, Ones Portion: 2.9096389653204824e-07,             Test_Total_Loss: 2.149256706237793, Test_Clf_Loss: 2.149256706237793, Test_Filter_Loss: 1.0649943078533397e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.97%, Test_Ones_Portion: 3.229388596537319e-07\n",
      "Epoch 147, Total Loss: 2.099708080291748, Clf Loss: 2.099708080291748, Filter Loss: 9.92764626062126e-07, Seq Loss: 1.0, Accuracy Rate: 42.82%, Ones Portion: 2.9721110195168876e-07,             Test_Total_Loss: 2.144359827041626, Test_Clf_Loss: 2.144359827041626, Test_Filter_Loss: 1.060826662069303e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 42.16%, Test_Ones_Portion: 3.130765833248006e-07\n",
      "Epoch 148, Total Loss: 2.0995514392852783, Clf Loss: 2.0995514392852783, Filter Loss: 9.959094313671812e-07, Seq Loss: 0.9999998807907104, Accuracy Rate: 42.86%, Ones Portion: 2.965989267522673e-07,             Test_Total_Loss: 2.1591804027557373, Test_Clf_Loss: 2.1591804027557373, Test_Filter_Loss: 1.0097461426994414e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.97%, Test_Ones_Portion: 3.193651991750812e-07\n",
      "Epoch 149, Total Loss: 2.104257583618164, Clf Loss: 2.104257583618164, Filter Loss: 9.365833193442086e-07, Seq Loss: 1.0, Accuracy Rate: 42.76%, Ones Portion: 2.9419177849376865e-07,             Test_Total_Loss: 2.1578450202941895, Test_Clf_Loss: 2.1578450202941895, Test_Filter_Loss: 9.770282076715375e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.82%, Test_Ones_Portion: 3.1122050359044806e-07\n",
      "Epoch 150, Total Loss: 2.103151798248291, Clf Loss: 2.103151798248291, Filter Loss: 9.011962447402766e-07, Seq Loss: 0.9999998807907104, Accuracy Rate: 42.78%, Ones Portion: 2.722435965551995e-07,             Test_Total_Loss: 2.156376361846924, Test_Clf_Loss: 2.156376361846924, Test_Filter_Loss: 1.0135055390492198e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.72%, Test_Ones_Portion: 3.0371302273124456e-07\n",
      "Epoch 151, Total Loss: 2.101388692855835, Clf Loss: 2.101388692855835, Filter Loss: 9.005208880807913e-07, Seq Loss: 1.0, Accuracy Rate: 42.82%, Ones Portion: 2.717029303767049e-07,             Test_Total_Loss: 2.1611547470092773, Test_Clf_Loss: 2.1611547470092773, Test_Filter_Loss: 9.691599416328245e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.38%, Test_Ones_Portion: 3.0523665373038966e-07\n",
      "Epoch 152, Total Loss: 2.1037137508392334, Clf Loss: 2.1037137508392334, Filter Loss: 9.410342727278476e-07, Seq Loss: 1.0, Accuracy Rate: 42.80%, Ones Portion: 2.767411331205949e-07,             Test_Total_Loss: 2.1557817459106445, Test_Clf_Loss: 2.1557817459106445, Test_Filter_Loss: 9.924422101903474e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.67%, Test_Ones_Portion: 3.0349136181939684e-07\n",
      "Epoch 153, Total Loss: 2.099252462387085, Clf Loss: 2.099252462387085, Filter Loss: 9.919489230014733e-07, Seq Loss: 1.0, Accuracy Rate: 42.74%, Ones Portion: 3.05317371385172e-07,             Test_Total_Loss: 2.157623529434204, Test_Clf_Loss: 2.157623529434204, Test_Filter_Loss: 1.0117008741872269e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.63%, Test_Ones_Portion: 3.0631710501438647e-07\n",
      "Epoch 154, Total Loss: 2.098799467086792, Clf Loss: 2.098799467086792, Filter Loss: 9.544318118059891e-07, Seq Loss: 1.0, Accuracy Rate: 42.75%, Ones Portion: 2.8112108907407674e-07,             Test_Total_Loss: 2.161482810974121, Test_Clf_Loss: 2.161482810974121, Test_Filter_Loss: 1.002453473120113e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.63%, Test_Ones_Portion: 2.9725819672421494e-07\n",
      "Epoch 155, Total Loss: 2.10073184967041, Clf Loss: 2.10073184967041, Filter Loss: 1.0219187061011326e-06, Seq Loss: 1.0, Accuracy Rate: 42.85%, Ones Portion: 3.0725450983482006e-07,             Test_Total_Loss: 2.1527907848358154, Test_Clf_Loss: 2.1527907848358154, Test_Filter_Loss: 1.082824951481598e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.77%, Test_Ones_Portion: 3.039069156329788e-07\n",
      "Epoch 156, Total Loss: 2.1013102531433105, Clf Loss: 2.1013102531433105, Filter Loss: 1.0018023886004812e-06, Seq Loss: 1.0, Accuracy Rate: 42.80%, Ones Portion: 2.9235883403089247e-07,             Test_Total_Loss: 2.160759449005127, Test_Clf_Loss: 2.160759449005127, Test_Filter_Loss: 1.0187341104028746e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.63%, Test_Ones_Portion: 2.8304660304456775e-07\n",
      "Epoch 157, Total Loss: 2.1070568561553955, Clf Loss: 2.1070568561553955, Filter Loss: 9.496315556134505e-07, Seq Loss: 1.0, Accuracy Rate: 42.59%, Ones Portion: 2.679916804027016e-07,             Test_Total_Loss: 2.1654295921325684, Test_Clf_Loss: 2.1654295921325684, Test_Filter_Loss: 9.815638577492791e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.53%, Test_Ones_Portion: 2.8066415325156413e-07\n",
      "Epoch 158, Total Loss: 2.1127710342407227, Clf Loss: 2.1127710342407227, Filter Loss: 9.211236147166346e-07, Seq Loss: 1.0, Accuracy Rate: 42.55%, Ones Portion: 2.571767936387914e-07,             Test_Total_Loss: 2.166083574295044, Test_Clf_Loss: 2.166083574295044, Test_Filter_Loss: 9.75585635387688e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.63%, Test_Ones_Portion: 2.6780998041431303e-07\n",
      "Epoch 159, Total Loss: 2.113833427429199, Clf Loss: 2.113833427429199, Filter Loss: 9.857500344878645e-07, Seq Loss: 1.0, Accuracy Rate: 42.55%, Ones Portion: 2.78583911494934e-07,             Test_Total_Loss: 2.1736490726470947, Test_Clf_Loss: 2.1736490726470947, Test_Filter_Loss: 9.639811651140917e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.29%, Test_Ones_Portion: 2.5930515334948723e-07\n",
      "Epoch 160, Total Loss: 2.11122989654541, Clf Loss: 2.11122989654541, Filter Loss: 9.726128382681054e-07, Seq Loss: 1.0, Accuracy Rate: 42.52%, Ones Portion: 2.749229679466225e-07,             Test_Total_Loss: 2.173524856567383, Test_Clf_Loss: 2.173524856567383, Test_Filter_Loss: 1.0198957625107141e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.05%, Test_Ones_Portion: 2.767648936696787e-07\n",
      "Epoch 161, Total Loss: 2.1173102855682373, Clf Loss: 2.1173102855682373, Filter Loss: 9.383200563206628e-07, Seq Loss: 1.0, Accuracy Rate: 42.48%, Ones Portion: 2.614030165659642e-07,             Test_Total_Loss: 2.183556079864502, Test_Clf_Loss: 2.183556079864502, Test_Filter_Loss: 9.423278015674441e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.05%, Test_Ones_Portion: 2.674566701443837e-07\n",
      "Epoch 162, Total Loss: 2.1233315467834473, Clf Loss: 2.1233315467834473, Filter Loss: 8.927327144192532e-07, Seq Loss: 1.0, Accuracy Rate: 42.40%, Ones Portion: 2.406389114639751e-07,             Test_Total_Loss: 2.1866674423217773, Test_Clf_Loss: 2.1866674423217773, Test_Filter_Loss: 9.884221299216733e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.90%, Test_Ones_Portion: 2.7033777882934373e-07\n",
      "Epoch 163, Total Loss: 2.117422342300415, Clf Loss: 2.117422342300415, Filter Loss: 9.102293461182853e-07, Seq Loss: 1.0, Accuracy Rate: 42.42%, Ones Portion: 2.4204351234402566e-07,             Test_Total_Loss: 2.1767446994781494, Test_Clf_Loss: 2.1767446994781494, Test_Filter_Loss: 1.0036653748102253e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.14%, Test_Ones_Portion: 2.691742793103913e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164, Total Loss: 2.119631767272949, Clf Loss: 2.119631767272949, Filter Loss: 9.30080091166019e-07, Seq Loss: 1.0, Accuracy Rate: 42.43%, Ones Portion: 2.3683966787757527e-07,             Test_Total_Loss: 2.17671275138855, Test_Clf_Loss: 2.17671275138855, Test_Filter_Loss: 1.0025116807810264e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 41.05%, Test_Ones_Portion: 2.634951101754268e-07\n",
      "Epoch 165, Total Loss: 2.1228525638580322, Clf Loss: 2.1228525638580322, Filter Loss: 8.749279913899954e-07, Seq Loss: 1.0, Accuracy Rate: 42.31%, Ones Portion: 2.2205536254205072e-07,             Test_Total_Loss: 2.1869521141052246, Test_Clf_Loss: 2.1869521141052246, Test_Filter_Loss: 9.8160273864778e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.71%, Test_Ones_Portion: 2.5615386789468175e-07\n",
      "Epoch 166, Total Loss: 2.1202759742736816, Clf Loss: 2.1202759742736816, Filter Loss: 9.857163831838989e-07, Seq Loss: 1.0, Accuracy Rate: 42.49%, Ones Portion: 2.32034153668792e-07,             Test_Total_Loss: 2.193272829055786, Test_Clf_Loss: 2.193272829055786, Test_Filter_Loss: 1.0161446653000894e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.46%, Test_Ones_Portion: 2.4504495854671404e-07\n",
      "Epoch 167, Total Loss: 2.126256227493286, Clf Loss: 2.126256227493286, Filter Loss: 1.0191972705797525e-06, Seq Loss: 1.0, Accuracy Rate: 42.37%, Ones Portion: 2.236259177834654e-07,             Test_Total_Loss: 2.201972246170044, Test_Clf_Loss: 2.201972246170044, Test_Filter_Loss: 1.0532899068493862e-06, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.46%, Test_Ones_Portion: 2.3792530612354312e-07\n",
      "Epoch 168, Total Loss: 2.1243860721588135, Clf Loss: 2.1243860721588135, Filter Loss: 9.956347639672458e-07, Seq Loss: 1.0, Accuracy Rate: 42.17%, Ones Portion: 2.230850242312954e-07,             Test_Total_Loss: 2.196559429168701, Test_Clf_Loss: 2.196559429168701, Test_Filter_Loss: 9.61293039836164e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.27%, Test_Ones_Portion: 2.2678874245229963e-07\n",
      "Epoch 169, Total Loss: 2.1287856101989746, Clf Loss: 2.1287856101989746, Filter Loss: 9.250169910046679e-07, Seq Loss: 1.0, Accuracy Rate: 42.18%, Ones Portion: 2.2311390068807668e-07,             Test_Total_Loss: 2.1982243061065674, Test_Clf_Loss: 2.1982243061065674, Test_Filter_Loss: 9.100225497604697e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.46%, Test_Ones_Portion: 2.0955749846507388e-07\n",
      "Epoch 170, Total Loss: 2.130147933959961, Clf Loss: 2.130147933959961, Filter Loss: 8.556440889151418e-07, Seq Loss: 1.0, Accuracy Rate: 42.17%, Ones Portion: 1.9947333385061938e-07,             Test_Total_Loss: 2.1969571113586426, Test_Clf_Loss: 2.1969571113586426, Test_Filter_Loss: 9.50032358559838e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.22%, Test_Ones_Portion: 2.0950210455339402e-07\n",
      "Epoch 171, Total Loss: 2.1315770149230957, Clf Loss: 2.1315770149230957, Filter Loss: 8.623067628832359e-07, Seq Loss: 1.0, Accuracy Rate: 42.09%, Ones Portion: 1.9073721091444895e-07,             Test_Total_Loss: 2.1901276111602783, Test_Clf_Loss: 2.1901276111602783, Test_Filter_Loss: 9.567125971443602e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.42%, Test_Ones_Portion: 2.169819026676123e-07\n",
      "Epoch 172, Total Loss: 2.1316306591033936, Clf Loss: 2.1316306591033936, Filter Loss: 8.770079489295313e-07, Seq Loss: 1.0, Accuracy Rate: 42.01%, Ones Portion: 2.0057581195942475e-07,             Test_Total_Loss: 2.1843576431274414, Test_Clf_Loss: 2.1843576431274414, Test_Filter_Loss: 9.491786272519676e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.46%, Test_Ones_Portion: 2.0606692885394295e-07\n",
      "Epoch 173, Total Loss: 2.1355648040771484, Clf Loss: 2.1355648040771484, Filter Loss: 8.582363193454512e-07, Seq Loss: 1.0, Accuracy Rate: 41.95%, Ones Portion: 1.9242312987444166e-07,             Test_Total_Loss: 2.1939313411712646, Test_Clf_Loss: 2.1939313411712646, Test_Filter_Loss: 8.740860266698292e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.46%, Test_Ones_Portion: 2.0105267140024807e-07\n",
      "Epoch 174, Total Loss: 2.14235520362854, Clf Loss: 2.14235520362854, Filter Loss: 8.395557529183861e-07, Seq Loss: 1.0, Accuracy Rate: 41.71%, Ones Portion: 1.8275449065185967e-07,             Test_Total_Loss: 2.1951470375061035, Test_Clf_Loss: 2.1951470375061035, Test_Filter_Loss: 8.49719583584374e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.51%, Test_Ones_Portion: 1.922985575220082e-07\n",
      "Epoch 175, Total Loss: 2.1465094089508057, Clf Loss: 2.1465094089508057, Filter Loss: 7.373943731181498e-07, Seq Loss: 1.0, Accuracy Rate: 41.73%, Ones Portion: 1.5446978807176492e-07,             Test_Total_Loss: 2.19801926612854, Test_Clf_Loss: 2.19801926612854, Test_Filter_Loss: 7.388244966932689e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.27%, Test_Ones_Portion: 1.811065573065207e-07\n",
      "Epoch 176, Total Loss: 2.145979881286621, Clf Loss: 2.145979881286621, Filter Loss: 6.87258932430268e-07, Seq Loss: 1.0, Accuracy Rate: 41.73%, Ones Portion: 1.4731561748249078e-07,             Test_Total_Loss: 2.1957147121429443, Test_Clf_Loss: 2.1957147121429443, Test_Filter_Loss: 7.834692041797098e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.51%, Test_Ones_Portion: 1.8476333707440062e-07\n",
      "Epoch 177, Total Loss: 2.1467065811157227, Clf Loss: 2.1467065811157227, Filter Loss: 7.337606007240538e-07, Seq Loss: 1.0, Accuracy Rate: 41.67%, Ones Portion: 1.506473523704699e-07,             Test_Total_Loss: 2.191053628921509, Test_Clf_Loss: 2.191053628921509, Test_Filter_Loss: 7.264533792294969e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.42%, Test_Ones_Portion: 1.8010923952260782e-07\n",
      "Epoch 178, Total Loss: 2.1471025943756104, Clf Loss: 2.1471025943756104, Filter Loss: 6.547340376528155e-07, Seq Loss: 1.0, Accuracy Rate: 41.77%, Ones Portion: 1.438934162933947e-07,             Test_Total_Loss: 2.1925487518310547, Test_Clf_Loss: 2.1925487518310547, Test_Filter_Loss: 7.319939072658599e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.46%, Test_Ones_Portion: 1.7963829179734603e-07\n",
      "Epoch 179, Total Loss: 2.1553637981414795, Clf Loss: 2.1553637981414795, Filter Loss: 7.079223678374547e-07, Seq Loss: 1.0, Accuracy Rate: 41.57%, Ones Portion: 1.3848237756519666e-07,             Test_Total_Loss: 2.188594341278076, Test_Clf_Loss: 2.188594341278076, Test_Filter_Loss: 7.54145276005147e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.22%, Test_Ones_Portion: 1.792227379837641e-07\n",
      "Epoch 180, Total Loss: 2.151463508605957, Clf Loss: 2.151463508605957, Filter Loss: 7.049201258269022e-07, Seq Loss: 1.0, Accuracy Rate: 41.60%, Ones Portion: 1.483633553789332e-07,             Test_Total_Loss: 2.1997854709625244, Test_Clf_Loss: 2.1997854709625244, Test_Filter_Loss: 7.571239848402911e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.27%, Test_Ones_Portion: 1.7221390180566232e-07\n",
      "Epoch 181, Total Loss: 2.1541876792907715, Clf Loss: 2.1541876792907715, Filter Loss: 6.942250365682412e-07, Seq Loss: 1.0, Accuracy Rate: 41.49%, Ones Portion: 1.3662408093750855e-07,             Test_Total_Loss: 2.198103427886963, Test_Clf_Loss: 2.198103427886963, Test_Filter_Loss: 6.861176871097996e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.51%, Test_Ones_Portion: 1.6983143780180399e-07\n",
      "Epoch 182, Total Loss: 2.157209873199463, Clf Loss: 2.157209873199463, Filter Loss: 7.00254474850226e-07, Seq Loss: 1.0, Accuracy Rate: 41.45%, Ones Portion: 1.3452516611778265e-07,             Test_Total_Loss: 2.2054500579833984, Test_Clf_Loss: 2.2054500579833984, Test_Filter_Loss: 6.735480155839468e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 1.4677573290100554e-07\n",
      "Epoch 183, Total Loss: 2.1613597869873047, Clf Loss: 2.1613597869873047, Filter Loss: 6.787975621591613e-07, Seq Loss: 1.0, Accuracy Rate: 41.44%, Ones Portion: 1.2705238816579367e-07,             Test_Total_Loss: 2.207139730453491, Test_Clf_Loss: 2.207139730453491, Test_Filter_Loss: 6.399999961104186e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.98%, Test_Ones_Portion: 1.4093041045271093e-07\n",
      "Epoch 184, Total Loss: 2.155298948287964, Clf Loss: 2.155298948287964, Filter Loss: 6.444373639169498e-07, Seq Loss: 1.0, Accuracy Rate: 41.53%, Ones Portion: 1.3452321923068666e-07,             Test_Total_Loss: 2.20729660987854, Test_Clf_Loss: 2.20729660987854, Test_Filter_Loss: 6.49387288831349e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.32%, Test_Ones_Portion: 1.476899313956892e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185, Total Loss: 2.1564526557922363, Clf Loss: 2.1564526557922363, Filter Loss: 6.498304401247879e-07, Seq Loss: 1.0, Accuracy Rate: 41.51%, Ones Portion: 1.3352931205190544e-07,             Test_Total_Loss: 2.204991340637207, Test_Clf_Loss: 2.204991340637207, Test_Filter_Loss: 7.02462557455874e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.22%, Test_Ones_Portion: 1.4943522330668202e-07\n",
      "Epoch 186, Total Loss: 2.1571624279022217, Clf Loss: 2.1571624279022217, Filter Loss: 6.778421379749489e-07, Seq Loss: 1.0, Accuracy Rate: 41.54%, Ones Portion: 1.301673648868018e-07,             Test_Total_Loss: 2.212212562561035, Test_Clf_Loss: 2.212212562561035, Test_Filter_Loss: 6.873644338156737e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.22%, Test_Ones_Portion: 1.4774533951822377e-07\n",
      "Epoch 187, Total Loss: 2.1596877574920654, Clf Loss: 2.1596877574920654, Filter Loss: 6.256728966036462e-07, Seq Loss: 1.0, Accuracy Rate: 41.44%, Ones Portion: 1.239151288245921e-07,             Test_Total_Loss: 2.2073097229003906, Test_Clf_Loss: 2.2073097229003906, Test_Filter_Loss: 6.199799145178986e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.37%, Test_Ones_Portion: 1.3965608047783462e-07\n",
      "Epoch 188, Total Loss: 2.1572980880737305, Clf Loss: 2.1572980880737305, Filter Loss: 5.885085556656122e-07, Seq Loss: 1.0, Accuracy Rate: 41.43%, Ones Portion: 1.2335725330103742e-07,             Test_Total_Loss: 2.213024854660034, Test_Clf_Loss: 2.213024854660034, Test_Filter_Loss: 5.717202498090046e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.98%, Test_Ones_Portion: 1.3588847025403084e-07\n",
      "Epoch 189, Total Loss: 2.1537795066833496, Clf Loss: 2.1537795066833496, Filter Loss: 6.438593800339731e-07, Seq Loss: 1.0, Accuracy Rate: 41.54%, Ones Portion: 1.3824626421410358e-07,             Test_Total_Loss: 2.206130027770996, Test_Clf_Loss: 2.206130027770996, Test_Filter_Loss: 7.114240361261182e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.17%, Test_Ones_Portion: 1.4289733485384204e-07\n",
      "Epoch 190, Total Loss: 2.1541266441345215, Clf Loss: 2.1541266441345215, Filter Loss: 6.777809744562546e-07, Seq Loss: 1.0, Accuracy Rate: 41.61%, Ones Portion: 1.325226861581541e-07,             Test_Total_Loss: 2.213930368423462, Test_Clf_Loss: 2.213930368423462, Test_Filter_Loss: 6.538570573866309e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.27%, Test_Ones_Portion: 1.3602699766579462e-07\n",
      "Epoch 191, Total Loss: 2.1570687294006348, Clf Loss: 2.1570687294006348, Filter Loss: 6.868825153105718e-07, Seq Loss: 1.0, Accuracy Rate: 41.50%, Ones Portion: 1.3297464818151639e-07,             Test_Total_Loss: 2.208601951599121, Test_Clf_Loss: 2.208601951599121, Test_Filter_Loss: 7.598192723889952e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.17%, Test_Ones_Portion: 1.5234404315833672e-07\n",
      "Epoch 192, Total Loss: 2.1538803577423096, Clf Loss: 2.1538803577423096, Filter Loss: 7.388458129753417e-07, Seq Loss: 1.0, Accuracy Rate: 41.54%, Ones Portion: 1.3951722621641238e-07,             Test_Total_Loss: 2.2103397846221924, Test_Clf_Loss: 2.2103397846221924, Test_Filter_Loss: 7.117660629774036e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.46%, Test_Ones_Portion: 1.4353450694670755e-07\n",
      "Epoch 193, Total Loss: 2.1538095474243164, Clf Loss: 2.1538095474243164, Filter Loss: 7.330926337090204e-07, Seq Loss: 1.0, Accuracy Rate: 41.63%, Ones Portion: 1.379725773631435e-07,             Test_Total_Loss: 2.2062411308288574, Test_Clf_Loss: 2.2062411308288574, Test_Filter_Loss: 7.322136070797569e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.27%, Test_Ones_Portion: 1.4691426031276933e-07\n",
      "Epoch 194, Total Loss: 2.1577858924865723, Clf Loss: 2.1577858924865723, Filter Loss: 7.450698831235059e-07, Seq Loss: 1.0, Accuracy Rate: 41.48%, Ones Portion: 1.3624395478473161e-07,             Test_Total_Loss: 2.2016210556030273, Test_Clf_Loss: 2.2016210556030273, Test_Filter_Loss: 7.306677503038372e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.51%, Test_Ones_Portion: 1.4951832838505652e-07\n",
      "Epoch 195, Total Loss: 2.158512592315674, Clf Loss: 2.158512592315674, Filter Loss: 7.350675446105015e-07, Seq Loss: 1.0, Accuracy Rate: 41.56%, Ones Portion: 1.3963236256131495e-07,             Test_Total_Loss: 2.2073917388916016, Test_Clf_Loss: 2.2073917388916016, Test_Filter_Loss: 7.352414286287967e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.37%, Test_Ones_Portion: 1.4630478517574375e-07\n",
      "Epoch 196, Total Loss: 2.1528005599975586, Clf Loss: 2.1528005599975586, Filter Loss: 7.138633009162731e-07, Seq Loss: 1.0, Accuracy Rate: 41.59%, Ones Portion: 1.3458900127716333e-07,             Test_Total_Loss: 2.220071315765381, Test_Clf_Loss: 2.220071315765381, Test_Filter_Loss: 6.987232268329535e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.88%, Test_Ones_Portion: 1.3785539465516194e-07\n",
      "Epoch 197, Total Loss: 2.156252145767212, Clf Loss: 2.156252145767212, Filter Loss: 7.148484542085498e-07, Seq Loss: 1.0, Accuracy Rate: 41.48%, Ones Portion: 1.3649366792378714e-07,             Test_Total_Loss: 2.2330925464630127, Test_Clf_Loss: 2.2330925464630127, Test_Filter_Loss: 7.335139571296168e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.08%, Test_Ones_Portion: 1.2330826848483412e-07\n",
      "Epoch 198, Total Loss: 2.1567459106445312, Clf Loss: 2.1567459106445312, Filter Loss: 7.671131356801197e-07, Seq Loss: 1.0, Accuracy Rate: 41.69%, Ones Portion: 1.3995642689224042e-07,             Test_Total_Loss: 2.2275044918060303, Test_Clf_Loss: 2.2275044918060303, Test_Filter_Loss: 7.538403110629588e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.17%, Test_Ones_Portion: 1.2474880861645943e-07\n",
      "Epoch 199, Total Loss: 2.1554386615753174, Clf Loss: 2.1554386615753174, Filter Loss: 7.378879445241182e-07, Seq Loss: 1.0, Accuracy Rate: 41.61%, Ones Portion: 1.3968163159461255e-07,             Test_Total_Loss: 2.225132942199707, Test_Clf_Loss: 2.225132942199707, Test_Filter_Loss: 7.527525553996384e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.32%, Test_Ones_Portion: 1.2286500350455754e-07\n",
      "Epoch 200, Total Loss: 2.1556131839752197, Clf Loss: 2.1556131839752197, Filter Loss: 7.518376605730737e-07, Seq Loss: 1.0, Accuracy Rate: 41.59%, Ones Portion: 1.4548666626978957e-07,             Test_Total_Loss: 2.225142002105713, Test_Clf_Loss: 2.225142002105713, Test_Filter_Loss: 7.250167755046277e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.42%, Test_Ones_Portion: 1.2067646082414285e-07\n",
      "Epoch 201, Total Loss: 2.1539671421051025, Clf Loss: 2.1539671421051025, Filter Loss: 7.060814937176474e-07, Seq Loss: 1.0, Accuracy Rate: 41.56%, Ones Portion: 1.329171652741934e-07,             Test_Total_Loss: 2.2267510890960693, Test_Clf_Loss: 2.2267510890960693, Test_Filter_Loss: 6.668385594821302e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.17%, Test_Ones_Portion: 1.1488655360381017e-07\n",
      "Epoch 202, Total Loss: 2.1587767601013184, Clf Loss: 2.1587767601013184, Filter Loss: 5.820995738758938e-07, Seq Loss: 1.0, Accuracy Rate: 41.54%, Ones Portion: 1.2139346949879837e-07,             Test_Total_Loss: 2.229001760482788, Test_Clf_Loss: 2.229001760482788, Test_Filter_Loss: 5.925468258283217e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.22%, Test_Ones_Portion: 1.0962300223127386e-07\n",
      "Epoch 203, Total Loss: 2.1551132202148438, Clf Loss: 2.1551132202148438, Filter Loss: 5.808865353174042e-07, Seq Loss: 1.0, Accuracy Rate: 41.60%, Ones Portion: 1.242222111841329e-07,             Test_Total_Loss: 2.2314748764038086, Test_Clf_Loss: 2.2314748764038086, Test_Filter_Loss: 5.752475544795743e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.32%, Test_Ones_Portion: 1.0984462051055743e-07\n",
      "Epoch 204, Total Loss: 2.1559674739837646, Clf Loss: 2.1559674739837646, Filter Loss: 6.394871547854564e-07, Seq Loss: 1.0, Accuracy Rate: 41.60%, Ones Portion: 1.346071911711988e-07,             Test_Total_Loss: 2.224658250808716, Test_Clf_Loss: 2.224658250808716, Test_Filter_Loss: 6.561456302733859e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.37%, Test_Ones_Portion: 1.1325208504331385e-07\n",
      "Epoch 205, Total Loss: 2.161134719848633, Clf Loss: 2.161134719848633, Filter Loss: 7.070943865983281e-07, Seq Loss: 1.0, Accuracy Rate: 41.57%, Ones Portion: 1.405984448865638e-07,             Test_Total_Loss: 2.22611141204834, Test_Clf_Loss: 2.22611141204834, Test_Filter_Loss: 6.484175969490025e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.46%, Test_Ones_Portion: 1.118669388233684e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206, Total Loss: 2.160193920135498, Clf Loss: 2.160193920135498, Filter Loss: 6.811404773543472e-07, Seq Loss: 1.0, Accuracy Rate: 41.50%, Ones Portion: 1.3104596519042389e-07,             Test_Total_Loss: 2.232536554336548, Test_Clf_Loss: 2.232536554336548, Test_Filter_Loss: 6.581620937140542e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.27%, Test_Ones_Portion: 1.0740675548959189e-07\n",
      "Epoch 207, Total Loss: 2.1606738567352295, Clf Loss: 2.1606738567352295, Filter Loss: 7.281432772288099e-07, Seq Loss: 1.0, Accuracy Rate: 41.57%, Ones Portion: 1.3271800014535984e-07,             Test_Total_Loss: 2.235502243041992, Test_Clf_Loss: 2.235502243041992, Test_Filter_Loss: 7.068653644637379e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 1.0915204029515735e-07\n",
      "Epoch 208, Total Loss: 2.15777850151062, Clf Loss: 2.15777850151062, Filter Loss: 7.019247050266131e-07, Seq Loss: 1.0, Accuracy Rate: 41.60%, Ones Portion: 1.3588407909992384e-07,             Test_Total_Loss: 2.2430858612060547, Test_Clf_Loss: 2.2430858612060547, Test_Filter_Loss: 6.310511935225804e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.84%, Test_Ones_Portion: 1.0322361276848824e-07\n",
      "Epoch 209, Total Loss: 2.169034719467163, Clf Loss: 2.169034719467163, Filter Loss: 6.401410246326122e-07, Seq Loss: 1.0, Accuracy Rate: 41.39%, Ones Portion: 1.1500274155196166e-07,             Test_Total_Loss: 2.2408761978149414, Test_Clf_Loss: 2.2408761978149414, Test_Filter_Loss: 6.36149991350976e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.84%, Test_Ones_Portion: 9.654721111473918e-08\n",
      "Epoch 210, Total Loss: 2.1681065559387207, Clf Loss: 2.1681065559387207, Filter Loss: 6.031650059412641e-07, Seq Loss: 1.0, Accuracy Rate: 41.38%, Ones Portion: 1.1223752949263144e-07,             Test_Total_Loss: 2.2539658546447754, Test_Clf_Loss: 2.2539658546447754, Test_Filter_Loss: 5.515323664440075e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.79%, Test_Ones_Portion: 9.358299024597727e-08\n",
      "Epoch 211, Total Loss: 2.167522430419922, Clf Loss: 2.167522430419922, Filter Loss: 5.94276627907675e-07, Seq Loss: 1.0, Accuracy Rate: 41.44%, Ones Portion: 1.1480319983547815e-07,             Test_Total_Loss: 2.247274160385132, Test_Clf_Loss: 2.247274160385132, Test_Filter_Loss: 6.532046654683654e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.93%, Test_Ones_Portion: 1.0327902799645017e-07\n",
      "Epoch 212, Total Loss: 2.1648895740509033, Clf Loss: 2.1648895740509033, Filter Loss: 6.756616812708671e-07, Seq Loss: 1.0, Accuracy Rate: 41.48%, Ones Portion: 1.2217570599659666e-07,             Test_Total_Loss: 2.2499146461486816, Test_Clf_Loss: 2.2499146461486816, Test_Filter_Loss: 6.452748380070261e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.79%, Test_Ones_Portion: 1.0530134630926113e-07\n",
      "Epoch 213, Total Loss: 2.167964220046997, Clf Loss: 2.167964220046997, Filter Loss: 6.868020818728837e-07, Seq Loss: 1.0, Accuracy Rate: 41.37%, Ones Portion: 1.1780726794086149e-07,             Test_Total_Loss: 2.249851942062378, Test_Clf_Loss: 2.249851942062378, Test_Filter_Loss: 6.578554234693001e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.79%, Test_Ones_Portion: 1.0103509140435563e-07\n",
      "Epoch 214, Total Loss: 2.1622092723846436, Clf Loss: 2.1622092723846436, Filter Loss: 7.126462264750444e-07, Seq Loss: 1.0, Accuracy Rate: 41.43%, Ones Portion: 1.260058155594379e-07,             Test_Total_Loss: 2.245083808898926, Test_Clf_Loss: 2.245083808898926, Test_Filter_Loss: 6.742208711330022e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.98%, Test_Ones_Portion: 1.0305739550631188e-07\n",
      "Epoch 215, Total Loss: 2.164977550506592, Clf Loss: 2.164977550506592, Filter Loss: 6.841459594397747e-07, Seq Loss: 1.0, Accuracy Rate: 41.43%, Ones Portion: 1.229462043284002e-07,             Test_Total_Loss: 2.2487242221832275, Test_Clf_Loss: 2.2487242221832275, Test_Filter_Loss: 6.627283823945618e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.84%, Test_Ones_Portion: 1.033898300306646e-07\n",
      "Epoch 216, Total Loss: 2.1683833599090576, Clf Loss: 2.1683833599090576, Filter Loss: 6.892343549225188e-07, Seq Loss: 1.0, Accuracy Rate: 41.46%, Ones Portion: 1.2440862917628692e-07,             Test_Total_Loss: 2.244405508041382, Test_Clf_Loss: 2.244405508041382, Test_Filter_Loss: 6.74250372867391e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.93%, Test_Ones_Portion: 1.0906893521678285e-07\n",
      "Epoch 217, Total Loss: 2.1631436347961426, Clf Loss: 2.1631436347961426, Filter Loss: 7.223811735457275e-07, Seq Loss: 1.0, Accuracy Rate: 41.54%, Ones Portion: 1.2010848138288566e-07,             Test_Total_Loss: 2.2596590518951416, Test_Clf_Loss: 2.2596590518951416, Test_Filter_Loss: 6.978510782573721e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.74%, Test_Ones_Portion: 1.1280884137931935e-07\n",
      "Epoch 218, Total Loss: 2.169473886489868, Clf Loss: 2.169473886489868, Filter Loss: 7.402572919090744e-07, Seq Loss: 1.0, Accuracy Rate: 41.40%, Ones Portion: 1.1768809571321981e-07,             Test_Total_Loss: 2.243342161178589, Test_Clf_Loss: 2.243342161178589, Test_Filter_Loss: 7.197731974883936e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.88%, Test_Ones_Portion: 1.1183924186752847e-07\n",
      "Epoch 219, Total Loss: 2.1706626415252686, Clf Loss: 2.1706626415252686, Filter Loss: 6.898907827235234e-07, Seq Loss: 1.0, Accuracy Rate: 41.39%, Ones Portion: 1.1461344229246606e-07,             Test_Total_Loss: 2.2438037395477295, Test_Clf_Loss: 2.2438037395477295, Test_Filter_Loss: 6.201150881679496e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.98%, Test_Ones_Portion: 9.804316647432643e-08\n",
      "Epoch 220, Total Loss: 2.1696245670318604, Clf Loss: 2.1696245670318604, Filter Loss: 6.656346158706583e-07, Seq Loss: 1.0, Accuracy Rate: 41.34%, Ones Portion: 1.1177184688904163e-07,             Test_Total_Loss: 2.2531678676605225, Test_Clf_Loss: 2.2531678676605225, Test_Filter_Loss: 6.320362899714382e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.88%, Test_Ones_Portion: 9.862493044465737e-08\n",
      "Epoch 221, Total Loss: 2.1756515502929688, Clf Loss: 2.1756515502929688, Filter Loss: 6.810586796746065e-07, Seq Loss: 1.0, Accuracy Rate: 41.31%, Ones Portion: 1.0893845825421522e-07,             Test_Total_Loss: 2.253457546234131, Test_Clf_Loss: 2.253457546234131, Test_Filter_Loss: 6.284945470724779e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.88%, Test_Ones_Portion: 1.0081345180878998e-07\n",
      "Epoch 222, Total Loss: 2.1708984375, Clf Loss: 2.1708984375, Filter Loss: 6.300762152022799e-07, Seq Loss: 1.0, Accuracy Rate: 41.36%, Ones Portion: 1.1046851966511895e-07,             Test_Total_Loss: 2.253237247467041, Test_Clf_Loss: 2.253237247467041, Test_Filter_Loss: 5.893753609598207e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.98%, Test_Ones_Portion: 9.851411419958822e-08\n",
      "Epoch 223, Total Loss: 2.171726942062378, Clf Loss: 2.171726942062378, Filter Loss: 6.576749456144171e-07, Seq Loss: 1.0, Accuracy Rate: 41.26%, Ones Portion: 1.1101388963652425e-07,             Test_Total_Loss: 2.25646710395813, Test_Clf_Loss: 2.25646710395813, Test_Filter_Loss: 5.574409556174942e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 9.363839126308449e-08\n",
      "Epoch 224, Total Loss: 2.1713922023773193, Clf Loss: 2.1713922023773193, Filter Loss: 5.929697408646462e-07, Seq Loss: 1.0, Accuracy Rate: 41.25%, Ones Portion: 1.0937318251080796e-07,             Test_Total_Loss: 2.2472801208496094, Test_Clf_Loss: 2.2472801208496094, Test_Filter_Loss: 5.793849595647771e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.74%, Test_Ones_Portion: 9.90958710644918e-08\n",
      "Epoch 225, Total Loss: 2.172438859939575, Clf Loss: 2.172438859939575, Filter Loss: 5.749293450207915e-07, Seq Loss: 1.0, Accuracy Rate: 41.28%, Ones Portion: 1.0786934723228114e-07,             Test_Total_Loss: 2.2520384788513184, Test_Clf_Loss: 2.2520384788513184, Test_Filter_Loss: 5.821635227221122e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.74%, Test_Ones_Portion: 9.554990043625367e-08\n",
      "Epoch 226, Total Loss: 2.175499677658081, Clf Loss: 2.175499677658081, Filter Loss: 6.3838223240964e-07, Seq Loss: 1.0, Accuracy Rate: 41.32%, Ones Portion: 1.0999087862728629e-07,             Test_Total_Loss: 2.249549150466919, Test_Clf_Loss: 2.249549150466919, Test_Filter_Loss: 5.854312234987447e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.08%, Test_Ones_Portion: 9.868033146176458e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227, Total Loss: 2.1741445064544678, Clf Loss: 2.1741445064544678, Filter Loss: 6.034656507836189e-07, Seq Loss: 1.0, Accuracy Rate: 41.34%, Ones Portion: 1.1153228740568011e-07,             Test_Total_Loss: 2.251171588897705, Test_Clf_Loss: 2.251171588897705, Test_Filter_Loss: 5.312607527230284e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.79%, Test_Ones_Portion: 9.158837599443359e-08\n",
      "Epoch 228, Total Loss: 2.1734964847564697, Clf Loss: 2.1734964847564697, Filter Loss: 5.80153141527262e-07, Seq Loss: 1.0, Accuracy Rate: 41.25%, Ones Portion: 1.0562730068386372e-07,             Test_Total_Loss: 2.25058913230896, Test_Clf_Loss: 2.25058913230896, Test_Filter_Loss: 5.402675355981046e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.93%, Test_Ones_Portion: 9.380460852526085e-08\n",
      "Epoch 229, Total Loss: 2.176816463470459, Clf Loss: 2.176816463470459, Filter Loss: 5.829512588206853e-07, Seq Loss: 1.0, Accuracy Rate: 41.23%, Ones Portion: 1.0524376392595514e-07,             Test_Total_Loss: 2.2466912269592285, Test_Clf_Loss: 2.2466912269592285, Test_Filter_Loss: 5.208710831539065e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 9.302893033691362e-08\n",
      "Epoch 230, Total Loss: 2.173151731491089, Clf Loss: 2.173151731491089, Filter Loss: 5.832523015669722e-07, Seq Loss: 1.0, Accuracy Rate: 41.25%, Ones Portion: 1.0367830327595584e-07,             Test_Total_Loss: 2.2484798431396484, Test_Clf_Loss: 2.2484798431396484, Test_Filter_Loss: 5.885593736820738e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 9.735058625892634e-08\n",
      "Epoch 231, Total Loss: 2.1761386394500732, Clf Loss: 2.1761386394500732, Filter Loss: 6.058423309696082e-07, Seq Loss: 1.0, Accuracy Rate: 41.22%, Ones Portion: 1.116202383855125e-07,             Test_Total_Loss: 2.249568223953247, Test_Clf_Loss: 2.249568223953247, Test_Filter_Loss: 5.506368552232743e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.13%, Test_Ones_Portion: 9.826478475361e-08\n",
      "Epoch 232, Total Loss: 2.175600051879883, Clf Loss: 2.175600051879883, Filter Loss: 5.46391845546168e-07, Seq Loss: 1.0, Accuracy Rate: 41.17%, Ones Portion: 9.692800517768774e-08,             Test_Total_Loss: 2.2500715255737305, Test_Clf_Loss: 2.2500715255737305, Test_Filter_Loss: 4.917974933960068e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.93%, Test_Ones_Portion: 8.768225967514809e-08\n",
      "Epoch 233, Total Loss: 2.178624153137207, Clf Loss: 2.178624153137207, Filter Loss: 4.994280971004628e-07, Seq Loss: 1.0, Accuracy Rate: 41.13%, Ones Portion: 9.682596413540523e-08,             Test_Total_Loss: 2.2370996475219727, Test_Clf_Loss: 2.2370996475219727, Test_Filter_Loss: 5.439645747173927e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 9.615936136242453e-08\n",
      "Epoch 234, Total Loss: 2.169603109359741, Clf Loss: 2.169603109359741, Filter Loss: 5.463037382469338e-07, Seq Loss: 1.0, Accuracy Rate: 41.27%, Ones Portion: 1.0741122480339982e-07,             Test_Total_Loss: 2.2499704360961914, Test_Clf_Loss: 2.2499704360961914, Test_Filter_Loss: 5.060933290224057e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.98%, Test_Ones_Portion: 9.663031619311369e-08\n",
      "Epoch 235, Total Loss: 2.1753249168395996, Clf Loss: 2.1753249168395996, Filter Loss: 5.187202418710513e-07, Seq Loss: 1.0, Accuracy Rate: 41.21%, Ones Portion: 1.0342071732338809e-07,             Test_Total_Loss: 2.2474958896636963, Test_Clf_Loss: 2.2474958896636963, Test_Filter_Loss: 4.834960236621555e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 9.322285166035726e-08\n",
      "Epoch 236, Total Loss: 2.177942991256714, Clf Loss: 2.177942991256714, Filter Loss: 5.205941988606355e-07, Seq Loss: 1.0, Accuracy Rate: 41.15%, Ones Portion: 1.0372197323249566e-07,             Test_Total_Loss: 2.2507941722869873, Test_Clf_Loss: 2.2507941722869873, Test_Filter_Loss: 4.904543402517447e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.88%, Test_Ones_Portion: 9.084039476192629e-08\n",
      "Epoch 237, Total Loss: 2.1763734817504883, Clf Loss: 2.1763734817504883, Filter Loss: 4.614178976680705e-07, Seq Loss: 1.0, Accuracy Rate: 41.11%, Ones Portion: 9.147000668008332e-08,             Test_Total_Loss: 2.254499912261963, Test_Clf_Loss: 2.254499912261963, Test_Filter_Loss: 4.141919873745792e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.93%, Test_Ones_Portion: 8.723901601115358e-08\n",
      "Epoch 238, Total Loss: 2.1766719818115234, Clf Loss: 2.1766719818115234, Filter Loss: 4.656231737953931e-07, Seq Loss: 1.0, Accuracy Rate: 41.19%, Ones Portion: 9.554900515240661e-08,             Test_Total_Loss: 2.2487595081329346, Test_Clf_Loss: 2.2487595081329346, Test_Filter_Loss: 4.3518076608961564e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.93%, Test_Ones_Portion: 9.13944617764173e-08\n",
      "Epoch 239, Total Loss: 2.1800899505615234, Clf Loss: 2.1800899505615234, Filter Loss: 4.5557447947430774e-07, Seq Loss: 1.0, Accuracy Rate: 41.13%, Ones Portion: 9.575340698120272e-08,             Test_Total_Loss: 2.2517905235290527, Test_Clf_Loss: 2.2517905235290527, Test_Filter_Loss: 4.6954451704550593e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.08%, Test_Ones_Portion: 9.014782165195356e-08\n",
      "Epoch 240, Total Loss: 2.1788737773895264, Clf Loss: 2.1788737773895264, Filter Loss: 4.86303861180204e-07, Seq Loss: 1.0, Accuracy Rate: 41.20%, Ones Portion: 9.456363159188186e-08,             Test_Total_Loss: 2.2471976280212402, Test_Clf_Loss: 2.2471976280212402, Test_Filter_Loss: 4.83222208913503e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 9.366609532435177e-08\n",
      "Epoch 241, Total Loss: 2.173353672027588, Clf Loss: 2.173353672027588, Filter Loss: 5.05246191551123e-07, Seq Loss: 1.0, Accuracy Rate: 41.26%, Ones Portion: 1.0093329194660328e-07,             Test_Total_Loss: 2.2547056674957275, Test_Clf_Loss: 2.2547056674957275, Test_Filter_Loss: 4.867781058237597e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.08%, Test_Ones_Portion: 9.294582525853912e-08\n",
      "Epoch 242, Total Loss: 2.1789989471435547, Clf Loss: 2.1789989471435547, Filter Loss: 4.886829287897854e-07, Seq Loss: 1.0, Accuracy Rate: 41.23%, Ones Portion: 9.953634361181685e-08,             Test_Total_Loss: 2.2523410320281982, Test_Clf_Loss: 2.2523410320281982, Test_Filter_Loss: 4.586678130635846e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.13%, Test_Ones_Portion: 9.333366790542641e-08\n",
      "Epoch 243, Total Loss: 2.180058479309082, Clf Loss: 2.180058479309082, Filter Loss: 4.4836511392531975e-07, Seq Loss: 1.0, Accuracy Rate: 41.33%, Ones Portion: 9.249143317902053e-08,             Test_Total_Loss: 2.2484593391418457, Test_Clf_Loss: 2.2484593391418457, Test_Filter_Loss: 4.231484069805447e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 8.743293733459723e-08\n",
      "Epoch 244, Total Loss: 2.177365303039551, Clf Loss: 2.177365303039551, Filter Loss: 4.3465141175147437e-07, Seq Loss: 1.0, Accuracy Rate: 41.17%, Ones Portion: 8.842400234243541e-08,             Test_Total_Loss: 2.253612756729126, Test_Clf_Loss: 2.253612756729126, Test_Filter_Loss: 4.1290763874712866e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.84%, Test_Ones_Portion: 8.034097476183888e-08\n",
      "Epoch 245, Total Loss: 2.1834843158721924, Clf Loss: 2.1834843158721924, Filter Loss: 4.075159267813433e-07, Seq Loss: 1.0, Accuracy Rate: 41.13%, Ones Portion: 8.679376861664423e-08,             Test_Total_Loss: 2.2608771324157715, Test_Clf_Loss: 2.2608771324157715, Test_Filter_Loss: 3.915372701612796e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.98%, Test_Ones_Portion: 7.211388464156698e-08\n",
      "Epoch 246, Total Loss: 2.182781934738159, Clf Loss: 2.182781934738159, Filter Loss: 3.947974676066224e-07, Seq Loss: 1.0, Accuracy Rate: 41.16%, Ones Portion: 8.718613031533096e-08,             Test_Total_Loss: 2.2541301250457764, Test_Clf_Loss: 2.2541301250457764, Test_Filter_Loss: 3.871691376389208e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.93%, Test_Ones_Portion: 7.286185876864693e-08\n",
      "Epoch 247, Total Loss: 2.187588691711426, Clf Loss: 2.187588691711426, Filter Loss: 3.8785802303209493e-07, Seq Loss: 1.0, Accuracy Rate: 40.98%, Ones Portion: 8.525773154133276e-08,             Test_Total_Loss: 2.253387928009033, Test_Clf_Loss: 2.253387928009033, Test_Filter_Loss: 3.684674823034584e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.93%, Test_Ones_Portion: 6.956521048095965e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248, Total Loss: 2.1819446086883545, Clf Loss: 2.1819446086883545, Filter Loss: 3.611830550198647e-07, Seq Loss: 1.0, Accuracy Rate: 41.08%, Ones Portion: 8.714674493148777e-08,             Test_Total_Loss: 2.2494006156921387, Test_Clf_Loss: 2.2494006156921387, Test_Filter_Loss: 3.3913786978700955e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.08%, Test_Ones_Portion: 7.075644248288881e-08\n",
      "Epoch 249, Total Loss: 2.1812307834625244, Clf Loss: 2.1812307834625244, Filter Loss: 3.4775206358972355e-07, Seq Loss: 1.0, Accuracy Rate: 41.15%, Ones Portion: 8.880353163931431e-08,             Test_Total_Loss: 2.2538790702819824, Test_Clf_Loss: 2.2538790702819824, Test_Filter_Loss: 3.651251176961523e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.08%, Test_Ones_Portion: 7.360984000115423e-08\n",
      "Epoch 250, Total Loss: 2.1829030513763428, Clf Loss: 2.1829030513763428, Filter Loss: 3.5041034607274923e-07, Seq Loss: 1.0, Accuracy Rate: 41.11%, Ones Portion: 8.83185435895939e-08,             Test_Total_Loss: 2.249587059020996, Test_Clf_Loss: 2.249587059020996, Test_Filter_Loss: 3.3839171464933315e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 6.848478761867227e-08\n",
      "Epoch 251, Total Loss: 2.1805341243743896, Clf Loss: 2.1805341243743896, Filter Loss: 3.2449571563120116e-07, Seq Loss: 1.0, Accuracy Rate: 41.20%, Ones Portion: 8.302266962800786e-08,             Test_Total_Loss: 2.256164789199829, Test_Clf_Loss: 2.256164789199829, Test_Filter_Loss: 3.1809679512662115e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.88%, Test_Ones_Portion: 7.189225215142869e-08\n",
      "Epoch 252, Total Loss: 2.1791484355926514, Clf Loss: 2.1791484355926514, Filter Loss: 3.143153151086153e-07, Seq Loss: 1.0, Accuracy Rate: 41.17%, Ones Portion: 8.802658868489743e-08,             Test_Total_Loss: 2.256998300552368, Test_Clf_Loss: 2.256998300552368, Test_Filter_Loss: 3.267783483806852e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 7.383147249129252e-08\n",
      "Epoch 253, Total Loss: 2.18160080909729, Clf Loss: 2.18160080909729, Filter Loss: 3.4158750850110664e-07, Seq Loss: 1.0, Accuracy Rate: 41.14%, Ones Portion: 9.038132020577905e-08,             Test_Total_Loss: 2.2572124004364014, Test_Clf_Loss: 2.2572124004364014, Test_Filter_Loss: 3.110142472451116e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.84%, Test_Ones_Portion: 7.510580246616883e-08\n",
      "Epoch 254, Total Loss: 2.1788382530212402, Clf Loss: 2.1788382530212402, Filter Loss: 3.229741878385539e-07, Seq Loss: 1.0, Accuracy Rate: 41.22%, Ones Portion: 8.687143093766281e-08,             Test_Total_Loss: 2.2564148902893066, Test_Clf_Loss: 2.2564148902893066, Test_Filter_Loss: 3.1456008287022996e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.88%, Test_Ones_Portion: 7.59922968995852e-08\n",
      "Epoch 255, Total Loss: 2.1818490028381348, Clf Loss: 2.1818490028381348, Filter Loss: 3.321394217437046e-07, Seq Loss: 1.0, Accuracy Rate: 41.17%, Ones Portion: 8.992895317305738e-08,             Test_Total_Loss: 2.255427598953247, Test_Clf_Loss: 2.255427598953247, Test_Filter_Loss: 3.0430317110585747e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.88%, Test_Ones_Portion: 7.399768264804152e-08\n",
      "Epoch 256, Total Loss: 2.1780524253845215, Clf Loss: 2.1780524253845215, Filter Loss: 3.1754038332110213e-07, Seq Loss: 1.0, Accuracy Rate: 41.15%, Ones Portion: 8.506676607566988e-08,             Test_Total_Loss: 2.251762866973877, Test_Clf_Loss: 2.251762866973877, Test_Filter_Loss: 3.138649162792717e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 7.563215831396519e-08\n",
      "Epoch 257, Total Loss: 2.181118965148926, Clf Loss: 2.181118965148926, Filter Loss: 3.2190743581850256e-07, Seq Loss: 1.0, Accuracy Rate: 41.08%, Ones Portion: 8.693363184875125e-08,             Test_Total_Loss: 2.254070997238159, Test_Clf_Loss: 2.254070997238159, Test_Filter_Loss: 3.3545970268278325e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.98%, Test_Ones_Portion: 7.657405376448878e-08\n",
      "Epoch 258, Total Loss: 2.1845405101776123, Clf Loss: 2.1845405101776123, Filter Loss: 3.1232011110660096e-07, Seq Loss: 1.0, Accuracy Rate: 41.11%, Ones Portion: 7.76601183360981e-08,             Test_Total_Loss: 2.253314256668091, Test_Clf_Loss: 2.253314256668091, Test_Filter_Loss: 3.0139150908325973e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 7.286185876864693e-08\n",
      "Epoch 259, Total Loss: 2.183350086212158, Clf Loss: 2.183350086212158, Filter Loss: 3.3073570193664636e-07, Seq Loss: 1.0, Accuracy Rate: 41.14%, Ones Portion: 8.302217935352019e-08,             Test_Total_Loss: 2.255945920944214, Test_Clf_Loss: 2.255945920944214, Test_Filter_Loss: 3.3345398264827963e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.93%, Test_Ones_Portion: 8.089572389735622e-08\n",
      "Epoch 260, Total Loss: 2.1791512966156006, Clf Loss: 2.1791512966156006, Filter Loss: 3.2804675242914527e-07, Seq Loss: 1.0, Accuracy Rate: 40.99%, Ones Portion: 8.632211034864667e-08,             Test_Total_Loss: 2.2560901641845703, Test_Clf_Loss: 2.2560901641845703, Test_Filter_Loss: 3.209397618775256e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 7.51612105887034e-08\n",
      "Epoch 261, Total Loss: 2.1822352409362793, Clf Loss: 2.1822352409362793, Filter Loss: 3.3354487527503807e-07, Seq Loss: 1.0, Accuracy Rate: 41.05%, Ones Portion: 8.553417529810758e-08,             Test_Total_Loss: 2.2568607330322266, Test_Clf_Loss: 2.2568607330322266, Test_Filter_Loss: 3.1628039209863346e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.93%, Test_Ones_Portion: 7.6823383210467e-08\n",
      "Epoch 262, Total Loss: 2.180544376373291, Clf Loss: 2.180544376373291, Filter Loss: 3.2813636607897934e-07, Seq Loss: 1.0, Accuracy Rate: 41.13%, Ones Portion: 7.855258843392221e-08,             Test_Total_Loss: 2.2579517364501953, Test_Clf_Loss: 2.2579517364501953, Test_Filter_Loss: 3.217170672087377e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.98%, Test_Ones_Portion: 7.496728926525975e-08\n",
      "Epoch 263, Total Loss: 2.181615114212036, Clf Loss: 2.181615114212036, Filter Loss: 3.2775187719380483e-07, Seq Loss: 1.0, Accuracy Rate: 41.11%, Ones Portion: 7.966226434064083e-08,             Test_Total_Loss: 2.2618672847747803, Test_Clf_Loss: 2.2618672847747803, Test_Filter_Loss: 3.482574868485244e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.79%, Test_Ones_Portion: 7.2834161812807e-08\n",
      "Epoch 264, Total Loss: 2.183178663253784, Clf Loss: 2.183178663253784, Filter Loss: 3.5145367860422994e-07, Seq Loss: 1.0, Accuracy Rate: 41.05%, Ones Portion: 8.048343858035878e-08,             Test_Total_Loss: 2.25586199760437, Test_Clf_Loss: 2.25586199760437, Test_Filter_Loss: 3.219965378775669e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 7.47733679418161e-08\n",
      "Epoch 265, Total Loss: 2.1894195079803467, Clf Loss: 2.1894195079803467, Filter Loss: 3.2123455184773775e-07, Seq Loss: 1.0, Accuracy Rate: 40.97%, Ones Portion: 7.680562674750036e-08,             Test_Total_Loss: 2.2627737522125244, Test_Clf_Loss: 2.2627737522125244, Test_Filter_Loss: 3.1333232186625537e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.84%, Test_Ones_Portion: 7.21692856586742e-08\n",
      "Epoch 266, Total Loss: 2.1910338401794434, Clf Loss: 2.1910338401794434, Filter Loss: 2.9494850650735316e-07, Seq Loss: 1.0, Accuracy Rate: 40.90%, Ones Portion: 6.6647132257458e-08,             Test_Total_Loss: 2.263389825820923, Test_Clf_Loss: 2.263389825820923, Test_Filter_Loss: 2.9835891268703563e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.74%, Test_Ones_Portion: 7.142131153159426e-08\n",
      "Epoch 267, Total Loss: 2.191905975341797, Clf Loss: 2.191905975341797, Filter Loss: 3.120113660770585e-07, Seq Loss: 1.0, Accuracy Rate: 40.84%, Ones Portion: 7.073342800367755e-08,             Test_Total_Loss: 2.2556278705596924, Test_Clf_Loss: 2.2556278705596924, Test_Filter_Loss: 3.1213792794915207e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 40.03%, Test_Ones_Portion: 7.186455519558876e-08\n",
      "Epoch 268, Total Loss: 2.1916561126708984, Clf Loss: 2.1916561126708984, Filter Loss: 3.146944322907075e-07, Seq Loss: 1.0, Accuracy Rate: 40.93%, Ones Portion: 6.86695784679614e-08,             Test_Total_Loss: 2.2627596855163574, Test_Clf_Loss: 2.2627596855163574, Test_Filter_Loss: 3.313966487894504e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.88%, Test_Ones_Portion: 7.236320698211784e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269, Total Loss: 2.1916615962982178, Clf Loss: 2.1916615962982178, Filter Loss: 3.167941997617163e-07, Seq Loss: 1.0, Accuracy Rate: 40.88%, Ones Portion: 6.616991043983944e-08,             Test_Total_Loss: 2.264676094055176, Test_Clf_Loss: 2.264676094055176, Test_Filter_Loss: 3.168507589634828e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.84%, Test_Ones_Portion: 7.372065624622337e-08\n",
      "Epoch 270, Total Loss: 2.1944332122802734, Clf Loss: 2.1944332122802734, Filter Loss: 3.1433020808435685e-07, Seq Loss: 1.0, Accuracy Rate: 40.81%, Ones Portion: 6.753592884933823e-08,             Test_Total_Loss: 2.263044834136963, Test_Clf_Loss: 2.263044834136963, Test_Filter_Loss: 2.985368610097794e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.74%, Test_Ones_Portion: 6.967601962060144e-08\n",
      "Epoch 271, Total Loss: 2.1915769577026367, Clf Loss: 2.1915769577026367, Filter Loss: 3.0815539275863557e-07, Seq Loss: 1.0, Accuracy Rate: 40.84%, Ones Portion: 7.01248339396443e-08,             Test_Total_Loss: 2.260284423828125, Test_Clf_Loss: 2.260284423828125, Test_Filter_Loss: 2.9549752866842027e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.88%, Test_Ones_Portion: 6.804154395467776e-08\n",
      "Epoch 272, Total Loss: 2.1910221576690674, Clf Loss: 2.1910221576690674, Filter Loss: 3.0704632081324235e-07, Seq Loss: 1.0, Accuracy Rate: 40.92%, Ones Portion: 6.822066467293553e-08,             Test_Total_Loss: 2.273668050765991, Test_Clf_Loss: 2.273668050765991, Test_Filter_Loss: 3.2911239600252884e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 7.552134206889605e-08\n",
      "Epoch 273, Total Loss: 2.193800687789917, Clf Loss: 2.193800687789917, Filter Loss: 3.096222087606293e-07, Seq Loss: 1.0, Accuracy Rate: 40.82%, Ones Portion: 6.608296843069184e-08,             Test_Total_Loss: 2.263390302658081, Test_Clf_Loss: 2.263390302658081, Test_Filter_Loss: 3.153442094117054e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.88%, Test_Ones_Portion: 6.845709066283234e-08\n",
      "Epoch 274, Total Loss: 2.1938209533691406, Clf Loss: 2.1938209533691406, Filter Loss: 3.03216864949718e-07, Seq Loss: 1.0, Accuracy Rate: 40.81%, Ones Portion: 6.516181372262508e-08,             Test_Total_Loss: 2.2717952728271484, Test_Clf_Loss: 2.2717952728271484, Test_Filter_Loss: 2.896184696510318e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 6.474489566699049e-08\n",
      "Epoch 275, Total Loss: 2.1925833225250244, Clf Loss: 2.1925833225250244, Filter Loss: 3.0227312208808144e-07, Seq Loss: 1.0, Accuracy Rate: 40.77%, Ones Portion: 6.495913140724952e-08,             Test_Total_Loss: 2.2693636417388916, Test_Clf_Loss: 2.2693636417388916, Test_Filter_Loss: 2.894852855206409e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.69%, Test_Ones_Portion: 6.579760736258322e-08\n",
      "Epoch 276, Total Loss: 2.1975951194763184, Clf Loss: 2.1975951194763184, Filter Loss: 3.1230092645273544e-07, Seq Loss: 1.0, Accuracy Rate: 40.79%, Ones Portion: 6.715420397540584e-08,             Test_Total_Loss: 2.2658450603485107, Test_Clf_Loss: 2.2658450603485107, Test_Filter_Loss: 3.3871148730213463e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 7.222469378120877e-08\n",
      "Epoch 277, Total Loss: 2.191732883453369, Clf Loss: 2.191732883453369, Filter Loss: 3.394190173366951e-07, Seq Loss: 1.0, Accuracy Rate: 40.85%, Ones Portion: 6.811811203988327e-08,             Test_Total_Loss: 2.26613712310791, Test_Clf_Loss: 2.26613712310791, Test_Filter_Loss: 3.2435471553071693e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.59%, Test_Ones_Portion: 7.405308366514873e-08\n",
      "Epoch 278, Total Loss: 2.1954715251922607, Clf Loss: 2.1954715251922607, Filter Loss: 3.1615726925338095e-07, Seq Loss: 1.0, Accuracy Rate: 40.79%, Ones Portion: 6.894223503195462e-08,             Test_Total_Loss: 2.2651100158691406, Test_Clf_Loss: 2.2651100158691406, Test_Filter_Loss: 3.0412491014431e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.50%, Test_Ones_Portion: 7.264024048936335e-08\n",
      "Epoch 279, Total Loss: 2.1939704418182373, Clf Loss: 2.1939704418182373, Filter Loss: 3.033711095667968e-07, Seq Loss: 1.0, Accuracy Rate: 40.79%, Ones Portion: 6.772668115218039e-08,             Test_Total_Loss: 2.272461175918579, Test_Clf_Loss: 2.272461175918579, Test_Filter_Loss: 3.2902639190979244e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.69%, Test_Ones_Portion: 7.710040961228515e-08\n",
      "Epoch 280, Total Loss: 2.1943483352661133, Clf Loss: 2.1943483352661133, Filter Loss: 2.9309649107744917e-07, Seq Loss: 1.0, Accuracy Rate: 40.80%, Ones Portion: 6.48874589614934e-08,             Test_Total_Loss: 2.2702014446258545, Test_Clf_Loss: 2.2702014446258545, Test_Filter_Loss: 3.091022620083095e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.59%, Test_Ones_Portion: 7.01192703900233e-08\n",
      "Epoch 281, Total Loss: 2.1958725452423096, Clf Loss: 2.1958725452423096, Filter Loss: 3.124464171833097e-07, Seq Loss: 1.0, Accuracy Rate: 40.85%, Ones Portion: 6.601678848028314e-08,             Test_Total_Loss: 2.2663440704345703, Test_Clf_Loss: 2.2663440704345703, Test_Filter_Loss: 3.357677940130088e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.74%, Test_Ones_Portion: 7.32774054768015e-08\n",
      "Epoch 282, Total Loss: 2.192619562149048, Clf Loss: 2.192619562149048, Filter Loss: 3.222252189516439e-07, Seq Loss: 1.0, Accuracy Rate: 40.84%, Ones Portion: 6.851795575357755e-08,             Test_Total_Loss: 2.2611637115478516, Test_Clf_Loss: 2.2611637115478516, Test_Filter_Loss: 3.1348196216640645e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.84%, Test_Ones_Portion: 7.078413233330139e-08\n",
      "Epoch 283, Total Loss: 2.197000741958618, Clf Loss: 2.197000741958618, Filter Loss: 3.0155044328239455e-07, Seq Loss: 1.0, Accuracy Rate: 40.71%, Ones Portion: 6.38238475403341e-08,             Test_Total_Loss: 2.2688448429107666, Test_Clf_Loss: 2.2688448429107666, Test_Filter_Loss: 3.41874454079516e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.79%, Test_Ones_Portion: 7.114426381349404e-08\n",
      "Epoch 284, Total Loss: 2.1965620517730713, Clf Loss: 2.1965620517730713, Filter Loss: 2.973815469431429e-07, Seq Loss: 1.0, Accuracy Rate: 40.79%, Ones Portion: 6.419111286959378e-08,             Test_Total_Loss: 2.265920400619507, Test_Clf_Loss: 2.265920400619507, Test_Filter_Loss: 3.127120180579368e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.69%, Test_Ones_Portion: 7.626932330140335e-08\n",
      "Epoch 285, Total Loss: 2.1940793991088867, Clf Loss: 2.1940793991088867, Filter Loss: 3.049970871416008e-07, Seq Loss: 1.0, Accuracy Rate: 40.76%, Ones Portion: 6.47053610691728e-08,             Test_Total_Loss: 2.270559072494507, Test_Clf_Loss: 2.270559072494507, Test_Filter_Loss: 3.0958710794948274e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.74%, Test_Ones_Portion: 7.316658923173236e-08\n",
      "Epoch 286, Total Loss: 2.197467088699341, Clf Loss: 2.197467088699341, Filter Loss: 3.088117637162213e-07, Seq Loss: 1.0, Accuracy Rate: 40.81%, Ones Portion: 6.5768752222084e-08,             Test_Total_Loss: 2.271695375442505, Test_Clf_Loss: 2.271695375442505, Test_Filter_Loss: 3.449669634392194e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.74%, Test_Ones_Portion: 7.144900138200683e-08\n",
      "Epoch 287, Total Loss: 2.193746328353882, Clf Loss: 2.193746328353882, Filter Loss: 3.2580572906226735e-07, Seq Loss: 1.0, Accuracy Rate: 40.86%, Ones Portion: 6.886825332230728e-08,             Test_Total_Loss: 2.264378070831299, Test_Clf_Loss: 2.264378070831299, Test_Filter_Loss: 3.066818976549257e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.88%, Test_Ones_Portion: 7.119967904145597e-08\n",
      "Epoch 288, Total Loss: 2.2004761695861816, Clf Loss: 2.2004761695861816, Filter Loss: 3.0703182574143284e-07, Seq Loss: 1.0, Accuracy Rate: 40.80%, Ones Portion: 6.102712291067292e-08,             Test_Total_Loss: 2.263235092163086, Test_Clf_Loss: 2.263235092163086, Test_Filter_Loss: 2.941623051810893e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 6.493880988500678e-08\n",
      "Epoch 289, Total Loss: 2.2011141777038574, Clf Loss: 2.2011141777038574, Filter Loss: 3.1214520390676626e-07, Seq Loss: 1.0, Accuracy Rate: 40.67%, Ones Portion: 5.756238152798687e-08,             Test_Total_Loss: 2.2769672870635986, Test_Clf_Loss: 2.2769672870635986, Test_Filter_Loss: 3.139490445391857e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 6.28610905550886e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290, Total Loss: 2.201082229614258, Clf Loss: 2.201082229614258, Filter Loss: 3.232491962990025e-07, Seq Loss: 1.0, Accuracy Rate: 40.71%, Ones Portion: 6.538633812169792e-08,             Test_Total_Loss: 2.2733099460601807, Test_Clf_Loss: 2.2733099460601807, Test_Filter_Loss: 3.0339265322254505e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.50%, Test_Ones_Portion: 6.842938660156506e-08\n",
      "Epoch 291, Total Loss: 2.197120428085327, Clf Loss: 2.197120428085327, Filter Loss: 2.9366574949563073e-07, Seq Loss: 1.0, Accuracy Rate: 40.70%, Ones Portion: 5.990167295522042e-08,             Test_Total_Loss: 2.2733757495880127, Test_Clf_Loss: 2.2733757495880127, Test_Filter_Loss: 2.668760146207205e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 6.136513519550135e-08\n",
      "Epoch 292, Total Loss: 2.200676679611206, Clf Loss: 2.200676679611206, Filter Loss: 2.5538321324347635e-07, Seq Loss: 1.0, Accuracy Rate: 40.63%, Ones Portion: 5.533804525725827e-08,             Test_Total_Loss: 2.268667221069336, Test_Clf_Loss: 2.268667221069336, Test_Filter_Loss: 2.639361582623678e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.69%, Test_Ones_Portion: 6.427393373087398e-08\n",
      "Epoch 293, Total Loss: 2.2013378143310547, Clf Loss: 2.2013378143310547, Filter Loss: 2.4870490733519546e-07, Seq Loss: 1.0, Accuracy Rate: 40.65%, Ones Portion: 5.6874366549664046e-08,             Test_Total_Loss: 2.281369209289551, Test_Clf_Loss: 2.281369209289551, Test_Filter_Loss: 2.2998483473202214e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 4.942960529774609e-08\n",
      "Epoch 294, Total Loss: 2.2034599781036377, Clf Loss: 2.2034599781036377, Filter Loss: 2.3021384265575762e-07, Seq Loss: 1.0, Accuracy Rate: 40.50%, Ones Portion: 5.098356226085343e-08,             Test_Total_Loss: 2.275757312774658, Test_Clf_Loss: 2.275757312774658, Test_Filter_Loss: 2.5073819642784656e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.69%, Test_Ones_Portion: 6.000768593139583e-08\n",
      "Epoch 295, Total Loss: 2.203864812850952, Clf Loss: 2.203864812850952, Filter Loss: 2.3453792152849928e-07, Seq Loss: 1.0, Accuracy Rate: 40.70%, Ones Portion: 5.1693085367787717e-08,             Test_Total_Loss: 2.2826740741729736, Test_Clf_Loss: 2.2826740741729736, Test_Filter_Loss: 2.3102602142444084e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.25%, Test_Ones_Portion: 5.073164288660337e-08\n",
      "Epoch 296, Total Loss: 2.207017183303833, Clf Loss: 2.207017183303833, Filter Loss: 2.221383681444422e-07, Seq Loss: 1.0, Accuracy Rate: 40.57%, Ones Portion: 5.039168371467895e-08,             Test_Total_Loss: 2.2815444469451904, Test_Clf_Loss: 2.2815444469451904, Test_Filter_Loss: 2.0591564009464491e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.16%, Test_Ones_Portion: 4.970663525227792e-08\n",
      "Epoch 297, Total Loss: 2.2036960124969482, Clf Loss: 2.2036960124969482, Filter Loss: 1.9622302716015838e-07, Seq Loss: 1.0, Accuracy Rate: 40.59%, Ones Portion: 4.8069850322463026e-08,             Test_Total_Loss: 2.2771477699279785, Test_Clf_Loss: 2.2771477699279785, Test_Filter_Loss: 1.998545542392094e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.40%, Test_Ones_Portion: 4.4498477791421465e-08\n",
      "Epoch 298, Total Loss: 2.204650402069092, Clf Loss: 2.204650402069092, Filter Loss: 2.0019592739117797e-07, Seq Loss: 1.0, Accuracy Rate: 40.63%, Ones Portion: 5.162743477171716e-08,             Test_Total_Loss: 2.278654098510742, Test_Clf_Loss: 2.278654098510742, Test_Filter_Loss: 1.8186764805250277e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 4.4747803684686005e-08\n",
      "Epoch 299, Total Loss: 2.210739850997925, Clf Loss: 2.210739850997925, Filter Loss: 1.824002282546644e-07, Seq Loss: 1.0, Accuracy Rate: 40.40%, Ones Portion: 4.717876933568732e-08,             Test_Total_Loss: 2.2757487297058105, Test_Clf_Loss: 2.2757487297058105, Test_Filter_Loss: 1.8733381068614108e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.35%, Test_Ones_Portion: 4.859851543415061e-08\n",
      "Epoch 300, Total Loss: 2.2092111110687256, Clf Loss: 2.2092111110687256, Filter Loss: 1.8243794386307854e-07, Seq Loss: 1.0, Accuracy Rate: 40.44%, Ones Portion: 4.724550350942991e-08,             Test_Total_Loss: 2.280031442642212, Test_Clf_Loss: 2.280031442642212, Test_Filter_Loss: 1.8227905229650787e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 4.7324178353846946e-08\n",
      "Epoch 301, Total Loss: 2.212338447570801, Clf Loss: 2.212338447570801, Filter Loss: 1.7031808852152608e-07, Seq Loss: 1.0, Accuracy Rate: 40.41%, Ones Portion: 4.434177469647693e-08,             Test_Total_Loss: 2.2836995124816895, Test_Clf_Loss: 2.2836995124816895, Test_Filter_Loss: 1.7317155709406507e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.21%, Test_Ones_Portion: 4.6409983411876965e-08\n",
      "Epoch 302, Total Loss: 2.2114264965057373, Clf Loss: 2.2114264965057373, Filter Loss: 1.6930167134887597e-07, Seq Loss: 1.0, Accuracy Rate: 40.46%, Ones Portion: 4.4585881653347315e-08,             Test_Total_Loss: 2.2720448970794678, Test_Clf_Loss: 2.2720448970794678, Test_Filter_Loss: 1.720882494282705e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.40%, Test_Ones_Portion: 4.7185661600224194e-08\n",
      "Epoch 303, Total Loss: 2.211599349975586, Clf Loss: 2.211599349975586, Filter Loss: 1.7185166711897182e-07, Seq Loss: 1.0, Accuracy Rate: 40.40%, Ones Portion: 4.5780293334019007e-08,             Test_Total_Loss: 2.2817134857177734, Test_Clf_Loss: 2.2817134857177734, Test_Filter_Loss: 1.716764614911881e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.11%, Test_Ones_Portion: 4.6742414383516007e-08\n",
      "Epoch 304, Total Loss: 2.211014986038208, Clf Loss: 2.211014986038208, Filter Loss: 1.6848572670369322e-07, Seq Loss: 1.0, Accuracy Rate: 40.34%, Ones Portion: 4.430555122780788e-08,             Test_Total_Loss: 2.277759313583374, Test_Clf_Loss: 2.277759313583374, Test_Filter_Loss: 1.7169762145385903e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.25%, Test_Ones_Portion: 4.768432049218063e-08\n",
      "Epoch 305, Total Loss: 2.211716890335083, Clf Loss: 2.211716890335083, Filter Loss: 1.622158976033461e-07, Seq Loss: 1.0, Accuracy Rate: 40.39%, Ones Portion: 4.260709829395637e-08,             Test_Total_Loss: 2.2712085247039795, Test_Clf_Loss: 2.2712085247039795, Test_Filter_Loss: 1.7001870844524092e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.35%, Test_Ones_Portion: 4.771202100073424e-08\n",
      "Epoch 306, Total Loss: 2.2144393920898438, Clf Loss: 2.2144393920898438, Filter Loss: 1.622705951831449e-07, Seq Loss: 1.0, Accuracy Rate: 40.44%, Ones Portion: 4.3107842628842263e-08,             Test_Total_Loss: 2.278402328491211, Test_Clf_Loss: 2.278402328491211, Test_Filter_Loss: 1.7167081978186616e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 4.643768747314425e-08\n",
      "Epoch 307, Total Loss: 2.2086241245269775, Clf Loss: 2.2086241245269775, Filter Loss: 1.6529931201603176e-07, Seq Loss: 1.0, Accuracy Rate: 40.42%, Ones Portion: 4.505587725134319e-08,             Test_Total_Loss: 2.273871660232544, Test_Clf_Loss: 2.273871660232544, Test_Filter_Loss: 1.7513188765860832e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.35%, Test_Ones_Portion: 4.998366165409607e-08\n",
      "Epoch 308, Total Loss: 2.207664966583252, Clf Loss: 2.207664966583252, Filter Loss: 1.6861856977357093e-07, Seq Loss: 1.0, Accuracy Rate: 40.42%, Ones Portion: 4.581036705531005e-08,             Test_Total_Loss: 2.274219274520874, Test_Clf_Loss: 2.274219274520874, Test_Filter_Loss: 1.8171283500123536e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.35%, Test_Ones_Portion: 5.073164288660337e-08\n",
      "Epoch 309, Total Loss: 2.207413673400879, Clf Loss: 2.207413673400879, Filter Loss: 1.7084320802496222e-07, Seq Loss: 1.0, Accuracy Rate: 40.48%, Ones Portion: 4.616887139263781e-08,             Test_Total_Loss: 2.278887987136841, Test_Clf_Loss: 2.278887987136841, Test_Filter_Loss: 1.8434184312354773e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.35%, Test_Ones_Portion: 5.13688114267552e-08\n",
      "Epoch 310, Total Loss: 2.2079451084136963, Clf Loss: 2.2079451084136963, Filter Loss: 1.768616328945427e-07, Seq Loss: 1.0, Accuracy Rate: 40.47%, Ones Portion: 4.87452886943629e-08,             Test_Total_Loss: 2.2821226119995117, Test_Clf_Loss: 2.2821226119995117, Test_Filter_Loss: 1.7893131598611944e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 5.0593126132980615e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311, Total Loss: 2.209826707839966, Clf Loss: 2.209826707839966, Filter Loss: 1.7674828711733426e-07, Seq Loss: 1.0, Accuracy Rate: 40.50%, Ones Portion: 4.746875958971941e-08,             Test_Total_Loss: 2.271760940551758, Test_Clf_Loss: 2.271760940551758, Test_Filter_Loss: 1.8528444911680708e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.50%, Test_Ones_Portion: 5.3945182543202463e-08\n",
      "Epoch 312, Total Loss: 2.2080936431884766, Clf Loss: 2.2080936431884766, Filter Loss: 1.7305019639479724e-07, Seq Loss: 1.0, Accuracy Rate: 40.40%, Ones Portion: 4.8359666493524855e-08,             Test_Total_Loss: 2.278505325317383, Test_Clf_Loss: 2.278505325317383, Test_Filter_Loss: 1.8056272210742463e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.50%, Test_Ones_Portion: 5.123029467313245e-08\n",
      "Epoch 313, Total Loss: 2.2075884342193604, Clf Loss: 2.2075884342193604, Filter Loss: 1.8731029172158742e-07, Seq Loss: 1.0, Accuracy Rate: 40.51%, Ones Portion: 5.393888002913627e-08,             Test_Total_Loss: 2.272667407989502, Test_Clf_Loss: 2.272667407989502, Test_Filter_Loss: 1.8513674149289727e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 5.41114033580925e-08\n",
      "Epoch 314, Total Loss: 2.2046828269958496, Clf Loss: 2.2046828269958496, Filter Loss: 1.840848398160233e-07, Seq Loss: 1.0, Accuracy Rate: 40.56%, Ones Portion: 5.007737158280179e-08,             Test_Total_Loss: 2.274904489517212, Test_Clf_Loss: 2.274904489517212, Test_Filter_Loss: 1.853662610074025e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.35%, Test_Ones_Portion: 5.369585664993792e-08\n",
      "Epoch 315, Total Loss: 2.2071197032928467, Clf Loss: 2.2071197032928467, Filter Loss: 1.9137753781706124e-07, Seq Loss: 1.0, Accuracy Rate: 40.54%, Ones Portion: 5.3254865406415774e-08,             Test_Total_Loss: 2.2713043689727783, Test_Clf_Loss: 2.2713043689727783, Test_Filter_Loss: 1.9437651133102918e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 5.469316377570976e-08\n",
      "Epoch 316, Total Loss: 2.2031240463256836, Clf Loss: 2.2031240463256836, Filter Loss: 1.8376734089997626e-07, Seq Loss: 1.0, Accuracy Rate: 40.70%, Ones Portion: 5.247961709642368e-08,             Test_Total_Loss: 2.2667644023895264, Test_Clf_Loss: 2.2667644023895264, Test_Filter_Loss: 1.9472143719667656e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 5.7158732857942596e-08\n",
      "Epoch 317, Total Loss: 2.2052907943725586, Clf Loss: 2.2052907943725586, Filter Loss: 1.8252832489906723e-07, Seq Loss: 1.0, Accuracy Rate: 40.56%, Ones Portion: 4.951196075353437e-08,             Test_Total_Loss: 2.2729339599609375, Test_Clf_Loss: 2.2729339599609375, Test_Filter_Loss: 1.9272027884653653e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.35%, Test_Ones_Portion: 5.369585664993792e-08\n",
      "Epoch 318, Total Loss: 2.208414077758789, Clf Loss: 2.208414077758789, Filter Loss: 1.854846090054707e-07, Seq Loss: 1.0, Accuracy Rate: 40.53%, Ones Portion: 5.3977352365564e-08,             Test_Total_Loss: 2.2694382667541504, Test_Clf_Loss: 2.2694382667541504, Test_Filter_Loss: 1.9050656874242122e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 5.588439222492525e-08\n",
      "Epoch 319, Total Loss: 2.2054355144500732, Clf Loss: 2.2054355144500732, Filter Loss: 1.844976367237905e-07, Seq Loss: 1.0, Accuracy Rate: 40.57%, Ones Portion: 5.495627775076173e-08,             Test_Total_Loss: 2.2695157527923584, Test_Clf_Loss: 2.2695157527923584, Test_Filter_Loss: 1.886837708298117e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.40%, Test_Ones_Portion: 5.627223487181254e-08\n",
      "Epoch 320, Total Loss: 2.203655242919922, Clf Loss: 2.203655242919922, Filter Loss: 1.8105494348219509e-07, Seq Loss: 1.0, Accuracy Rate: 40.58%, Ones Portion: 5.090386778761058e-08,             Test_Total_Loss: 2.2750113010406494, Test_Clf_Loss: 2.2750113010406494, Test_Filter_Loss: 1.870080552635045e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.16%, Test_Ones_Portion: 5.729724250613799e-08\n",
      "Epoch 321, Total Loss: 2.2090115547180176, Clf Loss: 2.2090115547180176, Filter Loss: 1.8608200491598836e-07, Seq Loss: 1.0, Accuracy Rate: 40.53%, Ones Portion: 5.390294788298888e-08,             Test_Total_Loss: 2.267598867416382, Test_Clf_Loss: 2.267598867416382, Test_Filter_Loss: 1.90769043229011e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 5.538574043839617e-08\n",
      "Epoch 322, Total Loss: 2.207914113998413, Clf Loss: 2.207914113998413, Filter Loss: 1.8258546674587706e-07, Seq Loss: 1.0, Accuracy Rate: 40.53%, Ones Portion: 5.295780525216287e-08,             Test_Total_Loss: 2.278970718383789, Test_Clf_Loss: 2.278970718383789, Test_Filter_Loss: 1.9273196016911243e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 5.48593845905998e-08\n",
      "Epoch 323, Total Loss: 2.208103895187378, Clf Loss: 2.208103895187378, Filter Loss: 1.8005084712058306e-07, Seq Loss: 1.0, Accuracy Rate: 40.47%, Ones Portion: 5.2110081583123247e-08,             Test_Total_Loss: 2.2733638286590576, Test_Clf_Loss: 2.2733638286590576, Test_Filter_Loss: 1.870387080771252e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 5.538574043839617e-08\n",
      "Epoch 324, Total Loss: 2.2074573040008545, Clf Loss: 2.2074573040008545, Filter Loss: 1.8079300900808448e-07, Seq Loss: 1.0, Accuracy Rate: 40.51%, Ones Portion: 5.246789314128364e-08,             Test_Total_Loss: 2.2740116119384766, Test_Clf_Loss: 2.2740116119384766, Test_Filter_Loss: 1.8737307527771918e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.40%, Test_Ones_Portion: 5.3086392171053376e-08\n",
      "Epoch 325, Total Loss: 2.2083256244659424, Clf Loss: 2.2083256244659424, Filter Loss: 1.8385246391972032e-07, Seq Loss: 1.0, Accuracy Rate: 40.58%, Ones Portion: 5.3629563012691506e-08,             Test_Total_Loss: 2.2706706523895264, Test_Clf_Loss: 2.2706706523895264, Test_Filter_Loss: 1.9365741366073053e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.25%, Test_Ones_Portion: 5.959659432619446e-08\n",
      "Epoch 326, Total Loss: 2.2080931663513184, Clf Loss: 2.2080931663513184, Filter Loss: 1.9297691267183836e-07, Seq Loss: 1.0, Accuracy Rate: 40.57%, Ones Portion: 5.7889860016757666e-08,             Test_Total_Loss: 2.278325319290161, Test_Clf_Loss: 2.278325319290161, Test_Filter_Loss: 1.911574543100869e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.25%, Test_Ones_Portion: 5.740805519849346e-08\n",
      "Epoch 327, Total Loss: 2.208519458770752, Clf Loss: 2.208519458770752, Filter Loss: 1.831416227560112e-07, Seq Loss: 1.0, Accuracy Rate: 40.57%, Ones Portion: 5.180150708383735e-08,             Test_Total_Loss: 2.2722043991088867, Test_Clf_Loss: 2.2722043991088867, Test_Filter_Loss: 1.9015699592728197e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.50%, Test_Ones_Portion: 5.5912096286192536e-08\n",
      "Epoch 328, Total Loss: 2.203374147415161, Clf Loss: 2.203374147415161, Filter Loss: 1.7882540248592704e-07, Seq Loss: 1.0, Accuracy Rate: 40.50%, Ones Portion: 5.04546697754904e-08,             Test_Total_Loss: 2.273969888687134, Test_Clf_Loss: 2.273969888687134, Test_Filter_Loss: 1.9153225139234564e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 5.5912096286192536e-08\n",
      "Epoch 329, Total Loss: 2.2029340267181396, Clf Loss: 2.2029340267181396, Filter Loss: 1.8367096288329776e-07, Seq Loss: 1.0, Accuracy Rate: 40.56%, Ones Portion: 5.349996357040254e-08,             Test_Total_Loss: 2.2830867767333984, Test_Clf_Loss: 2.2830867767333984, Test_Filter_Loss: 1.8982120764121646e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.11%, Test_Ones_Portion: 5.172895001237521e-08\n",
      "Epoch 330, Total Loss: 2.207700252532959, Clf Loss: 2.207700252532959, Filter Loss: 1.8733624074229738e-07, Seq Loss: 1.0, Accuracy Rate: 40.47%, Ones Portion: 5.5576350632691174e-08,             Test_Total_Loss: 2.2862353324890137, Test_Clf_Loss: 2.2862353324890137, Test_Filter_Loss: 1.885342015839342e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.16%, Test_Ones_Portion: 5.3917485587362535e-08\n",
      "Epoch 331, Total Loss: 2.2056877613067627, Clf Loss: 2.2056877613067627, Filter Loss: 1.7949349739865283e-07, Seq Loss: 1.0, Accuracy Rate: 40.48%, Ones Portion: 4.9278245484174477e-08,             Test_Total_Loss: 2.281193494796753, Test_Clf_Loss: 2.281193494796753, Test_Filter_Loss: 1.9702918052644236e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.21%, Test_Ones_Portion: 5.461005869733526e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332, Total Loss: 2.2065682411193848, Clf Loss: 2.2065682411193848, Filter Loss: 1.7565608345648798e-07, Seq Loss: 1.0, Accuracy Rate: 40.50%, Ones Portion: 5.033872696458275e-08,             Test_Total_Loss: 2.291361093521118, Test_Clf_Loss: 2.291361093521118, Test_Filter_Loss: 1.936349462994258e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.01%, Test_Ones_Portion: 5.0925564210047014e-08\n",
      "Epoch 333, Total Loss: 2.207064151763916, Clf Loss: 2.207064151763916, Filter Loss: 1.853891689052034e-07, Seq Loss: 1.0, Accuracy Rate: 40.46%, Ones Portion: 5.2967834562878124e-08,             Test_Total_Loss: 2.2839744091033936, Test_Clf_Loss: 2.2839744091033936, Test_Filter_Loss: 1.912545712912106e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.16%, Test_Ones_Portion: 5.461005869733526e-08\n",
      "Epoch 334, Total Loss: 2.207014322280884, Clf Loss: 2.207014322280884, Filter Loss: 1.76403005980319e-07, Seq Loss: 1.0, Accuracy Rate: 40.50%, Ones Portion: 5.1207379669904185e-08,             Test_Total_Loss: 2.284412145614624, Test_Clf_Loss: 2.284412145614624, Test_Filter_Loss: 1.882686291310165e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.16%, Test_Ones_Portion: 5.369585664993792e-08\n",
      "Epoch 335, Total Loss: 2.2093513011932373, Clf Loss: 2.2093513011932373, Filter Loss: 1.7116460071520123e-07, Seq Loss: 1.0, Accuracy Rate: 40.47%, Ones Portion: 4.974085143771845e-08,             Test_Total_Loss: 2.2913146018981934, Test_Clf_Loss: 2.2913146018981934, Test_Filter_Loss: 1.9480422963624733e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.06%, Test_Ones_Portion: 5.610601760963618e-08\n",
      "Epoch 336, Total Loss: 2.2139992713928223, Clf Loss: 2.2139992713928223, Filter Loss: 1.7575176514128543e-07, Seq Loss: 1.0, Accuracy Rate: 40.44%, Ones Portion: 4.9693888115598384e-08,             Test_Total_Loss: 2.287364959716797, Test_Clf_Loss: 2.287364959716797, Test_Filter_Loss: 1.9180625088210945e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.16%, Test_Ones_Portion: 5.3501938879207955e-08\n",
      "Epoch 337, Total Loss: 2.2112414836883545, Clf Loss: 2.2112414836883545, Filter Loss: 1.7900795512559853e-07, Seq Loss: 1.0, Accuracy Rate: 40.44%, Ones Portion: 5.3690012435936296e-08,             Test_Total_Loss: 2.2835044860839844, Test_Clf_Loss: 2.2835044860839844, Test_Filter_Loss: 1.9460091493783693e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.16%, Test_Ones_Portion: 5.9014823250436166e-08\n",
      "Epoch 338, Total Loss: 2.2111058235168457, Clf Loss: 2.2111058235168457, Filter Loss: 1.8297507153874903e-07, Seq Loss: 1.0, Accuracy Rate: 40.50%, Ones Portion: 5.219303034209588e-08,             Test_Total_Loss: 2.275386095046997, Test_Clf_Loss: 2.275386095046997, Test_Filter_Loss: 1.9673827011956746e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.35%, Test_Ones_Portion: 5.99844298676544e-08\n",
      "Epoch 339, Total Loss: 2.2105891704559326, Clf Loss: 2.2105891704559326, Filter Loss: 1.7804129015530634e-07, Seq Loss: 1.0, Accuracy Rate: 40.42%, Ones Portion: 5.2004644146563805e-08,             Test_Total_Loss: 2.2784180641174316, Test_Clf_Loss: 2.2784180641174316, Test_Filter_Loss: 2.014033526620551e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 5.962429128203439e-08\n",
      "Epoch 340, Total Loss: 2.207489252090454, Clf Loss: 2.207489252090454, Filter Loss: 1.8387527234153822e-07, Seq Loss: 1.0, Accuracy Rate: 40.52%, Ones Portion: 5.419676440965304e-08,             Test_Total_Loss: 2.2724740505218506, Test_Clf_Loss: 2.2724740505218506, Test_Filter_Loss: 1.9821148100618302e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.35%, Test_Ones_Portion: 5.829454963190983e-08\n",
      "Epoch 341, Total Loss: 2.206202745437622, Clf Loss: 2.206202745437622, Filter Loss: 1.8250179323331395e-07, Seq Loss: 1.0, Accuracy Rate: 40.51%, Ones Portion: 5.281889059460809e-08,             Test_Total_Loss: 2.273118019104004, Test_Clf_Loss: 2.273118019104004, Test_Filter_Loss: 2.030035233246963e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 6.145268827140171e-08\n",
      "Epoch 342, Total Loss: 2.204814910888672, Clf Loss: 2.204814910888672, Filter Loss: 1.8997101847162412e-07, Seq Loss: 1.0, Accuracy Rate: 40.56%, Ones Portion: 5.651209633583676e-08,             Test_Total_Loss: 2.276440382003784, Test_Clf_Loss: 2.276440382003784, Test_Filter_Loss: 1.8992898276337655e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 5.967969940456896e-08\n",
      "Epoch 343, Total Loss: 2.203939437866211, Clf Loss: 2.203939437866211, Filter Loss: 1.8647293131834886e-07, Seq Loss: 1.0, Accuracy Rate: 40.58%, Ones Portion: 5.40063282983283e-08,             Test_Total_Loss: 2.2827563285827637, Test_Clf_Loss: 2.2827563285827637, Test_Filter_Loss: 1.9015860175386479e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.16%, Test_Ones_Portion: 5.8654691770243517e-08\n",
      "Epoch 344, Total Loss: 2.20467472076416, Clf Loss: 2.20467472076416, Filter Loss: 1.7964192977615312e-07, Seq Loss: 1.0, Accuracy Rate: 40.59%, Ones Portion: 5.207654041328169e-08,             Test_Total_Loss: 2.2806270122528076, Test_Clf_Loss: 2.2806270122528076, Test_Filter_Loss: 1.9000377449174266e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.40%, Test_Ones_Portion: 5.9513482142392604e-08\n",
      "Epoch 345, Total Loss: 2.2049427032470703, Clf Loss: 2.2049427032470703, Filter Loss: 1.8002459967192408e-07, Seq Loss: 1.0, Accuracy Rate: 40.52%, Ones Portion: 5.297228611311766e-08,             Test_Total_Loss: 2.2865147590637207, Test_Clf_Loss: 2.2865147590637207, Test_Filter_Loss: 1.9173477028289199e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.21%, Test_Ones_Portion: 5.95688867122135e-08\n",
      "Epoch 346, Total Loss: 2.2033214569091797, Clf Loss: 2.2033214569091797, Filter Loss: 1.8847657656806405e-07, Seq Loss: 1.0, Accuracy Rate: 40.70%, Ones Portion: 5.819415349606061e-08,             Test_Total_Loss: 2.2787036895751953, Test_Clf_Loss: 2.2787036895751953, Test_Filter_Loss: 2.023697476261077e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 6.328108526076903e-08\n",
      "Epoch 347, Total Loss: 2.209359884262085, Clf Loss: 2.209359884262085, Filter Loss: 1.8783036637159967e-07, Seq Loss: 1.0, Accuracy Rate: 40.59%, Ones Portion: 5.687755688654761e-08,             Test_Total_Loss: 2.27909779548645, Test_Clf_Loss: 2.27909779548645, Test_Filter_Loss: 1.9805831641406257e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 6.100943750197985e-08\n",
      "Epoch 348, Total Loss: 2.2025442123413086, Clf Loss: 2.2025442123413086, Filter Loss: 1.8245383159865014e-07, Seq Loss: 1.0, Accuracy Rate: 40.53%, Ones Portion: 5.551416748517113e-08,             Test_Total_Loss: 2.2796356678009033, Test_Clf_Loss: 2.2796356678009033, Test_Filter_Loss: 1.9217473834487464e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.50%, Test_Ones_Portion: 5.7657384644471676e-08\n",
      "Epoch 349, Total Loss: 2.2049081325531006, Clf Loss: 2.2049081325531006, Filter Loss: 1.8347695629472582e-07, Seq Loss: 1.0, Accuracy Rate: 40.63%, Ones Portion: 5.612513831465549e-08,             Test_Total_Loss: 2.280092477798462, Test_Clf_Loss: 2.280092477798462, Test_Filter_Loss: 1.9373337067918328e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.21%, Test_Ones_Portion: 5.9153347109486276e-08\n",
      "Epoch 350, Total Loss: 2.207287549972534, Clf Loss: 2.207287549972534, Filter Loss: 1.946558541021659e-07, Seq Loss: 1.0, Accuracy Rate: 40.61%, Ones Portion: 6.165102206523443e-08,             Test_Total_Loss: 2.278303861618042, Test_Clf_Loss: 2.278303861618042, Test_Filter_Loss: 1.949827463931797e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.50%, Test_Ones_Portion: 5.8239152167516295e-08\n",
      "Epoch 351, Total Loss: 2.2037856578826904, Clf Loss: 2.2037856578826904, Filter Loss: 1.8847245542019664e-07, Seq Loss: 1.0, Accuracy Rate: 40.61%, Ones Portion: 5.834714755792447e-08,             Test_Total_Loss: 2.2796785831451416, Test_Clf_Loss: 2.2796785831451416, Test_Filter_Loss: 2.038197095544092e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 6.186823497955629e-08\n",
      "Epoch 352, Total Loss: 2.200880289077759, Clf Loss: 2.200880289077759, Filter Loss: 1.981684647489601e-07, Seq Loss: 1.0, Accuracy Rate: 40.59%, Ones Portion: 6.371318761466682e-08,             Test_Total_Loss: 2.2767789363861084, Test_Clf_Loss: 2.2767789363861084, Test_Filter_Loss: 2.0388861798892322e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 6.40844746158109e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353, Total Loss: 2.2008121013641357, Clf Loss: 2.2008121013641357, Filter Loss: 1.967657823342961e-07, Seq Loss: 1.0, Accuracy Rate: 40.63%, Ones Portion: 6.515457329214769e-08,             Test_Total_Loss: 2.274864435195923, Test_Clf_Loss: 2.274864435195923, Test_Filter_Loss: 2.012991160427191e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 6.358581572385447e-08\n",
      "Epoch 354, Total Loss: 2.2003228664398193, Clf Loss: 2.2003228664398193, Filter Loss: 2.0109688136926707e-07, Seq Loss: 1.0, Accuracy Rate: 40.65%, Ones Portion: 6.838117627694373e-08,             Test_Total_Loss: 2.275681257247925, Test_Clf_Loss: 2.275681257247925, Test_Filter_Loss: 2.002127672540155e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.35%, Test_Ones_Portion: 6.167431365611264e-08\n",
      "Epoch 355, Total Loss: 2.196406126022339, Clf Loss: 2.196406126022339, Filter Loss: 1.9307186960304534e-07, Seq Loss: 1.0, Accuracy Rate: 40.59%, Ones Portion: 6.282175490923692e-08,             Test_Total_Loss: 2.2772929668426514, Test_Clf_Loss: 2.2772929668426514, Test_Filter_Loss: 1.9488601310513332e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 5.879320852386627e-08\n",
      "Epoch 356, Total Loss: 2.19748854637146, Clf Loss: 2.19748854637146, Filter Loss: 1.8357806652602449e-07, Seq Loss: 1.0, Accuracy Rate: 40.62%, Ones Portion: 5.714359119224355e-08,             Test_Total_Loss: 2.272310256958008, Test_Clf_Loss: 2.272310256958008, Test_Filter_Loss: 1.930066844124667e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.50%, Test_Ones_Portion: 5.962429128203439e-08\n",
      "Epoch 357, Total Loss: 2.2043285369873047, Clf Loss: 2.2043285369873047, Filter Loss: 1.8283468250501755e-07, Seq Loss: 1.0, Accuracy Rate: 40.63%, Ones Portion: 5.492426424780206e-08,             Test_Total_Loss: 2.2789201736450195, Test_Clf_Loss: 2.2789201736450195, Test_Filter_Loss: 1.9105473825220542e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.40%, Test_Ones_Portion: 5.984592377217268e-08\n",
      "Epoch 358, Total Loss: 2.199157953262329, Clf Loss: 2.199157953262329, Filter Loss: 1.8550912272985443e-07, Seq Loss: 1.0, Accuracy Rate: 40.67%, Ones Portion: 6.064784940917889e-08,             Test_Total_Loss: 2.2774124145507812, Test_Clf_Loss: 2.2774124145507812, Test_Filter_Loss: 1.9188064470654353e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.40%, Test_Ones_Portion: 6.214526138137444e-08\n",
      "Epoch 359, Total Loss: 2.197275400161743, Clf Loss: 2.197275400161743, Filter Loss: 1.9651970717404765e-07, Seq Loss: 1.0, Accuracy Rate: 40.73%, Ones Portion: 6.3261850868912e-08,             Test_Total_Loss: 2.2687811851501465, Test_Clf_Loss: 2.2687811851501465, Test_Filter_Loss: 1.985278004212887e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 6.430610000052184e-08\n",
      "Epoch 360, Total Loss: 2.1992788314819336, Clf Loss: 2.1992788314819336, Filter Loss: 1.8724301753536565e-07, Seq Loss: 1.0, Accuracy Rate: 40.76%, Ones Portion: 6.32054764082568e-08,             Test_Total_Loss: 2.273918628692627, Test_Clf_Loss: 2.273918628692627, Test_Filter_Loss: 1.9467493928004842e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.50%, Test_Ones_Portion: 6.49155609266927e-08\n",
      "Epoch 361, Total Loss: 2.200596570968628, Clf Loss: 2.200596570968628, Filter Loss: 1.9039113396956964e-07, Seq Loss: 1.0, Accuracy Rate: 40.65%, Ones Portion: 6.101736005348357e-08,             Test_Total_Loss: 2.2733075618743896, Test_Clf_Loss: 2.2733075618743896, Test_Filter_Loss: 1.9356248515123298e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 6.41675796941854e-08\n",
      "Epoch 362, Total Loss: 2.1973178386688232, Clf Loss: 2.1973178386688232, Filter Loss: 1.908739335476639e-07, Seq Loss: 1.0, Accuracy Rate: 40.74%, Ones Portion: 6.303990573996998e-08,             Test_Total_Loss: 2.270901918411255, Test_Clf_Loss: 2.270901918411255, Test_Filter_Loss: 1.9890373437192466e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 6.253310402826173e-08\n",
      "Epoch 363, Total Loss: 2.1964304447174072, Clf Loss: 2.1964304447174072, Filter Loss: 2.024198550998335e-07, Seq Loss: 1.0, Accuracy Rate: 40.74%, Ones Portion: 6.861778700795185e-08,             Test_Total_Loss: 2.270890235900879, Test_Clf_Loss: 2.270890235900879, Test_Filter_Loss: 1.9817368013264058e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 6.450001421853813e-08\n",
      "Epoch 364, Total Loss: 2.1983840465545654, Clf Loss: 2.1983840465545654, Filter Loss: 2.068227615836804e-07, Seq Loss: 1.0, Accuracy Rate: 40.67%, Ones Portion: 6.883287539949379e-08,             Test_Total_Loss: 2.2803688049316406, Test_Clf_Loss: 2.2803688049316406, Test_Filter_Loss: 2.048861205139474e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.59%, Test_Ones_Portion: 6.987438183614358e-08\n",
      "Epoch 365, Total Loss: 2.1952903270721436, Clf Loss: 2.1952903270721436, Filter Loss: 1.9707655951606284e-07, Seq Loss: 1.0, Accuracy Rate: 40.74%, Ones Portion: 6.920073047922415e-08,             Test_Total_Loss: 2.273555040359497, Test_Clf_Loss: 2.273555040359497, Test_Filter_Loss: 2.0592496241533809e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.35%, Test_Ones_Portion: 6.630070714663816e-08\n",
      "Epoch 366, Total Loss: 2.1915500164031982, Clf Loss: 2.1915500164031982, Filter Loss: 1.982037929337821e-07, Seq Loss: 1.0, Accuracy Rate: 40.77%, Ones Portion: 6.917093031688637e-08,             Test_Total_Loss: 2.2733726501464844, Test_Clf_Loss: 2.2733726501464844, Test_Filter_Loss: 2.088522137455584e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.50%, Test_Ones_Portion: 6.807369601347091e-08\n",
      "Epoch 367, Total Loss: 2.1897192001342773, Clf Loss: 2.1897192001342773, Filter Loss: 2.0893931207410787e-07, Seq Loss: 1.0, Accuracy Rate: 40.85%, Ones Portion: 7.809725133256507e-08,             Test_Total_Loss: 2.2750985622406006, Test_Clf_Loss: 2.2750985622406006, Test_Filter_Loss: 2.0667059175139002e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 6.865545998380185e-08\n",
      "Epoch 368, Total Loss: 2.188265085220337, Clf Loss: 2.188265085220337, Filter Loss: 2.0451003024390957e-07, Seq Loss: 1.0, Accuracy Rate: 40.92%, Ones Portion: 7.482145036874499e-08,             Test_Total_Loss: 2.2669012546539307, Test_Clf_Loss: 2.2669012546539307, Test_Filter_Loss: 2.0876196060726215e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 7.734973905826337e-08\n",
      "Epoch 369, Total Loss: 2.190180540084839, Clf Loss: 2.190180540084839, Filter Loss: 2.053346435104686e-07, Seq Loss: 1.0, Accuracy Rate: 40.81%, Ones Portion: 7.666770329706196e-08,             Test_Total_Loss: 2.2636425495147705, Test_Clf_Loss: 2.2636425495147705, Test_Filter_Loss: 2.0790287180716405e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 7.798691115112888e-08\n",
      "Epoch 370, Total Loss: 2.186777353286743, Clf Loss: 2.186777353286743, Filter Loss: 2.0324188199083437e-07, Seq Loss: 1.0, Accuracy Rate: 40.94%, Ones Portion: 7.555727421504344e-08,             Test_Total_Loss: 2.2597310543060303, Test_Clf_Loss: 2.2597310543060303, Test_Filter_Loss: 2.065070816570369e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 7.734973905826337e-08\n",
      "Epoch 371, Total Loss: 2.1883203983306885, Clf Loss: 2.1883203983306885, Filter Loss: 1.9902178394204384e-07, Seq Loss: 1.0, Accuracy Rate: 40.97%, Ones Portion: 7.719881978118792e-08,             Test_Total_Loss: 2.2597053050994873, Test_Clf_Loss: 2.2597053050994873, Test_Filter_Loss: 2.036951087802663e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.59%, Test_Ones_Portion: 7.732203499699608e-08\n",
      "Epoch 372, Total Loss: 2.1895785331726074, Clf Loss: 2.1895785331726074, Filter Loss: 2.1042924913672323e-07, Seq Loss: 1.0, Accuracy Rate: 40.93%, Ones Portion: 8.296822073816656e-08,             Test_Total_Loss: 2.2600717544555664, Test_Clf_Loss: 2.2600717544555664, Test_Filter_Loss: 2.026131653565244e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 7.826394465837438e-08\n",
      "Epoch 373, Total Loss: 2.190126895904541, Clf Loss: 2.190126895904541, Filter Loss: 1.960516868848572e-07, Seq Loss: 1.0, Accuracy Rate: 40.88%, Ones Portion: 7.534400481290504e-08,             Test_Total_Loss: 2.2630889415740967, Test_Clf_Loss: 2.2630889415740967, Test_Filter_Loss: 2.076655647442749e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.69%, Test_Ones_Portion: 7.90673269079889e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374, Total Loss: 2.187715768814087, Clf Loss: 2.187715768814087, Filter Loss: 2.1298451713391842e-07, Seq Loss: 1.0, Accuracy Rate: 41.02%, Ones Portion: 8.644474291941151e-08,             Test_Total_Loss: 2.247349977493286, Test_Clf_Loss: 2.247349977493286, Test_Filter_Loss: 2.084578198946474e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.69%, Test_Ones_Portion: 8.989849220597534e-08\n",
      "Epoch 375, Total Loss: 2.185805082321167, Clf Loss: 2.185805082321167, Filter Loss: 2.0079424700725212e-07, Seq Loss: 1.0, Accuracy Rate: 40.93%, Ones Portion: 7.836533200134e-08,             Test_Total_Loss: 2.2579946517944336, Test_Clf_Loss: 2.2579946517944336, Test_Filter_Loss: 2.1097602598274534e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 7.881800456743804e-08\n",
      "Epoch 376, Total Loss: 2.185260772705078, Clf Loss: 2.185260772705078, Filter Loss: 2.081661563124726e-07, Seq Loss: 1.0, Accuracy Rate: 41.08%, Ones Portion: 8.353209324241107e-08,             Test_Total_Loss: 2.2619495391845703, Test_Clf_Loss: 2.2619495391845703, Test_Filter_Loss: 2.1836686414644646e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 7.726663397988887e-08\n",
      "Epoch 377, Total Loss: 2.1818673610687256, Clf Loss: 2.1818673610687256, Filter Loss: 2.1962050311685744e-07, Seq Loss: 1.0, Accuracy Rate: 41.10%, Ones Portion: 8.742522794591423e-08,             Test_Total_Loss: 2.2650809288024902, Test_Clf_Loss: 2.2650809288024902, Test_Filter_Loss: 2.177642386413936e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.59%, Test_Ones_Portion: 7.693419945553615e-08\n",
      "Epoch 378, Total Loss: 2.1855170726776123, Clf Loss: 2.1855170726776123, Filter Loss: 2.1083771173380228e-07, Seq Loss: 1.0, Accuracy Rate: 40.98%, Ones Portion: 8.605268675410116e-08,             Test_Total_Loss: 2.2672650814056396, Test_Clf_Loss: 2.2672650814056396, Test_Filter_Loss: 2.100221223599874e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 7.369295218495608e-08\n",
      "Epoch 379, Total Loss: 2.189561605453491, Clf Loss: 2.189561605453491, Filter Loss: 2.070326132752598e-07, Seq Loss: 1.0, Accuracy Rate: 41.00%, Ones Portion: 8.209756430233028e-08,             Test_Total_Loss: 2.264599323272705, Test_Clf_Loss: 2.264599323272705, Test_Filter_Loss: 2.1162664154417143e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 7.593689588247798e-08\n",
      "Epoch 380, Total Loss: 2.182692289352417, Clf Loss: 2.182692289352417, Filter Loss: 2.0904657560549822e-07, Seq Loss: 1.0, Accuracy Rate: 40.96%, Ones Portion: 8.402643913996144e-08,             Test_Total_Loss: 2.270249605178833, Test_Clf_Loss: 2.270249605178833, Test_Filter_Loss: 2.149142090956957e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 7.638013244104513e-08\n",
      "Epoch 381, Total Loss: 2.1862447261810303, Clf Loss: 2.1862447261810303, Filter Loss: 2.1843148090283648e-07, Seq Loss: 1.0, Accuracy Rate: 41.02%, Ones Portion: 8.877859158928914e-08,             Test_Total_Loss: 2.270946502685547, Test_Clf_Loss: 2.270946502685547, Test_Filter_Loss: 2.153131930526797e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.59%, Test_Ones_Portion: 7.69342065609635e-08\n",
      "Epoch 382, Total Loss: 2.1871511936187744, Clf Loss: 2.1871511936187744, Filter Loss: 2.2220521600502252e-07, Seq Loss: 1.0, Accuracy Rate: 41.03%, Ones Portion: 8.898839354287702e-08,             Test_Total_Loss: 2.2619457244873047, Test_Clf_Loss: 2.2619457244873047, Test_Filter_Loss: 2.2220531548100553e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 7.937205737107433e-08\n",
      "Epoch 383, Total Loss: 2.181551933288574, Clf Loss: 2.181551933288574, Filter Loss: 2.198159307909009e-07, Seq Loss: 1.0, Accuracy Rate: 41.10%, Ones Portion: 9.057140459844959e-08,             Test_Total_Loss: 2.260824203491211, Test_Clf_Loss: 2.260824203491211, Test_Filter_Loss: 2.3028320583762252e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 8.189302036498702e-08\n",
      "Epoch 384, Total Loss: 2.1822378635406494, Clf Loss: 2.1822378635406494, Filter Loss: 2.224213204726766e-07, Seq Loss: 1.0, Accuracy Rate: 41.19%, Ones Portion: 9.147861845804073e-08,             Test_Total_Loss: 2.267279624938965, Test_Clf_Loss: 2.267279624938965, Test_Filter_Loss: 2.2463780169346137e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.74%, Test_Ones_Portion: 9.397083289286456e-08\n",
      "Epoch 385, Total Loss: 2.187323808670044, Clf Loss: 2.187323808670044, Filter Loss: 2.3587280395531707e-07, Seq Loss: 1.0, Accuracy Rate: 40.96%, Ones Portion: 9.728385919061111e-08,             Test_Total_Loss: 2.265289306640625, Test_Clf_Loss: 2.265289306640625, Test_Filter_Loss: 2.294917038625499e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.40%, Test_Ones_Portion: 8.505115545176523e-08\n",
      "Epoch 386, Total Loss: 2.1846349239349365, Clf Loss: 2.1846349239349365, Filter Loss: 2.1912131842327653e-07, Seq Loss: 1.0, Accuracy Rate: 41.02%, Ones Portion: 9.212209306497243e-08,             Test_Total_Loss: 2.2620811462402344, Test_Clf_Loss: 2.2620811462402344, Test_Filter_Loss: 2.2610616667861905e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 8.302885134980897e-08\n",
      "Epoch 387, Total Loss: 2.1827638149261475, Clf Loss: 2.1827638149261475, Filter Loss: 2.175759590272719e-07, Seq Loss: 1.0, Accuracy Rate: 41.08%, Ones Portion: 9.014949853280996e-08,             Test_Total_Loss: 2.2736527919769287, Test_Clf_Loss: 2.2736527919769287, Test_Filter_Loss: 2.1713975684178877e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 7.881800456743804e-08\n",
      "Epoch 388, Total Loss: 2.183795213699341, Clf Loss: 2.183795213699341, Filter Loss: 2.3075659782989533e-07, Seq Loss: 1.0, Accuracy Rate: 41.02%, Ones Portion: 9.955799384897546e-08,             Test_Total_Loss: 2.266386032104492, Test_Clf_Loss: 2.266386032104492, Test_Filter_Loss: 2.218953056853934e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.59%, Test_Ones_Portion: 8.144976959556516e-08\n",
      "Epoch 389, Total Loss: 2.1877050399780273, Clf Loss: 2.1877050399780273, Filter Loss: 2.1666625116267824e-07, Seq Loss: 1.0, Accuracy Rate: 40.98%, Ones Portion: 8.949201202312906e-08,             Test_Total_Loss: 2.2679717540740967, Test_Clf_Loss: 2.2679717540740967, Test_Filter_Loss: 2.163527881293703e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 7.674027102666514e-08\n",
      "Epoch 390, Total Loss: 2.1833572387695312, Clf Loss: 2.1833572387695312, Filter Loss: 2.1423140594833967e-07, Seq Loss: 1.0, Accuracy Rate: 40.91%, Ones Portion: 8.766321712982972e-08,             Test_Total_Loss: 2.2705135345458984, Test_Clf_Loss: 2.2705135345458984, Test_Filter_Loss: 2.139595096650737e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 7.674027102666514e-08\n",
      "Epoch 391, Total Loss: 2.185194730758667, Clf Loss: 2.185194730758667, Filter Loss: 2.185257272913077e-07, Seq Loss: 1.0, Accuracy Rate: 41.03%, Ones Portion: 8.199776857509278e-08,             Test_Total_Loss: 2.271054267883301, Test_Clf_Loss: 2.271054267883301, Test_Filter_Loss: 2.0563554414820828e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.50%, Test_Ones_Portion: 7.529972378961247e-08\n",
      "Epoch 392, Total Loss: 2.185109853744507, Clf Loss: 2.185109853744507, Filter Loss: 1.9428509290264628e-07, Seq Loss: 1.0, Accuracy Rate: 40.96%, Ones Portion: 7.689953207545841e-08,             Test_Total_Loss: 2.2671103477478027, Test_Clf_Loss: 2.2671103477478027, Test_Filter_Loss: 2.0839978276399052e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 7.543823699052155e-08\n",
      "Epoch 393, Total Loss: 2.183465003967285, Clf Loss: 2.183465003967285, Filter Loss: 2.0815694767861714e-07, Seq Loss: 1.0, Accuracy Rate: 41.02%, Ones Portion: 8.479514690407086e-08,             Test_Total_Loss: 2.2666893005371094, Test_Clf_Loss: 2.2666893005371094, Test_Filter_Loss: 2.1121695681358688e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.64%, Test_Ones_Portion: 7.687879133300157e-08\n",
      "Epoch 394, Total Loss: 2.184185028076172, Clf Loss: 2.184185028076172, Filter Loss: 2.1285590889874584e-07, Seq Loss: 1.0, Accuracy Rate: 40.97%, Ones Portion: 8.512303395491472e-08,             Test_Total_Loss: 2.269887924194336, Test_Clf_Loss: 2.269887924194336, Test_Filter_Loss: 2.1160784058338322e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.50%, Test_Ones_Portion: 7.674027102666514e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395, Total Loss: 2.183882713317871, Clf Loss: 2.183882713317871, Filter Loss: 2.0444824144760787e-07, Seq Loss: 1.0, Accuracy Rate: 41.03%, Ones Portion: 8.122474781657729e-08,             Test_Total_Loss: 2.2695000171661377, Test_Clf_Loss: 2.2695000171661377, Test_Filter_Loss: 2.136863486157381e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 7.7017311639338e-08\n",
      "Epoch 396, Total Loss: 2.1811654567718506, Clf Loss: 2.1811654567718506, Filter Loss: 2.046058682481089e-07, Seq Loss: 1.0, Accuracy Rate: 41.00%, Ones Portion: 8.160716902239074e-08,             Test_Total_Loss: 2.2678606510162354, Test_Clf_Loss: 2.2678606510162354, Test_Filter_Loss: 2.0884830576051172e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 7.665716594829064e-08\n",
      "Epoch 397, Total Loss: 2.1816279888153076, Clf Loss: 2.1816279888153076, Filter Loss: 2.0418946178324404e-07, Seq Loss: 1.0, Accuracy Rate: 41.02%, Ones Portion: 8.355885228183979e-08,             Test_Total_Loss: 2.26684308052063, Test_Clf_Loss: 2.26684308052063, Test_Filter_Loss: 2.061054829027853e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 7.629702736267063e-08\n",
      "Epoch 398, Total Loss: 2.187589645385742, Clf Loss: 2.187589645385742, Filter Loss: 2.0194097771764064e-07, Seq Loss: 1.0, Accuracy Rate: 40.97%, Ones Portion: 7.841605764724591e-08,             Test_Total_Loss: 2.2655720710754395, Test_Clf_Loss: 2.2655720710754395, Test_Filter_Loss: 2.0572967684984178e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.40%, Test_Ones_Portion: 7.510580246616883e-08\n",
      "Epoch 399, Total Loss: 2.183973550796509, Clf Loss: 2.183973550796509, Filter Loss: 1.9804436135473225e-07, Seq Loss: 1.0, Accuracy Rate: 40.99%, Ones Portion: 8.04612980687125e-08,             Test_Total_Loss: 2.2698416709899902, Test_Clf_Loss: 2.2698416709899902, Test_Filter_Loss: 2.070325280101315e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.55%, Test_Ones_Portion: 7.58260867428362e-08\n",
      "Epoch 400, Total Loss: 2.1866371631622314, Clf Loss: 2.1866371631622314, Filter Loss: 1.9999774281131977e-07, Seq Loss: 1.0, Accuracy Rate: 40.79%, Ones Portion: 7.748220554049112e-08,             Test_Total_Loss: 2.266638994216919, Test_Clf_Loss: 2.266638994216919, Test_Filter_Loss: 2.0539697231924947e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.50%, Test_Ones_Portion: 7.358213593988694e-08\n",
      "Epoch 401, Total Loss: 2.1872849464416504, Clf Loss: 2.1872849464416504, Filter Loss: 1.942766942875096e-07, Seq Loss: 1.0, Accuracy Rate: 40.96%, Ones Portion: 7.552370107077877e-08,             Test_Total_Loss: 2.2668886184692383, Test_Clf_Loss: 2.2668886184692383, Test_Filter_Loss: 2.0080587148640916e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 7.341591867771058e-08\n",
      "Epoch 402, Total Loss: 2.1898694038391113, Clf Loss: 2.1898694038391113, Filter Loss: 1.9774597603827715e-07, Seq Loss: 1.0, Accuracy Rate: 40.90%, Ones Portion: 7.557443382211204e-08,             Test_Total_Loss: 2.272663116455078, Test_Clf_Loss: 2.272663116455078, Test_Filter_Loss: 2.042408340230395e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 7.294496384702143e-08\n",
      "Epoch 403, Total Loss: 2.1901392936706543, Clf Loss: 2.1901392936706543, Filter Loss: 2.0166223180240195e-07, Seq Loss: 1.0, Accuracy Rate: 40.80%, Ones Portion: 7.358813292057675e-08,             Test_Total_Loss: 2.2717678546905518, Test_Clf_Loss: 2.2717678546905518, Test_Filter_Loss: 2.063793829165661e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.45%, Test_Ones_Portion: 7.311118110919779e-08\n",
      "Epoch 404, Total Loss: 2.184263229370117, Clf Loss: 2.184263229370117, Filter Loss: 2.1902529567796591e-07, Seq Loss: 1.0, Accuracy Rate: 40.96%, Ones Portion: 8.390022543380837e-08,             Test_Total_Loss: 2.266267776489258, Test_Clf_Loss: 2.266267776489258, Test_Filter_Loss: 2.0848980852861132e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.40%, Test_Ones_Portion: 7.360984000115423e-08\n",
      "Epoch 405, Total Loss: 2.186922788619995, Clf Loss: 2.186922788619995, Filter Loss: 1.977703192324043e-07, Seq Loss: 1.0, Accuracy Rate: 40.97%, Ones Portion: 7.4329655319616e-08,             Test_Total_Loss: 2.2757625579833984, Test_Clf_Loss: 2.2757625579833984, Test_Filter_Loss: 2.0057933625139412e-07, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 39.30%, Test_Ones_Portion: 7.383146538586516e-08\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2000\n",
    "DateID = '2019110801'\n",
    "\n",
    "saveP1 = './model/'+DateID+'/model1'\n",
    "saveP2 = './model/'+DateID+'/model2'\n",
    "train_loss_acc = []\n",
    "train_loss_filter = []\n",
    "train_loss_seq = []\n",
    "train_weighted_loss = []\n",
    "train_acc_rate = []\n",
    "train_ones_num = []\n",
    "\n",
    "test_loss_acc = []\n",
    "test_loss_filter = []\n",
    "test_loss_seq = []\n",
    "test_weighted_loss = []\n",
    "test_acc_rate = []\n",
    "test_ones_num = []\n",
    "\n",
    "# signature_dict = {'att':model1.att}\n",
    "\n",
    "gc.collect()\n",
    "best_clf = 0.0\n",
    "for epoch in range(EPOCHS):\n",
    "    for text, labels in train_ds:\n",
    "        train_step(text, labels)\n",
    "\n",
    "    for test_text, test_labels in valid_ds:\n",
    "        test_step(test_text, test_labels)\n",
    "\n",
    "    template = 'Epoch {}, Total Loss: {}, Clf Loss: {}, Filter Loss: {}, Seq Loss: {}, Accuracy Rate: {:5.2f}%, Ones Portion: {}, \\\n",
    "            Test_Total_Loss: {}, Test_Clf_Loss: {}, Test_Filter_Loss: {}, TEST_Seq_Loss: {}, Test_Accuracy_Rate: {:5.2f}%, Test_Ones_Portion: {}'\n",
    "    print(template.format(epoch+1,train_loss.result(),\n",
    "                          train_accloss.result(),train_filloss.result(),train_seqloss.result(),\n",
    "                        train_accuracy.result()*100,train_ones.result(),\n",
    "                        test_loss.result(),\n",
    "                        test_accloss.result(),test_filloss.result(),test_seqloss.result(),\n",
    "                        test_accuracy.result()*100,test_ones.result(),\n",
    "                        ))\n",
    "\n",
    "    train_loss_acc.append( train_accloss.result().numpy())\n",
    "    train_loss_filter.append( train_filloss.result().numpy())\n",
    "    train_loss_seq.append( train_seqloss.result().numpy())\n",
    "    train_weighted_loss.append( train_loss.result().numpy())\n",
    "    train_acc_rate.append( train_accuracy.result().numpy())\n",
    "    train_ones_num.append( train_ones.result().numpy())\n",
    "    \n",
    "    test_loss_acc.append( test_accloss.result().numpy())\n",
    "    test_loss_filter.append( test_filloss.result().numpy())\n",
    "    test_loss_seq.append( test_seqloss.result().numpy())\n",
    "    test_weighted_loss.append( test_loss.result().numpy())\n",
    "    test_acc_rate.append( test_accuracy.result().numpy())\n",
    "    test_ones_num.append( test_ones.result().numpy())\n",
    "    if best_clf<=test_accuracy.result()*100:\n",
    "        #tf.saved_model.save(model1,saveP1+'_all')\n",
    "        #model1.save(saveP1,save_format='h5')\n",
    "        #model2.save(saveP2,save_format='h5')\n",
    "        #tf.saved_model.save(model2,saveP2+'_all')\n",
    "        model1.save_weights(saveP1,save_format='tf')\n",
    "        model2.save_weights(saveP2,save_format='tf')\n",
    "        best_clf = test_accuracy.result()*100\n",
    "        print('===MODEL WEIGHTS SAVED===',saveP1,saveP2)\n",
    "    # Reset the metrics for the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accloss.reset_states()\n",
    "    train_filloss.reset_states()\n",
    "    train_seqloss.reset_states()\n",
    "    train_ones.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    test_loss.reset_states()\n",
    "    test_accloss.reset_states()\n",
    "    test_filloss.reset_states()\n",
    "    test_seqloss.reset_states()\n",
    "    test_ones.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train total loss</th>\n",
       "      <th>train acc loss</th>\n",
       "      <th>train filter loss</th>\n",
       "      <th>train seq loss</th>\n",
       "      <th>train acc rate</th>\n",
       "      <th>train ones num</th>\n",
       "      <th>test total loss</th>\n",
       "      <th>test acc loss</th>\n",
       "      <th>test filter loss</th>\n",
       "      <th>test seq loss</th>\n",
       "      <th>test acc rate</th>\n",
       "      <th>test ones num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.659511</td>\n",
       "      <td>2.659450</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.362077</td>\n",
       "      <td>2.362016</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371733</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.329190</td>\n",
       "      <td>2.329129</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.251624</td>\n",
       "      <td>2.251564</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372701</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.995442</td>\n",
       "      <td>1.995381</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.899837</td>\n",
       "      <td>1.899777</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518877</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.836639</td>\n",
       "      <td>1.836579</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.799838</td>\n",
       "      <td>1.799778</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.543562</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.789347</td>\n",
       "      <td>1.789287</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.904030</td>\n",
       "      <td>1.903970</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518877</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.964969</td>\n",
       "      <td>0.964969</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.707264</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>2.291040</td>\n",
       "      <td>2.291040</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.564860</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.960884</td>\n",
       "      <td>0.960884</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.709201</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>2.273444</td>\n",
       "      <td>2.273444</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.567280</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1.058729</td>\n",
       "      <td>1.058729</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.681840</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>2.222906</td>\n",
       "      <td>2.222906</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.563892</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.028507</td>\n",
       "      <td>1.028507</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.691889</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>2.163985</td>\n",
       "      <td>2.163985</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.570668</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1.021370</td>\n",
       "      <td>1.021370</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.694673</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>2.183733</td>\n",
       "      <td>2.183733</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.575992</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      train total loss  train acc loss  train filter loss  train seq loss  \\\n",
       "0             2.659511        2.659450           0.600000        0.000000   \n",
       "1             2.329190        2.329129           0.600000        0.000000   \n",
       "2             1.995442        1.995381           0.600000        0.000000   \n",
       "3             1.836639        1.836579           0.600000        0.000000   \n",
       "4             1.789347        1.789287           0.600000        0.000000   \n",
       "...                ...             ...                ...             ...   \n",
       "1995          0.964969        0.964969           0.000033        0.999999   \n",
       "1996          0.960884        0.960884           0.000033        0.999998   \n",
       "1997          1.058729        1.058729           0.000033        0.999999   \n",
       "1998          1.028507        1.028507           0.000034        0.999999   \n",
       "1999          1.021370        1.021370           0.000033        0.999999   \n",
       "\n",
       "      train acc rate  train ones num  test total loss  test acc loss  \\\n",
       "0           0.369855        1.000000         2.362077       2.362016   \n",
       "1           0.377240        1.000000         2.251624       2.251564   \n",
       "2           0.496731        1.000000         1.899837       1.899777   \n",
       "3           0.535956        1.000000         1.799838       1.799778   \n",
       "4           0.552542        1.000000         1.904030       1.903970   \n",
       "...              ...             ...              ...            ...   \n",
       "1995        0.707264        0.000048         2.291040       2.291040   \n",
       "1996        0.709201        0.000048         2.273444       2.273444   \n",
       "1997        0.681840        0.000048         2.222906       2.222906   \n",
       "1998        0.691889        0.000048         2.163985       2.163985   \n",
       "1999        0.694673        0.000048         2.183733       2.183733   \n",
       "\n",
       "      test filter loss  test seq loss  test acc rate  test ones num  \n",
       "0             0.600000       0.000000       0.371733       1.000000  \n",
       "1             0.600000       0.000000       0.372701       1.000000  \n",
       "2             0.600000       0.000000       0.518877       1.000000  \n",
       "3             0.600000       0.000000       0.543562       1.000000  \n",
       "4             0.600000       0.000000       0.518877       1.000000  \n",
       "...                ...            ...            ...            ...  \n",
       "1995          0.000035       0.999998       0.564860       0.000051  \n",
       "1996          0.000035       0.999998       0.567280       0.000051  \n",
       "1997          0.000035       0.999998       0.563892       0.000050  \n",
       "1998          0.000035       0.999998       0.570668       0.000051  \n",
       "1999          0.000035       0.999998       0.575992       0.000050  \n",
       "\n",
       "[2000 rows x 12 columns]"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = './results/'+DateID+'/'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "saveR = save_dir + 'losses_metrics.xlsx'\n",
    "data = {'train total loss':train_weighted_loss, 'train acc loss':train_loss_acc,\n",
    "        'train filter loss':train_loss_filter,'train seq loss':train_loss_seq,\n",
    "        'train acc rate':train_acc_rate, 'train ones num':train_ones_num,\n",
    "        'test total loss':test_weighted_loss, 'test acc loss':test_loss_acc,\n",
    "        'test filter loss':test_loss_filter, 'test seq loss': test_loss_seq,\n",
    "        'test acc rate':test_acc_rate, 'test ones num':test_ones_num\n",
    "       }\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel(saveR)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019110601'"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DateID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(None, dtype=object)"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_weighted_loss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.3583207, dtype=float32)"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk = np.array(test_accloss.result())\n",
    "kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3583207"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accloss.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1125\u001b[0m                                        \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m                                        sigcls=Signature)\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2287\u001b[0m         return _signature_from_builtin(sigcls, obj,\n\u001b[0;32m-> 2288\u001b[0;31m                                        skip_bound_arg=skip_bound_arg)\n\u001b[0m\u001b[1;32m   2289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_builtin\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no signature found for builtin {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no signature found for builtin <tensorflow.python.keras.saving.saved_model.save_impl.LayerCall object at 0x7f052aadf350>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-523-1449814dd641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model1.save('./model/emb_layer') #tf.keras.models.load_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'./model/emb_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/emb_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    868\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msignatures\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     signatures = signature_serialization.find_function_to_export(\n\u001b[0;32m--> 870\u001b[0;31m         checkpoint_graph_view)\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m   \u001b[0msignatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature_serialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_signatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_serialization.py\u001b[0m in \u001b[0;36mfind_function_to_export\u001b[0;34m(saveable_view)\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;31m# If the user did not specify signatures, check the root object for a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;31m# that can be made into a signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEFAULT_SIGNATURE_ATTR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msignature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36mlist_functions\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobj_functions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access\n\u001b[0;32m--> 141\u001b[0;31m           self._serialization_cache)\n\u001b[0m\u001b[1;32m    142\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_list_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m   2420\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_list_functions_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     return (self._trackable_saved_model_saver\n\u001b[0;32m-> 2422\u001b[0;31m             .list_functions_for_serialization(serialization_cache))\n\u001b[0m\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/base_serialization.py\u001b[0m in \u001b[0;36mlist_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mConcreteFunction\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mfns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# The parent AutoTrackable class saves all user-defined tf.functions, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36mfunctions_to_serialize\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfunctions_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     return (self._get_serialized_attributes(\n\u001b[0;32m---> 79\u001b[0;31m         serialization_cache).functions_to_serialize)\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_serialized_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     object_dict, function_dict = self._get_serialized_attributes_internal(\n\u001b[0;32m---> 94\u001b[0;31m         serialization_cache)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mserialized_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_and_validate_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/model_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# cache (i.e. this is the root level object).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKERAS_CACHE_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m       \u001b[0mdefault_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_save_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Other than the default signature function, all other attributes match with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mdefault_save_signature\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[0moriginal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reset_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m   \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_model_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m   \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m   \u001b[0m_restore_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36m_wrapped_model\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    141\u001b[0m     with base_layer_utils.call_context().enter(\n\u001b[1;32m    142\u001b[0m         model, inputs=inputs, build_graph=False, training=False, saving=True):\n\u001b[0;32m--> 143\u001b[0;31m       \u001b[0moutputs_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-498-f3457470eec4>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#x = self.rnn1(x1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#x = self.bn1(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    218\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mhas_arg\u001b[0;34m(fn, name, accept_all)\u001b[0m\n\u001b[1;32m    302\u001b[0m       \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhether\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0maccepts\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mname\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m   \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m   \u001b[0marg_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maccept_all\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvarkw\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/util/tf_inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator_argspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_maybe_argspec_to_fullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_getfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m# else. So to be fully backwards compatible, we catch all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# possible exceptions here, and reraise a TypeError.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unsupported callable'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported callable"
     ]
    }
   ],
   "source": [
    "# model1.save('./model/emb_layer') #tf.keras.models.load_model\n",
    "tf.saved_model.save(model1,'./model/emb_layer')\n",
    "model3 = tf.keras.models.load_model('./model/emb_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CheckpointLoadStatus' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-524-07c6ede4bf0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/emb_layer_weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'CheckpointLoadStatus' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "model3 = model1.load_weights('./model/emb_layer_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.emb.set_weights(model3.emb.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"base_model_1_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_58 (Masking)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "glove_emb (Embedding)        multiple                  2138112   \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You tried to call `count_params` on common_extract, but the layer isn't built. You can build it manually via: `common_extract.build(batch_input_shape)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-526-cdf54a019e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/emb_layer_weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1263\u001b[0m                               \u001b[0mline_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m                               \u001b[0mpositions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m                               print_fn=print_fn)\n\u001b[0m\u001b[1;32m   1266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_validate_graph_inputs_and_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/layer_utils.py\u001b[0m in \u001b[0;36mprint_summary\u001b[0;34m(model, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m    224\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequential_like\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m       \u001b[0mprint_layer_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m       \u001b[0mprint_layer_summary_with_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/layer_utils.py\u001b[0m in \u001b[0;36mprint_layer_summary\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mcls_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ('\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m')'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0mprint_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mcount_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1627\u001b[0m                          \u001b[0;34m', but the layer isn\\'t built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m                          \u001b[0;34m'You can build it manually via: `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m                          '.build(batch_input_shape)`.')\n\u001b[0m\u001b[1;32m   1630\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You tried to call `count_params` on common_extract, but the layer isn't built. You can build it manually via: `common_extract.build(batch_input_shape)`."
     ]
    }
   ],
   "source": [
    "model3 = model1\n",
    "model3.load_weights('./model/emb_layer_weight')\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 在某些參數的情況下0 1是train不起來的但是weight可以\n",
    "    * alpha = 0.0, beta=0.6\n",
    "    * init_w = tensorflow.keras.initializers.Constant(value=0.9), init_b = tensorflow.keras.initializers.Constant(value=0.7)\n",
    "* 0/1 with emb比較容易overfit。如果是weight的比較沒那麼嚴重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 不用sigmoid或是hard_sigmoid。改良relu + linear，並拆成兩個model，把round前面多加上clip\n",
    "    * sigmoid中間的變化太快(一瞬間就會掉到0或是1)，改成relu在>0~無限大(linear為了還在0~1)再去clip再round，可以看到每個epoch的變化\n",
    "* 1st phase的beta一定要>=0.6否則不會動，ones#都會是0\n",
    "    * beta=1 (放0 1進去): weight init設成1也沒用，但把bias設成1就會一開始都是ones#=1了。weight=1 bias=0.2都匯市0，bias=0.3會是0.87。0.6/0.3都是0。0.8/0.3差不多是0.5(但是train很慢acc進步很慢就是了)。0.5/0.5是從0.01開始往上升 (0 1放進去會比較難train是因為它的變化量太大，一下就是有或沒有，所以clf可能學不好，但如果是weight每次gradient進步的都是一小點就會比較容易上升)\n",
    "    * beta=0.6 (放0 1進去): 0.8/0.5都是0。0.9/0.8 從0.9一直到0。0.9/0.6差不多是從0.5但又有時候到0.7都是0.0(很難train，Nadam換個opt有時候沒用。EX變成adam 0.9/0.8才有0.96開始但如果0.9/0.75變成0開始。Rmsprop 0.9/0.8又是從0.95開始往下)。但如果都改成傳入weight就都沒問題。ones一開始大概0.5 weight平均，也不會卡住\n",
    "* 建議: 先訓練embedding weight matrix，但是要看goal是要怎樣的matrix\n",
    "* 其實他不管幾%都會train得很好，除非固定embedding，或是用更弱的clf\n",
    "* 若設定alpha，就像是regularizer term (penalty)，設越大drop越多\n",
    "* 一開始先很多ones，再越來越少個"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 同一個opt若加入transform就會train不起來\n",
    "* 兩個不同的opt加入transform也會train不起來 (persistent、non-persis都不行)，且與BN無關"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
