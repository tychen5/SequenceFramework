{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.text import *\n",
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import pickle\n",
    "import gc\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_statistics(all_length):\n",
    "    '''\n",
    "    input: length list of elements e.g.[1,1,1,3,5,9,4,2,1,3,54,78,5...]\n",
    "    output1: mean、std、mode、min、q1、median(q2)、q3、max、iqr、outlier、far out\n",
    "    output2: statistics graph、10%~90% form\n",
    "    '''\n",
    "    stat_dict = {}\n",
    "    stat_dict['mean'] = np.mean(all_length)\n",
    "    stat_dict['std'] = np.std(all_length)\n",
    "    stat_dict['mode'] = np.argmax(np.bincount(all_length))\n",
    "    stat_dict['min'] = np.min(all_length)\n",
    "    stat_dict['q1'] = np.quantile(all_length,0.25)\n",
    "    stat_dict['median'] = np.quantile(all_length,0.5)\n",
    "    stat_dict['q3'] = np.quantile(all_length,0.75)\n",
    "    stat_dict['max'] = np.max(all_length)\n",
    "    stat_dict['iqr'] = stat_dict['q3'] - stat_dict['q1']\n",
    "    stat_dict['outlier'] = stat_dict['q3'] + 1.5*stat_dict['iqr']\n",
    "    stat_dict['far_out'] = stat_dict['q3'] + 3*stat_dict['iqr']\n",
    "    for i in [10,20,30,40,50,60,70,80,90,100]:\n",
    "        stat_dict[str(i)+'%'] = np.percentile(all_length,i)\n",
    "    return pd.DataFrame.from_dict(stat_dict,orient='index',columns=['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 8352#8352 #Top most frequent words to consider. Any less frequent word will appear as oov_char value in the sequence data.\n",
    "max_length = 360#360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_words#: 30979\n",
      "8260 train sequences\n",
      "2066 test sequences\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "print('all_words#:',len(word_index))\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,maxlen=max_length,\n",
    "                                                         test_split=0.2,seed=830913)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>145.964197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>145.878476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q1</th>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q3</th>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2376.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iqr</th>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlier</th>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_out</th>\n",
       "      <td>540.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>154.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>206.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>315.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100%</th>\n",
       "      <td>2376.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              length\n",
       "mean      145.964197\n",
       "std       145.878476\n",
       "mode       17.000000\n",
       "min         2.000000\n",
       "q1         60.000000\n",
       "median     95.000000\n",
       "q3        180.000000\n",
       "max      2376.000000\n",
       "iqr       120.000000\n",
       "outlier   360.000000\n",
       "far_out   540.000000\n",
       "10%        35.000000\n",
       "20%        53.000000\n",
       "30%        67.000000\n",
       "40%        81.000000\n",
       "50%        95.000000\n",
       "60%       112.000000\n",
       "70%       154.000000\n",
       "80%       206.000000\n",
       "90%       315.000000\n",
       "100%     2376.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_len = [len(x) for x in x_train]\n",
    "# test_len = [len(x) for x in x_test]\n",
    "# all_len = train_len\n",
    "# all_len.extend(test_len)\n",
    "# basic_statistics(all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(all_len)\n",
    "# df.to_excel('./results/length_dist.xlsx', header=False, index=False)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 11228,\n",
       "         53: 4213,\n",
       "         352: 647,\n",
       "         26: 8451,\n",
       "         14: 15015,\n",
       "         279: 801,\n",
       "         39: 5818,\n",
       "         72: 3091,\n",
       "         4497: 26,\n",
       "         18: 11039,\n",
       "         83: 2597,\n",
       "         5291: 21,\n",
       "         88: 2381,\n",
       "         5397: 20,\n",
       "         11: 20141,\n",
       "         3412: 37,\n",
       "         19: 10755,\n",
       "         151: 1363,\n",
       "         230: 962,\n",
       "         831: 253,\n",
       "         15: 13329,\n",
       "         165: 1232,\n",
       "         318: 707,\n",
       "         3780: 33,\n",
       "         124: 1676,\n",
       "         1527: 117,\n",
       "         1424: 128,\n",
       "         35: 6588,\n",
       "         5302: 20,\n",
       "         12: 16668,\n",
       "         17: 11191,\n",
       "         486: 459,\n",
       "         341: 663,\n",
       "         142: 1466,\n",
       "         255: 870,\n",
       "         219: 997,\n",
       "         429: 528,\n",
       "         68: 3363,\n",
       "         146: 1402,\n",
       "         252: 882,\n",
       "         191: 1098,\n",
       "         15448: 3,\n",
       "         3631: 35,\n",
       "         2283: 65,\n",
       "         71: 3120,\n",
       "         10: 29581,\n",
       "         342: 660,\n",
       "         49: 4565,\n",
       "         1977: 80,\n",
       "         324: 695,\n",
       "         27: 8311,\n",
       "         9222: 8,\n",
       "         672: 330,\n",
       "         450: 506,\n",
       "         5: 42393,\n",
       "         547: 406,\n",
       "         40: 5593,\n",
       "         471: 476,\n",
       "         4810: 24,\n",
       "         149: 1371,\n",
       "         26639: 1,\n",
       "         794: 266,\n",
       "         734: 300,\n",
       "         8976: 8,\n",
       "         8975: 8,\n",
       "         4007: 31,\n",
       "         9: 29956,\n",
       "         25113: 1,\n",
       "         247: 904,\n",
       "         8: 29978,\n",
       "         1299: 144,\n",
       "         381: 618,\n",
       "         34: 7010,\n",
       "         385: 604,\n",
       "         13: 15224,\n",
       "         109: 1810,\n",
       "         167: 1224,\n",
       "         4: 82723,\n",
       "         60: 3654,\n",
       "         130: 1617,\n",
       "         1461: 123,\n",
       "         3366: 38,\n",
       "         1896: 86,\n",
       "         204: 1046,\n",
       "         33: 7037,\n",
       "         3512: 36,\n",
       "         888: 234,\n",
       "         25: 8579,\n",
       "         423: 535,\n",
       "         256: 866,\n",
       "         7: 33157,\n",
       "         1075: 185,\n",
       "         329: 685,\n",
       "         769: 281,\n",
       "         302: 742,\n",
       "         113: 1749,\n",
       "         446: 508,\n",
       "         107: 1841,\n",
       "         226: 979,\n",
       "         240: 923,\n",
       "         817: 258,\n",
       "         101: 1923,\n",
       "         36: 6436,\n",
       "         189: 1107,\n",
       "         6501: 15,\n",
       "         57: 3756,\n",
       "         6: 40350,\n",
       "         481: 464,\n",
       "         239: 927,\n",
       "         118: 1704,\n",
       "         246: 905,\n",
       "         424: 535,\n",
       "         386: 601,\n",
       "         415: 545,\n",
       "         1677: 103,\n",
       "         24: 9022,\n",
       "         291: 767,\n",
       "         662: 337,\n",
       "         85: 2474,\n",
       "         2243: 67,\n",
       "         880: 236,\n",
       "         224: 988,\n",
       "         1077: 184,\n",
       "         54: 3858,\n",
       "         29: 7797,\n",
       "         530: 419,\n",
       "         30: 7627,\n",
       "         1500: 119,\n",
       "         4175: 29,\n",
       "         69: 3203,\n",
       "         12040: 5,\n",
       "         84: 2506,\n",
       "         442: 509,\n",
       "         31: 7288,\n",
       "         373: 628,\n",
       "         159: 1298,\n",
       "         7370: 12,\n",
       "         41: 5553,\n",
       "         351: 648,\n",
       "         343: 656,\n",
       "         6880: 14,\n",
       "         21: 10377,\n",
       "         840: 249,\n",
       "         184: 1129,\n",
       "         5463: 20,\n",
       "         526: 420,\n",
       "         87: 2405,\n",
       "         108: 1812,\n",
       "         140: 1471,\n",
       "         168: 1207,\n",
       "         231: 961,\n",
       "         286: 779,\n",
       "         1351: 138,\n",
       "         397: 574,\n",
       "         105: 1866,\n",
       "         3497: 36,\n",
       "         120: 1694,\n",
       "         1456: 124,\n",
       "         161: 1272,\n",
       "         64: 3453,\n",
       "         1909: 84,\n",
       "         762: 283,\n",
       "         550: 403,\n",
       "         325: 694,\n",
       "         1766: 95,\n",
       "         613: 365,\n",
       "         548: 406,\n",
       "         3205: 41,\n",
       "         16: 12395,\n",
       "         5700: 18,\n",
       "         15663: 3,\n",
       "         51: 4256,\n",
       "         562: 396,\n",
       "         299: 753,\n",
       "         45: 5081,\n",
       "         306: 733,\n",
       "         194: 1086,\n",
       "         572: 388,\n",
       "         1222: 156,\n",
       "         3586: 35,\n",
       "         7718: 11,\n",
       "         22: 9345,\n",
       "         3297: 39,\n",
       "         3380: 38,\n",
       "         66: 3380,\n",
       "         2794: 50,\n",
       "         1163: 167,\n",
       "         178: 1160,\n",
       "         74: 3060,\n",
       "         865: 242,\n",
       "         46: 4836,\n",
       "         353: 645,\n",
       "         134: 1564,\n",
       "         70: 3184,\n",
       "         4596: 25,\n",
       "         86: 2434,\n",
       "         47: 4688,\n",
       "         4315: 27,\n",
       "         597: 377,\n",
       "         688: 323,\n",
       "         5242: 21,\n",
       "         32: 7100,\n",
       "         4215: 28,\n",
       "         63: 3492,\n",
       "         180: 1143,\n",
       "         183: 1133,\n",
       "         61: 3652,\n",
       "         2979: 46,\n",
       "         59: 3689,\n",
       "         4999: 22,\n",
       "         123: 1680,\n",
       "         235: 946,\n",
       "         131: 1607,\n",
       "         891: 233,\n",
       "         4088: 30,\n",
       "         98: 2063,\n",
       "         1025: 196,\n",
       "         633: 351,\n",
       "         2543: 58,\n",
       "         150: 1366,\n",
       "         710: 313,\n",
       "         220: 994,\n",
       "         48: 4574,\n",
       "         864: 243,\n",
       "         276: 809,\n",
       "         360: 641,\n",
       "         211: 1026,\n",
       "         1004: 203,\n",
       "         128: 1619,\n",
       "         10485: 6,\n",
       "         5769: 18,\n",
       "         651: 343,\n",
       "         574: 387,\n",
       "         400: 571,\n",
       "         3673: 34,\n",
       "         6189: 16,\n",
       "         186: 1121,\n",
       "         3879: 32,\n",
       "         968: 212,\n",
       "         90: 2331,\n",
       "         1081: 183,\n",
       "         5604: 19,\n",
       "         4167: 29,\n",
       "         14223: 3,\n",
       "         265: 850,\n",
       "         861: 244,\n",
       "         483: 461,\n",
       "         2858: 48,\n",
       "         3044: 44,\n",
       "         2576: 56,\n",
       "         551: 401,\n",
       "         50: 4383,\n",
       "         5702: 18,\n",
       "         1594: 110,\n",
       "         2161: 71,\n",
       "         111: 1753,\n",
       "         304: 735,\n",
       "         44: 5082,\n",
       "         2128: 72,\n",
       "         3632: 35,\n",
       "         62: 3646,\n",
       "         4200: 29,\n",
       "         2535: 58,\n",
       "         160: 1298,\n",
       "         294: 764,\n",
       "         76: 3019,\n",
       "         67: 3374,\n",
       "         1872: 87,\n",
       "         915: 227,\n",
       "         89: 2371,\n",
       "         135: 1519,\n",
       "         312: 715,\n",
       "         117: 1705,\n",
       "         225: 979,\n",
       "         206: 1042,\n",
       "         152: 1363,\n",
       "         372: 629,\n",
       "         680: 325,\n",
       "         37: 6266,\n",
       "         38: 6157,\n",
       "         387: 600,\n",
       "         516: 431,\n",
       "         500: 447,\n",
       "         729: 301,\n",
       "         838: 250,\n",
       "         52: 4244,\n",
       "         846: 247,\n",
       "         458: 487,\n",
       "         757: 286,\n",
       "         1605: 109,\n",
       "         3963: 31,\n",
       "         317: 708,\n",
       "         55: 3838,\n",
       "         528: 420,\n",
       "         2457: 60,\n",
       "         16383: 2,\n",
       "         260: 859,\n",
       "         2735: 51,\n",
       "         681: 325,\n",
       "         1195: 159,\n",
       "         4779: 24,\n",
       "         1204: 158,\n",
       "         28: 8056,\n",
       "         196: 1072,\n",
       "         1735: 97,\n",
       "         523: 424,\n",
       "         145: 1407,\n",
       "         2068: 75,\n",
       "         420: 538,\n",
       "         73: 3061,\n",
       "         418: 541,\n",
       "         525: 421,\n",
       "         8255: 10,\n",
       "         102: 1921,\n",
       "         289: 772,\n",
       "         1474: 121,\n",
       "         93: 2246,\n",
       "         1926: 83,\n",
       "         273: 819,\n",
       "         542: 410,\n",
       "         202: 1049,\n",
       "         876: 237,\n",
       "         331: 684,\n",
       "         208: 1034,\n",
       "         147: 1400,\n",
       "         126: 1644,\n",
       "         28507: 1,\n",
       "         661: 339,\n",
       "         16629: 2,\n",
       "         768: 281,\n",
       "         3186: 42,\n",
       "         77: 3011,\n",
       "         238: 931,\n",
       "         43: 5369,\n",
       "         133: 1566,\n",
       "         91: 2277,\n",
       "         410: 550,\n",
       "         132: 1586,\n",
       "         663: 337,\n",
       "         233: 950,\n",
       "         5900: 18,\n",
       "         6404: 16,\n",
       "         4855: 23,\n",
       "         625: 355,\n",
       "         42: 5379,\n",
       "         438: 516,\n",
       "         80: 2749,\n",
       "         1901: 85,\n",
       "         158: 1318,\n",
       "         20: 10746,\n",
       "         355: 645,\n",
       "         6529: 15,\n",
       "         56: 3810,\n",
       "         17636: 2,\n",
       "         938: 220,\n",
       "         316: 709,\n",
       "         100: 1956,\n",
       "         261: 856,\n",
       "         439: 516,\n",
       "         7675: 11,\n",
       "         1286: 145,\n",
       "         29406: 1,\n",
       "         5073: 22,\n",
       "         4755: 24,\n",
       "         2827: 49,\n",
       "         19901: 2,\n",
       "         12035: 5,\n",
       "         9454: 7,\n",
       "         1452: 124,\n",
       "         986: 207,\n",
       "         148: 1374,\n",
       "         732: 301,\n",
       "         310: 724,\n",
       "         281: 793,\n",
       "         200: 1050,\n",
       "         11347: 5,\n",
       "         19454: 2,\n",
       "         1649: 105,\n",
       "         21032: 1,\n",
       "         903: 230,\n",
       "         963: 214,\n",
       "         675: 326,\n",
       "         21760: 1,\n",
       "         4254: 28,\n",
       "         18761: 2,\n",
       "         187: 1121,\n",
       "         188: 1114,\n",
       "         4163: 29,\n",
       "         3114: 43,\n",
       "         546: 406,\n",
       "         3611: 35,\n",
       "         5630: 19,\n",
       "         502: 445,\n",
       "         11066: 5,\n",
       "         701: 316,\n",
       "         765: 281,\n",
       "         1354: 136,\n",
       "         251: 882,\n",
       "         335: 670,\n",
       "         79: 2883,\n",
       "         4117: 29,\n",
       "         22496: 1,\n",
       "         6845: 14,\n",
       "         894: 232,\n",
       "         2302: 65,\n",
       "         205: 1045,\n",
       "         2430: 61,\n",
       "         362: 640,\n",
       "         524: 424,\n",
       "         78: 2905,\n",
       "         3063: 44,\n",
       "         863: 243,\n",
       "         582: 382,\n",
       "         832: 252,\n",
       "         323: 699,\n",
       "         195: 1081,\n",
       "         18932: 2,\n",
       "         22172: 1,\n",
       "         8947: 8,\n",
       "         1178: 162,\n",
       "         144: 1430,\n",
       "         671: 332,\n",
       "         396: 577,\n",
       "         6379: 16,\n",
       "         175: 1176,\n",
       "         1041: 193,\n",
       "         1379: 134,\n",
       "         735: 300,\n",
       "         788: 271,\n",
       "         2763: 51,\n",
       "         270: 826,\n",
       "         23: 9113,\n",
       "         515: 432,\n",
       "         472: 474,\n",
       "         272: 823,\n",
       "         4242: 28,\n",
       "         284: 783,\n",
       "         750: 291,\n",
       "         6115: 17,\n",
       "         5201: 21,\n",
       "         462: 484,\n",
       "         482: 464,\n",
       "         780: 275,\n",
       "         122: 1690,\n",
       "         1047: 191,\n",
       "         138: 1500,\n",
       "         2885: 48,\n",
       "         2528: 58,\n",
       "         4455: 26,\n",
       "         1069: 186,\n",
       "         207: 1038,\n",
       "         2938: 47,\n",
       "         8418: 9,\n",
       "         726: 302,\n",
       "         3711: 34,\n",
       "         2276: 66,\n",
       "         1402: 131,\n",
       "         1088: 181,\n",
       "         203: 1047,\n",
       "         5473: 20,\n",
       "         258: 861,\n",
       "         2819: 49,\n",
       "         3688: 34,\n",
       "         162: 1267,\n",
       "         1643: 105,\n",
       "         5553: 19,\n",
       "         4328: 27,\n",
       "         5453: 20,\n",
       "         921: 225,\n",
       "         139: 1491,\n",
       "         245: 906,\n",
       "         1271: 147,\n",
       "         1555: 114,\n",
       "         156: 1323,\n",
       "         2933: 47,\n",
       "         7392: 12,\n",
       "         749: 291,\n",
       "         6077: 17,\n",
       "         4313: 27,\n",
       "         875: 238,\n",
       "         314: 714,\n",
       "         2080: 74,\n",
       "         5237: 21,\n",
       "         2132: 72,\n",
       "         5529: 19,\n",
       "         1415: 129,\n",
       "         2178: 70,\n",
       "         296: 760,\n",
       "         5405: 20,\n",
       "         3806: 32,\n",
       "         1044: 192,\n",
       "         3952: 31,\n",
       "         363: 640,\n",
       "         842: 248,\n",
       "         852: 246,\n",
       "         4601: 25,\n",
       "         127: 1629,\n",
       "         591: 379,\n",
       "         262: 856,\n",
       "         5030: 22,\n",
       "         13989: 3,\n",
       "         5182: 21,\n",
       "         7018: 13,\n",
       "         3126: 43,\n",
       "         5569: 19,\n",
       "         5963: 17,\n",
       "         11427: 5,\n",
       "         1480: 120,\n",
       "         141: 1468,\n",
       "         2425: 61,\n",
       "         1038: 194,\n",
       "         851: 246,\n",
       "         311: 718,\n",
       "         512: 435,\n",
       "         519: 430,\n",
       "         2385: 62,\n",
       "         497: 450,\n",
       "         580: 383,\n",
       "         6682: 15,\n",
       "         332: 678,\n",
       "         1161: 167,\n",
       "         798: 265,\n",
       "         121: 1693,\n",
       "         1358: 136,\n",
       "         232: 956,\n",
       "         6360: 16,\n",
       "         829: 253,\n",
       "         6082: 17,\n",
       "         356: 643,\n",
       "         179: 1148,\n",
       "         14601: 3,\n",
       "         1139: 173,\n",
       "         2131: 72,\n",
       "         7590: 12,\n",
       "         1094: 180,\n",
       "         1458: 124,\n",
       "         1843: 89,\n",
       "         6084: 17,\n",
       "         7151: 13,\n",
       "         13785: 4,\n",
       "         7931: 11,\n",
       "         645: 346,\n",
       "         2510: 59,\n",
       "         1841: 89,\n",
       "         371: 630,\n",
       "         8891: 8,\n",
       "         297: 759,\n",
       "         900: 231,\n",
       "         3130: 42,\n",
       "         1064: 187,\n",
       "         988: 207,\n",
       "         679: 326,\n",
       "         278: 809,\n",
       "         65: 3440,\n",
       "         2753: 51,\n",
       "         401: 569,\n",
       "         5722: 18,\n",
       "         4821: 24,\n",
       "         201: 1050,\n",
       "         12192: 4,\n",
       "         1384: 132,\n",
       "         2732: 52,\n",
       "         699: 316,\n",
       "         4662: 25,\n",
       "         2307: 65,\n",
       "         9116: 8,\n",
       "         17694: 2,\n",
       "         652: 343,\n",
       "         6989: 13,\n",
       "         1109: 178,\n",
       "         155: 1328,\n",
       "         4957: 22,\n",
       "         1714: 99,\n",
       "         1895: 86,\n",
       "         1545: 115,\n",
       "         1485: 120,\n",
       "         778: 277,\n",
       "         354: 645,\n",
       "         1200: 158,\n",
       "         215: 1017,\n",
       "         181: 1140,\n",
       "         907: 229,\n",
       "         106: 1859,\n",
       "         1669: 104,\n",
       "         464: 482,\n",
       "         359: 643,\n",
       "         222: 990,\n",
       "         480: 464,\n",
       "         4216: 28,\n",
       "         3451: 37,\n",
       "         895: 232,\n",
       "         567: 392,\n",
       "         985: 207,\n",
       "         1434: 127,\n",
       "         18534: 2,\n",
       "         15146: 3,\n",
       "         16226: 3,\n",
       "         824: 256,\n",
       "         669: 333,\n",
       "         670: 333,\n",
       "         114: 1737,\n",
       "         1533: 116,\n",
       "         1365: 135,\n",
       "         1056: 188,\n",
       "         569: 391,\n",
       "         2594: 56,\n",
       "         250: 884,\n",
       "         1393: 131,\n",
       "         2291: 65,\n",
       "         12908: 4,\n",
       "         870: 240,\n",
       "         13684: 4,\n",
       "         19776: 2,\n",
       "         1022: 196,\n",
       "         5331: 20,\n",
       "         3080: 44,\n",
       "         422: 535,\n",
       "         337: 666,\n",
       "         1348: 138,\n",
       "         3207: 41,\n",
       "         15548: 3,\n",
       "         15395: 3,\n",
       "         8487: 9,\n",
       "         13131: 4,\n",
       "         2743: 51,\n",
       "         1679: 103,\n",
       "         1657: 105,\n",
       "         691: 321,\n",
       "         24421: 1,\n",
       "         249: 892,\n",
       "         5901: 18,\n",
       "         979: 208,\n",
       "         1304: 143,\n",
       "         4958: 22,\n",
       "         1449: 125,\n",
       "         4492: 26,\n",
       "         529: 419,\n",
       "         5356: 20,\n",
       "         1601: 109,\n",
       "         1446: 126,\n",
       "         1008: 201,\n",
       "         4040: 30,\n",
       "         104: 1883,\n",
       "         7775: 11,\n",
       "         257: 862,\n",
       "         217: 1001,\n",
       "         553: 400,\n",
       "         2781: 50,\n",
       "         5821: 18,\n",
       "         110: 1758,\n",
       "         8016: 10,\n",
       "         4185: 29,\n",
       "         777: 277,\n",
       "         4034: 30,\n",
       "         1215: 156,\n",
       "         193: 1093,\n",
       "         9162: 8,\n",
       "         58: 3710,\n",
       "         27814: 1,\n",
       "         1614: 108,\n",
       "         3326: 39,\n",
       "         1324: 141,\n",
       "         6046: 17,\n",
       "         709: 313,\n",
       "         16640: 2,\n",
       "         8808: 8,\n",
       "         4374: 27,\n",
       "         4932: 23,\n",
       "         4766: 24,\n",
       "         2005: 79,\n",
       "         9694: 7,\n",
       "         3533: 36,\n",
       "         3388: 38,\n",
       "         3343: 39,\n",
       "         27085: 1,\n",
       "         1833: 89,\n",
       "         321: 703,\n",
       "         9451: 7,\n",
       "         19750: 2,\n",
       "         1745: 96,\n",
       "         1965: 81,\n",
       "         2662: 54,\n",
       "         1262: 149,\n",
       "         2019: 78,\n",
       "         29713: 1,\n",
       "         3467: 37,\n",
       "         3860: 32,\n",
       "         599: 376,\n",
       "         182: 1137,\n",
       "         3138: 42,\n",
       "         1046: 191,\n",
       "         479: 466,\n",
       "         236: 945,\n",
       "         564: 395,\n",
       "         1997: 79,\n",
       "         1209: 157,\n",
       "         736: 299,\n",
       "         2148: 71,\n",
       "         9184: 8,\n",
       "         12187: 4,\n",
       "         308: 730,\n",
       "         1607: 109,\n",
       "         1082: 182,\n",
       "         328: 687,\n",
       "         1226: 155,\n",
       "         210: 1027,\n",
       "         961: 214,\n",
       "         4985: 22,\n",
       "         2023: 77,\n",
       "         1016: 199,\n",
       "         448: 506,\n",
       "         724: 305,\n",
       "         303: 736,\n",
       "         909: 229,\n",
       "         223: 989,\n",
       "         2040: 76,\n",
       "         3016: 45,\n",
       "         11303: 5,\n",
       "         287: 776,\n",
       "         8269: 10,\n",
       "         3227: 41,\n",
       "         198: 1058,\n",
       "         3235: 41,\n",
       "         1898: 85,\n",
       "         1024: 196,\n",
       "         1974: 80,\n",
       "         12497: 4,\n",
       "         11381: 5,\n",
       "         2563: 57,\n",
       "         478: 467,\n",
       "         9633: 7,\n",
       "         97: 2077,\n",
       "         305: 734,\n",
       "         1066: 186,\n",
       "         585: 380,\n",
       "         177: 1166,\n",
       "         6794: 14,\n",
       "         4759: 24,\n",
       "         253: 877,\n",
       "         228: 964,\n",
       "         1457: 124,\n",
       "         1927: 83,\n",
       "         112: 1753,\n",
       "         1349: 138,\n",
       "         616: 363,\n",
       "         1873: 87,\n",
       "         214: 1022,\n",
       "         212: 1025,\n",
       "         75: 3040,\n",
       "         1572: 112,\n",
       "         2505: 59,\n",
       "         190: 1100,\n",
       "         447: 507,\n",
       "         508: 437,\n",
       "         1171: 165,\n",
       "         358: 643,\n",
       "         1414: 129,\n",
       "         654: 343,\n",
       "         1218: 156,\n",
       "         967: 212,\n",
       "         457: 489,\n",
       "         1136: 173,\n",
       "         1622: 107,\n",
       "         1007: 202,\n",
       "         1237: 153,\n",
       "         3447: 37,\n",
       "         9263: 8,\n",
       "         657: 342,\n",
       "         820: 257,\n",
       "         1673: 103,\n",
       "         6851: 14,\n",
       "         1521: 117,\n",
       "         95: 2162,\n",
       "         23859: 1,\n",
       "         711: 312,\n",
       "         444: 508,\n",
       "         744: 294,\n",
       "         1515: 117,\n",
       "         2009: 78,\n",
       "         6847: 14,\n",
       "         3850: 32,\n",
       "         378: 621,\n",
       "         2825: 49,\n",
       "         958: 215,\n",
       "         1207: 157,\n",
       "         129: 1617,\n",
       "         485: 460,\n",
       "         154: 1331,\n",
       "         3030: 45,\n",
       "         992: 205,\n",
       "         1242: 152,\n",
       "         816: 258,\n",
       "         2985: 45,\n",
       "         571: 388,\n",
       "         520: 427,\n",
       "         725: 304,\n",
       "         115: 1737,\n",
       "         14289: 3,\n",
       "         10148: 6,\n",
       "         6768: 14,\n",
       "         11543: 5,\n",
       "         1524: 117,\n",
       "         7321: 12,\n",
       "         608: 369,\n",
       "         1176: 162,\n",
       "         3596: 35,\n",
       "         173: 1182,\n",
       "         563: 395,\n",
       "         488: 458,\n",
       "         4533: 26,\n",
       "         1413: 129,\n",
       "         1807: 91,\n",
       "         2666: 53,\n",
       "         408: 552,\n",
       "         164: 1243,\n",
       "         586: 380,\n",
       "         2335: 63,\n",
       "         1111: 178,\n",
       "         1666: 104,\n",
       "         1322: 141,\n",
       "         1290: 145,\n",
       "         4756: 24,\n",
       "         404: 563,\n",
       "         908: 229,\n",
       "         740: 295,\n",
       "         621: 359,\n",
       "         1316: 142,\n",
       "         15632: 3,\n",
       "         3815: 32,\n",
       "         650: 343,\n",
       "         1825: 90,\n",
       "         4234: 28,\n",
       "         673: 330,\n",
       "         3145: 42,\n",
       "         192: 1095,\n",
       "         510: 436,\n",
       "         604: 371,\n",
       "         2147: 71,\n",
       "         506: 440,\n",
       "         443: 508,\n",
       "         469: 476,\n",
       "         11887: 5,\n",
       "         2564: 57,\n",
       "         125: 1665,\n",
       "         454: 493,\n",
       "         19191: 2,\n",
       "         1152: 169,\n",
       "         96: 2097,\n",
       "         25255: 1,\n",
       "         6087: 17,\n",
       "         847: 247,\n",
       "         3530: 36,\n",
       "         3427: 37,\n",
       "         2852: 49,\n",
       "         1107: 178,\n",
       "         1742: 96,\n",
       "         81: 2664,\n",
       "         5207: 21,\n",
       "         2542: 58,\n",
       "         1450: 125,\n",
       "         116: 1706,\n",
       "         1498: 119,\n",
       "         2256: 66,\n",
       "         1467: 122,\n",
       "         1476: 121,\n",
       "         5163: 21,\n",
       "         1435: 127,\n",
       "         395: 578,\n",
       "         4568: 25,\n",
       "         4214: 28,\n",
       "         3031: 44,\n",
       "         6719: 14,\n",
       "         4341: 27,\n",
       "         1009: 200,\n",
       "         716: 307,\n",
       "         1578: 112,\n",
       "         4616: 25,\n",
       "         738: 297,\n",
       "         5060: 22,\n",
       "         3857: 32,\n",
       "         1423: 128,\n",
       "         507: 439,\n",
       "         384: 605,\n",
       "         1281: 146,\n",
       "         615: 363,\n",
       "         1540: 115,\n",
       "         1026: 196,\n",
       "         899: 231,\n",
       "         715: 307,\n",
       "         602: 373,\n",
       "         290: 769,\n",
       "         349: 653,\n",
       "         737: 297,\n",
       "         614: 365,\n",
       "         850: 246,\n",
       "         452: 496,\n",
       "         552: 401,\n",
       "         170: 1196,\n",
       "         5668: 19,\n",
       "         2582: 56,\n",
       "         761: 283,\n",
       "         266: 842,\n",
       "         3244: 40,\n",
       "         941: 219,\n",
       "         242: 920,\n",
       "         1225: 155,\n",
       "         477: 467,\n",
       "         2575: 56,\n",
       "         24857: 1,\n",
       "         12612: 4,\n",
       "         7005: 13,\n",
       "         2673: 53,\n",
       "         4081: 30,\n",
       "         4131: 29,\n",
       "         1360: 135,\n",
       "         884: 235,\n",
       "         8520: 9,\n",
       "         13719: 4,\n",
       "         12262: 4,\n",
       "         2888: 48,\n",
       "         339: 665,\n",
       "         609: 368,\n",
       "         812: 259,\n",
       "         13737: 4,\n",
       "         419: 539,\n",
       "         434: 520,\n",
       "         277: 809,\n",
       "         295: 761,\n",
       "         92: 2248,\n",
       "         7315: 12,\n",
       "         3748: 33,\n",
       "         280: 798,\n",
       "         209: 1033,\n",
       "         2142: 72,\n",
       "         12833: 4,\n",
       "         390: 589,\n",
       "         473: 474,\n",
       "         248: 901,\n",
       "         1362: 135,\n",
       "         20092: 2,\n",
       "         747: 291,\n",
       "         218: 998,\n",
       "         5589: 19,\n",
       "         1475: 121,\n",
       "         2669: 53,\n",
       "         476: 469,\n",
       "         800: 264,\n",
       "         3522: 36,\n",
       "         6930: 14,\n",
       "         4296: 28,\n",
       "         3367: 38,\n",
       "         487: 459,\n",
       "         594: 378,\n",
       "         6929: 14,\n",
       "         14191: 3,\n",
       "         810: 260,\n",
       "         7949: 11,\n",
       "         1061: 187,\n",
       "         1158: 168,\n",
       "         3505: 36,\n",
       "         2918: 47,\n",
       "         3026: 45,\n",
       "         3218: 41,\n",
       "         559: 397,\n",
       "         2014: 78,\n",
       "         1129: 175,\n",
       "         7346: 12,\n",
       "         853: 245,\n",
       "         15507: 3,\n",
       "         581: 382,\n",
       "         103: 1911,\n",
       "         10487: 6,\n",
       "         1208: 157,\n",
       "         7764: 11,\n",
       "         719: 307,\n",
       "         13098: 4,\n",
       "         6696: 14,\n",
       "         166: 1226,\n",
       "         730: 301,\n",
       "         15939: 3,\n",
       "         6122: 17,\n",
       "         3272: 40,\n",
       "         94: 2181,\n",
       "         1159: 167,\n",
       "         793: 267,\n",
       "         4252: 28,\n",
       "         176: 1172,\n",
       "         1112: 177,\n",
       "         791: 267,\n",
       "         3520: 36,\n",
       "         2248: 66,\n",
       "         1327: 141,\n",
       "         8776: 9,\n",
       "         605: 370,\n",
       "         172: 1182,\n",
       "         1202: 158,\n",
       "         897: 232,\n",
       "         1516: 117,\n",
       "         1059: 188,\n",
       "         157: 1319,\n",
       "         ...})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_words = []\n",
    "# for x in x_train:\n",
    "#     train_words.extend(x)\n",
    "# test_words = []\n",
    "# for x in x_test:\n",
    "#     test_words.extend(x)\n",
    "# all_words = train_words\n",
    "# all_words.extend(test_words)\n",
    "# all_statistcs = Counter(all_words)\n",
    "# all_statistcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24452</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18567</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27222</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26864</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24794</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30980 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "1      11228\n",
       "53      4213\n",
       "352      647\n",
       "26      8451\n",
       "14     15015\n",
       "...      ...\n",
       "24452      1\n",
       "18567      2\n",
       "27222      1\n",
       "26864      1\n",
       "24794      1\n",
       "\n",
       "[30980 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame.from_dict(dict(all_statistcs), orient = 'index')\n",
    "# df.to_excel('./results/words_dist2.xlsx', header=False, index=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8260, 360) (2066, 360)\n"
     ]
    }
   ],
   "source": [
    "trainX = tf.keras.preprocessing.sequence.pad_sequences(x_train,maxlen=max_length,padding='post',value=0)\n",
    "testX = tf.keras.preprocessing.sequence.pad_sequences(x_test,maxlen=max_length,padding='post',value=0)\n",
    "print(trainX.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "# do = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph execution\n",
    "### Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_id = Input(shape=(max_length,), dtype='int32', name='int_ids') # 輸入的api funvtion name ID\n",
    "int_ids = Masking(mask_value=0)(int_id)\n",
    "sent_emb = Embedding(max_words, hidden_dim,input_length=max_length\n",
    "                    ,trainable=True,name='glove_emb')(int_ids) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = GRU(int(hidden_dim/2),return_sequences=True,return_state=False,name='common_extract'\n",
    "                      ,trainable=True)(sent_emb)\n",
    "rnn = BatchNormalization(name='bn')(rnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = TimeDistributed(Dense(1,activation='sigmoid',\n",
    "                             name='filter_out'),name='TD2')(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = Multiply()([fil,sent_emb])\n",
    "clf = LSTM(int(hidden_dim/2),dropout=do,recurrent_dropout=do,name='lstm')(mul)\n",
    "clf = BatchNormalization(name='bn3')(clf)\n",
    "clf = Dense(max(y_train)+1,activation='softmax',name='clf')(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "int_ids (InputLayer)            [(None, 358)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 358)          0           int_ids[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "glove_emb (Embedding)           (None, 358, 128)     1280000     masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "common_extract (GRU)            (None, 358, 64)      37248       glove_emb[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 358, 64)      256         common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "TD2 (TimeDistributed)           (None, 358, 1)       65          bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 358, 128)     0           TD2[0][0]                        \n",
      "                                                                 glove_emb[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           49408       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 64)           256         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "clf (Dense)                     (None, 46)           2990        bn3[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 1,370,223\n",
      "Trainable params: 1,369,967\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=int_id, outputs = clf)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-189e30c4af05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     return K.sum(layer.output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# kk = tf.keras.backend.ea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TD2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       self._track_trackable(\n\u001b[1;32m    294\u001b[0m           self.optimizer, name='optimizer', overwrite=True)\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weight_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \"\"\"\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_bool_casting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m       \u001b[0;31m# Default: V1-style Graph execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"using a `tf.Tensor` as a Python `bool`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_in_graph_mode\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    521\u001b[0m     raise errors.OperatorNotAllowedInGraphError(\n\u001b[1;32m    522\u001b[0m         \u001b[0;34m\"{} is not allowed in Graph execution. Use Eager execution or decorate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \" this function with @tf.function.\".format(task))\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
     ]
    }
   ],
   "source": [
    "# loss\n",
    "import keras.backend as K\n",
    "def custom_objective(layer):\n",
    "    return K.sum(layer.output)\n",
    "#     return K.sum(layer.output)\n",
    "# kk = tf.keras.backend.ea\n",
    "model.compile(loss=custom_objective(model.get_layer(name='TD2')),optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole model\n",
    "do = 0\n",
    "init = tensorflow.keras.initializers.Ones()\n",
    "class base_model(Model):\n",
    "    def __init__(self):\n",
    "        super(base_model, self).__init__()\n",
    "        self.mask = Masking(mask_value=0)\n",
    "        self.emb = Embedding(max_words, hidden_dim,input_length=max_length\n",
    "                    ,trainable=True,name='glove_emb')\n",
    "        self.rnn1 = GRU(int(hidden_dim/2),return_sequences=True,return_state=False,name='common_extract'\n",
    "                      ,trainable=True)\n",
    "        self.bn1 = BatchNormalization(name='bn1')\n",
    "        self.fil = Dense(1,activation='hard_sigmoid',kernel_initializer=init,bias_initializer=init,name='filter_out')\n",
    "        #self.fil = TimeDistributed(Dense(1,activation='sigmoid', name='filter_out'),name='TD2')\n",
    "        self.mul = Multiply()\n",
    "        self.rnn2 = Bidirectional(GRU(int(hidden_dim/2),dropout=do,recurrent_dropout=do,name='lstm'))\n",
    "        self.rnn3 = LSTM(int(hidden_dim/2))\n",
    "        self.bn2 = BatchNormalization(name='bn2')\n",
    "        self.out = Dense(max(y_train)+1,activation='softmax',name='clf')\n",
    "    def transform(self,x):\n",
    "        return tf.math.round(x)\n",
    "    def call(self,x):\n",
    "        x = self.mask(x)\n",
    "        x1 = self.emb(x)\n",
    "        x = self.rnn1(x1)\n",
    "        x = self.bn1(x)\n",
    "        y = self.fil(x)\n",
    "        y1 = self.transform(y)\n",
    "        x2 = self.mul([y1,x1])\n",
    "        x = self.rnn2(x2) #x\n",
    "        x = self.bn2(x)\n",
    "        y2 = self.out(x)\n",
    "        return y,y1,y2\n",
    "        #return y,y1,y2,x2\n",
    "        \n",
    "model = base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).emb.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).fil.layer.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).fil.layer.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "# partial1 model\n",
    "init_w = tensorflow.keras.initializers.Constant(value=1.1) #portyion=0.6, w=0.9, b = 0.8-0.85 (0.83從0開始)\n",
    "init_b = tensorflow.keras.initializers.Constant(value=1.1) #w=1 ; b=0.499, portion=1\n",
    "def onezero(x):\n",
    "    portion = 0.6#0.6#0.6 #0.6~1\n",
    "    z = tf.where(x>=1.0, x - x + 1.0, x)\n",
    "    y = tf.where(z<=0.0, z - z + 0.0, portion*z)\n",
    "    return y\n",
    "\n",
    "class base_model_1(Model):\n",
    "    def __init__(self):\n",
    "        super(base_model_1, self).__init__()\n",
    "        self.mask = Masking(mask_value=0)\n",
    "        self.emb = Embedding(max_words, hidden_dim,input_length=max_length\n",
    "                    ,trainable=True,name='glove_emb')\n",
    "        #self.rnn1 = GRU(int(hidden_dim/4),return_sequences=True,return_state=False,name='common_extract'\n",
    "                      #,trainable=True)\n",
    "        self.att = Attention(name='selfatt')\n",
    "        #self.bn1 = BatchNormalization(name='bn1')\n",
    "        #self.fil = Dense(1,activation=onezero,name='filter_out')\n",
    "        self.fil = TimeDistributed(Dense(1,activation=onezero,kernel_initializer=init_w,bias_initializer=init_b, name='filter_out'),name='TD2') #relu/linear/step function\n",
    "\n",
    "    def call(self,x):\n",
    "        x = self.mask(x)\n",
    "        x1 = self.emb(x)\n",
    "        x = self.att([x1,x1])\n",
    "        #x = self.rnn1(x1)\n",
    "        #x = self.bn1(x)\n",
    "        y = self.fil(x)\n",
    "        return x1,y\n",
    "\n",
    "model1 = base_model_1()\n",
    "#phase2\n",
    "# model3 = load_model(saveP)\n",
    "\n",
    "model3 = base_model_1()\n",
    "model3.load_weights('./model/2019110501/model1')#,by_name=True)\n",
    "model1.emb.set_weights(model3.emb.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial2 model\n",
    "class base_model_2(Model):\n",
    "    def __init__(self):\n",
    "        super(base_model_2, self).__init__()\n",
    "        self.mul = Multiply()\n",
    "        self.rnn2 = Bidirectional(GRU(int(hidden_dim/2),dropout=do,recurrent_dropout=do,name='lstm'))\n",
    "        self.rnn3 = GRU(int(hidden_dim/2))\n",
    "        self.bn2 = BatchNormalization(name='bn2')\n",
    "        self.out = Dense(max(y_train)+1,activation='softmax',name='clf')\n",
    "\n",
    "    def call(self,x1,y1):\n",
    "        x2 = self.mul([y1,x1])\n",
    "        x = self.rnn3(x2) #x2 #y1=weight|binary\n",
    "        x = self.bn2(x)\n",
    "        y2 = self.out(x)\n",
    "        return y2\n",
    "    \n",
    "model2 = base_model_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5770753, shape=(32, 4), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# TEST\n",
    "x = tf.random.uniform((32, 6))\n",
    "out1,out2 = model1(x)\n",
    "out2 = tf.squeeze(out2,axis=-1)\n",
    "# out2 = out2.astype('float32')\n",
    "# out2 = tf.dtypes.cast(out2, tf.float8)\n",
    "# print(out2.shape)\n",
    "yy = tf.matmul(out2,kk)\n",
    "print(yy[0].shape)\n",
    "tf.where(yy[0]==0,1,0)\n",
    "\n",
    "gg = tf.range(-5,5)\n",
    "gg = tf.expand_dims(gg,axis=0)\n",
    "gg = tf.keras.backend.repeat_elements(gg,rep=32,axis=0)\n",
    "tf.where(gg==1,gg,0)\n",
    "\n",
    "kk = tf.Variable(np.array([[1.0,1.0,1.0,0.0,0.0,0.0],[0.0,1.0,1.0,1.0,0.0,0.0],[0.0,0.0,1.0,1.0,1.0,0.0],\n",
    "                           [0.0,0.0,0.0,1.0,1.0,1.0]]).T,dtype='float32')\n",
    "kk = tf.expand_dims(kk,axis=0)\n",
    "kk = tf.keras.backend.repeat_elements(kk,rep=1,axis=0)\n",
    "kk.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 #,reshuffle_each_iteration=True\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((trainX,y_train)).shuffle(trainX.shape[0]).batch(batch_size)\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((testX,y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9154313, shape=(1, 360, 359), dtype=float32, numpy=\n",
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_num = 2 #連續幾個才叫做連續，要改modify_idx看有幾個\n",
    "\n",
    "arr_len = max_length - seq_num + 1\n",
    "seq_arr = []\n",
    "for i in range(arr_len):\n",
    "    ori_np = np.array([0]*max_length)\n",
    "    modify_idx = [i,i+1] #要跟著seq_num改\n",
    "    ori_np[modify_idx]=1\n",
    "    seq_arr.append(ori_np)\n",
    "seq_arr = np.array(seq_arr)\n",
    "seq_mask = tf.Variable(seq_arr.T,dtype='float32')\n",
    "seq_mask = tf.expand_dims(seq_mask,axis=0)\n",
    "seq_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_object1(predictions): #filter loss\n",
    "    mask = tf.math.logical_not(tf.math.equal(predictions, 0))\n",
    "    loss_ = tf.reduce_mean(predictions)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "def one_percentage(predictions): #1 num\n",
    "    mask = tf.math.logical_not(tf.math.equal(predictions, 0))\n",
    "    loss_ = tf.reduce_mean(predictions)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "def seq_loss(predictions):\n",
    "    mask = tf.math.logical_not(tf.math.equal(predictions, 0))\n",
    "    predictions = tf.squeeze(predictions,axis=-1)\n",
    "    results = tf.matmul(predictions,seq_mask)\n",
    "    results = tf.where(results==seq_num,1.0,0.0)\n",
    "    loss_ = tf.reduce_mean(results)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "loss_object2 = tf.keras.losses.SparseCategoricalCrossentropy() #clf loss\n",
    "\n",
    "optimizer1 = tf.keras.optimizers.Nadam()\n",
    "optimizer2 = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss') #total_loss\n",
    "train_accloss = tf.keras.metrics.Mean(name='train_accloss')#loss_acc\n",
    "train_filloss = tf.keras.metrics.Mean(name='train_filloss') #loss_filter\n",
    "train_seqloss = tf.keras.metrics.Mean(name='train_seqloss') #loss_seq\n",
    "train_ones = tf.keras.metrics.Mean(name='train_ones') #ones_num\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy') #acc_rate\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss') #total_loss\n",
    "test_accloss = tf.keras.metrics.Mean(name='test_accloss')#loss_acc\n",
    "test_filloss = tf.keras.metrics.Mean(name='test_filloss') #loss_filter\n",
    "test_seqloss = tf.keras.metrics.Mean(name='test_seqloss')\n",
    "test_ones = tf.keras.metrics.Mean(name='test_ones') #ones_num\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate partial model\n",
    "alpha = 1.0 #pahse1: -0.1 / 0.0 ; phase2: 0.01~0.05~0.1 有1-就是希望1越多，沒1-就是希望0越多1越少\n",
    "beta = 1.0 #clf loss 越大越要求分好\n",
    "gamma = 0.0 #seqloss 越大越要求連續\n",
    "#-0.001 / 1.0 / 1.0\n",
    "\n",
    "@tf.function\n",
    "def train_step(x,yc):\n",
    "    with tf.GradientTape(persistent=False) as tape:\n",
    "        emb, pred_imp = model1(x)\n",
    "        #loss1 = alpha*loss_object1(pred_imp) #phase1\n",
    "        #pred_imp2 = tf.math.round(pred_imp)\n",
    "        #pred_imp3 = tf.clip_by_value(pred_imp,clip_value_max=1,clip_value_min=0)\n",
    "        pred_imp2 = tf.math.round(pred_imp)\n",
    "        loss1 = loss_object1(pred_imp) #有1-就是希望1越多，沒1-就是希望0越多1越少 #pahse2:alpha*loss_object1(pred_imp) ; phase1: alpha*(1-loss_object1(pred_imp))\n",
    "        pred_cat = model2(emb,pred_imp2) #pahse1: pred_imp; phase2; pred_imp2\n",
    "        loss2 = loss_object2(yc, pred_cat)\n",
    "        loss3 = 1-seq_loss(pred_imp2)\n",
    "        loss = alpha*loss1 + beta*loss2 + gamma*loss3\n",
    "    trainable_variable = model1.trainable_variables\n",
    "    trainable_variable.extend(model2.trainable_variables)\n",
    "    gradients = tape.gradient(loss,trainable_variable)\n",
    "    optimizer1.apply_gradients(zip(gradients,trainable_variable))\n",
    "    \n",
    "    train_loss(loss) #total_loss\n",
    "    train_filloss(loss1)\n",
    "    train_accloss(loss2)\n",
    "    train_seqloss(loss3) #loss_seq\n",
    "    train_accuracy(yc, pred_cat) #acc_rate\n",
    "    ones = one_percentage(pred_imp2) #pred_imp2\n",
    "    train_ones(ones) #ones_num\n",
    "    \n",
    "    \n",
    "@tf.function\n",
    "def test_step(x,yc):\n",
    "    emb, pred_imp = model1(x)\n",
    "    #loss1 = alpha*loss_object1(pred_imp) #phase1\n",
    "    #pred_imp2 = tf.math.round(pred_imp)\n",
    "    #pred_imp3 = tf.clip_by_value(pred_imp,clip_value_max=1,clip_value_min=0)\n",
    "    pred_imp2 = tf.math.round(pred_imp)\n",
    "    loss1 = loss_object1(pred_imp) #phase2\n",
    "    pred_cat = model2(emb,pred_imp2) #phase1: pred_imp ; phase2:pred_imp2\n",
    "    loss2 = loss_object2(yc, pred_cat)\n",
    "    loss3 = 1-seq_loss(pred_imp2)\n",
    "    #t_loss = loss1 + loss2\n",
    "    t_loss = alpha*loss1 + beta*loss2 + gamma*loss3\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_filloss(loss1)\n",
    "    test_accloss(loss2)\n",
    "    test_seqloss(loss3)\n",
    "    test_accuracy(yc, pred_cat)\n",
    "    t_ones = one_percentage(pred_imp2) #pred_imp2\n",
    "    test_ones(t_ones)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#AIO\n",
    "alpha = 0.1\n",
    "beta = 1\n",
    "gamma = 0\n",
    "@tf.function\n",
    "def train_step(x,yc):\n",
    "    with tf.GradientTape(persistent=True) as tape: #persistent=True\n",
    "        pred_imp,pred_round , pred_cat = model(x)\n",
    "#         pred_cat = model(x)\n",
    "#         loss = alpha*loss_object1(pred_imp) + loss_object2(yc,pred_cat)\n",
    "        loss1 = alpha*loss_object1(pred_imp)\n",
    "        loss2 = beta*loss_object2(yc,pred_cat)\n",
    "        loss = loss_object2(yc,pred_cat)\n",
    "#     gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    grad1 = tape.gradient(loss1, model.trainable_variables)\n",
    "    grad2 = tape.gradient(loss2, model.trainable_variables)\n",
    "#     optimizer1.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    optimizer1.apply_gradients(zip(grad1, model.trainable_variables))\n",
    "    optimizer2.apply_gradients(zip(grad2, model.trainable_variables))\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         pred_imp , pred_cat = model(x)\n",
    "#         loss2 = loss_object2(yc,pred_cat)\n",
    "#         loss = alpha*loss_object1(pred_imp) + loss_object2(yc,pred_cat)\n",
    "#     grad2 = tape.gradient(loss2, model.trainable_variables)\n",
    "#     optimizer2.apply_gradients(zip(grad2, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(yc, pred_cat)\n",
    "    ones = one_percentage(pred_round)\n",
    "    train_ones(ones)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(x,yc):\n",
    "    pred_imp,pred_round, pred_cat = model(x)\n",
    "#     pred_cat = model(x)\n",
    "    t_loss = alpha*loss_object1(pred_imp) + loss_object2(yc,pred_cat) \n",
    "#     t_loss = loss_object2(yc,pred_cat)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(yc, pred_cat)\n",
    "    t_ones = one_percentage(pred_round)\n",
    "    test_ones(t_ones)\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Total Loss: 3.270426034927368, Clf Loss: 2.6704258918762207, Filter Loss: 0.5999999642372131, Seq Loss: 0.0, Accuracy Rate: 37.08%, Ones Portion: 1.0,             Test_Total_Loss: 2.968629837036133, Test_Clf_Loss: 2.3686294555664062, Test_Filter_Loss: 0.6000000238418579, TEST_Seq_Loss: 0.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 1.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 2, Total Loss: 2.7061991691589355, Clf Loss: 2.3383965492248535, Filter Loss: 0.3678028881549835, Seq Loss: 0.3978385627269745, Accuracy Rate: 37.72%, Ones Portion: 0.6021719574928284,             Test_Total_Loss: 2.365687370300293, Test_Clf_Loss: 2.365687370300293, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 3, Total Loss: 2.3428328037261963, Clf Loss: 2.3428328037261963, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3642117977142334, Test_Clf_Loss: 2.3642117977142334, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 4, Total Loss: 2.3429784774780273, Clf Loss: 2.3429784774780273, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.363020658493042, Test_Clf_Loss: 2.363020658493042, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 5, Total Loss: 2.3445019721984863, Clf Loss: 2.3445019721984863, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3613290786743164, Test_Clf_Loss: 2.3613290786743164, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 6, Total Loss: 2.3426647186279297, Clf Loss: 2.3426647186279297, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3655431270599365, Test_Clf_Loss: 2.3655431270599365, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 7, Total Loss: 2.3413541316986084, Clf Loss: 2.3413541316986084, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.362149477005005, Test_Clf_Loss: 2.362149477005005, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 8, Total Loss: 2.3429408073425293, Clf Loss: 2.3429408073425293, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3612146377563477, Test_Clf_Loss: 2.3612146377563477, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 9, Total Loss: 2.3438100814819336, Clf Loss: 2.3438100814819336, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3610007762908936, Test_Clf_Loss: 2.3610007762908936, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 10, Total Loss: 2.34261155128479, Clf Loss: 2.34261155128479, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3623852729797363, Test_Clf_Loss: 2.3623852729797363, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 11, Total Loss: 2.3403749465942383, Clf Loss: 2.3403749465942383, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3673765659332275, Test_Clf_Loss: 2.3673765659332275, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 12, Total Loss: 2.3411483764648438, Clf Loss: 2.3411483764648438, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3636679649353027, Test_Clf_Loss: 2.3636679649353027, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 13, Total Loss: 2.3442506790161133, Clf Loss: 2.3442506790161133, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3638522624969482, Test_Clf_Loss: 2.3638522624969482, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 14, Total Loss: 2.3430094718933105, Clf Loss: 2.3430094718933105, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3597006797790527, Test_Clf_Loss: 2.3597006797790527, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 15, Total Loss: 2.3379831314086914, Clf Loss: 2.3379831314086914, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3676371574401855, Test_Clf_Loss: 2.3676371574401855, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 16, Total Loss: 2.3429031372070312, Clf Loss: 2.3429031372070312, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3617188930511475, Test_Clf_Loss: 2.3617188930511475, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 17, Total Loss: 2.3427724838256836, Clf Loss: 2.3427724838256836, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3636465072631836, Test_Clf_Loss: 2.3636465072631836, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 18, Total Loss: 2.3446273803710938, Clf Loss: 2.3446273803710938, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361790895462036, Test_Clf_Loss: 2.361790895462036, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 19, Total Loss: 2.340769052505493, Clf Loss: 2.340769052505493, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3610854148864746, Test_Clf_Loss: 2.3610854148864746, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 20, Total Loss: 2.3425207138061523, Clf Loss: 2.3425207138061523, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.36234712600708, Test_Clf_Loss: 2.36234712600708, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 21, Total Loss: 2.343599319458008, Clf Loss: 2.343599319458008, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3614468574523926, Test_Clf_Loss: 2.3614468574523926, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 22, Total Loss: 2.3422060012817383, Clf Loss: 2.3422060012817383, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.365314245223999, Test_Clf_Loss: 2.365314245223999, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Total Loss: 2.3405518531799316, Clf Loss: 2.3405518531799316, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.363615036010742, Test_Clf_Loss: 2.363615036010742, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 24, Total Loss: 2.3417751789093018, Clf Loss: 2.3417751789093018, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3637077808380127, Test_Clf_Loss: 2.3637077808380127, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 25, Total Loss: 2.3411200046539307, Clf Loss: 2.3411200046539307, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3646907806396484, Test_Clf_Loss: 2.3646907806396484, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 26, Total Loss: 2.3404252529144287, Clf Loss: 2.3404252529144287, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.366021156311035, Test_Clf_Loss: 2.366021156311035, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 27, Total Loss: 2.3407626152038574, Clf Loss: 2.3407626152038574, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.363455295562744, Test_Clf_Loss: 2.363455295562744, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 28, Total Loss: 2.341700792312622, Clf Loss: 2.341700792312622, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3636369705200195, Test_Clf_Loss: 2.3636369705200195, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 29, Total Loss: 2.3398828506469727, Clf Loss: 2.3398828506469727, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.362596273422241, Test_Clf_Loss: 2.362596273422241, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 30, Total Loss: 2.3416078090667725, Clf Loss: 2.3416078090667725, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3599250316619873, Test_Clf_Loss: 2.3599250316619873, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 31, Total Loss: 2.342960834503174, Clf Loss: 2.342960834503174, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.364849328994751, Test_Clf_Loss: 2.364849328994751, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 32, Total Loss: 2.3436877727508545, Clf Loss: 2.3436877727508545, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.362534999847412, Test_Clf_Loss: 2.362534999847412, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 33, Total Loss: 2.344712972640991, Clf Loss: 2.344712972640991, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3594753742218018, Test_Clf_Loss: 2.3594753742218018, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 34, Total Loss: 2.3421154022216797, Clf Loss: 2.3421154022216797, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3619585037231445, Test_Clf_Loss: 2.3619585037231445, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 35, Total Loss: 2.340625524520874, Clf Loss: 2.340625524520874, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3613901138305664, Test_Clf_Loss: 2.3613901138305664, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 36, Total Loss: 2.342024087905884, Clf Loss: 2.342024087905884, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.362685203552246, Test_Clf_Loss: 2.362685203552246, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 37, Total Loss: 2.341442823410034, Clf Loss: 2.341442823410034, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3601925373077393, Test_Clf_Loss: 2.3601925373077393, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 38, Total Loss: 2.342571258544922, Clf Loss: 2.342571258544922, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.363629102706909, Test_Clf_Loss: 2.363629102706909, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 39, Total Loss: 2.338676929473877, Clf Loss: 2.338676929473877, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.365044355392456, Test_Clf_Loss: 2.365044355392456, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 40, Total Loss: 2.339325428009033, Clf Loss: 2.339325428009033, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.360621452331543, Test_Clf_Loss: 2.360621452331543, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 41, Total Loss: 2.340449333190918, Clf Loss: 2.340449333190918, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3638744354248047, Test_Clf_Loss: 2.3638744354248047, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 42, Total Loss: 2.3398168087005615, Clf Loss: 2.3398168087005615, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361402988433838, Test_Clf_Loss: 2.361402988433838, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 43, Total Loss: 2.3392746448516846, Clf Loss: 2.3392746448516846, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3596956729888916, Test_Clf_Loss: 2.3596956729888916, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 44, Total Loss: 2.340578317642212, Clf Loss: 2.340578317642212, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.364102363586426, Test_Clf_Loss: 2.364102363586426, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Total Loss: 2.340125322341919, Clf Loss: 2.340125322341919, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3606395721435547, Test_Clf_Loss: 2.3606395721435547, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 46, Total Loss: 2.338162660598755, Clf Loss: 2.338162660598755, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3625569343566895, Test_Clf_Loss: 2.3625569343566895, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 47, Total Loss: 2.338914155960083, Clf Loss: 2.338914155960083, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3628463745117188, Test_Clf_Loss: 2.3628463745117188, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 48, Total Loss: 2.342775583267212, Clf Loss: 2.342775583267212, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3597049713134766, Test_Clf_Loss: 2.3597049713134766, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 49, Total Loss: 2.3393664360046387, Clf Loss: 2.3393664360046387, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3646602630615234, Test_Clf_Loss: 2.3646602630615234, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 50, Total Loss: 2.343942642211914, Clf Loss: 2.343942642211914, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3615899085998535, Test_Clf_Loss: 2.3615899085998535, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 51, Total Loss: 2.3422393798828125, Clf Loss: 2.3422393798828125, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.36470103263855, Test_Clf_Loss: 2.36470103263855, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 52, Total Loss: 2.342294692993164, Clf Loss: 2.342294692993164, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361837387084961, Test_Clf_Loss: 2.361837387084961, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 53, Total Loss: 2.339902877807617, Clf Loss: 2.339902877807617, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3616204261779785, Test_Clf_Loss: 2.3616204261779785, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 54, Total Loss: 2.3391544818878174, Clf Loss: 2.3391544818878174, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361046075820923, Test_Clf_Loss: 2.361046075820923, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 55, Total Loss: 2.340169668197632, Clf Loss: 2.340169668197632, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3631839752197266, Test_Clf_Loss: 2.3631839752197266, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 56, Total Loss: 2.3407084941864014, Clf Loss: 2.3407084941864014, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3609578609466553, Test_Clf_Loss: 2.3609578609466553, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 57, Total Loss: 2.33866810798645, Clf Loss: 2.33866810798645, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3618922233581543, Test_Clf_Loss: 2.3618922233581543, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 58, Total Loss: 2.3411853313446045, Clf Loss: 2.3411853313446045, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.359246253967285, Test_Clf_Loss: 2.359246253967285, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 59, Total Loss: 2.3394691944122314, Clf Loss: 2.3394691944122314, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.363020896911621, Test_Clf_Loss: 2.363020896911621, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 60, Total Loss: 2.3391969203948975, Clf Loss: 2.3391969203948975, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361356258392334, Test_Clf_Loss: 2.361356258392334, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 61, Total Loss: 2.3420515060424805, Clf Loss: 2.3420515060424805, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.36179518699646, Test_Clf_Loss: 2.36179518699646, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 62, Total Loss: 2.3393490314483643, Clf Loss: 2.3393490314483643, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.362508535385132, Test_Clf_Loss: 2.362508535385132, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 63, Total Loss: 2.3427987098693848, Clf Loss: 2.3427987098693848, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3609609603881836, Test_Clf_Loss: 2.3609609603881836, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 64, Total Loss: 2.339816093444824, Clf Loss: 2.339816093444824, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.360403537750244, Test_Clf_Loss: 2.360403537750244, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 65, Total Loss: 2.3378283977508545, Clf Loss: 2.3378283977508545, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.366943359375, Test_Clf_Loss: 2.366943359375, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 66, Total Loss: 2.340359926223755, Clf Loss: 2.340359926223755, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.36441969871521, Test_Clf_Loss: 2.36441969871521, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Total Loss: 2.3426196575164795, Clf Loss: 2.3426196575164795, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3616886138916016, Test_Clf_Loss: 2.3616886138916016, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 68, Total Loss: 2.341057062149048, Clf Loss: 2.341057062149048, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3608062267303467, Test_Clf_Loss: 2.3608062267303467, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 69, Total Loss: 2.340313673019409, Clf Loss: 2.340313673019409, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3615732192993164, Test_Clf_Loss: 2.3615732192993164, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 70, Total Loss: 2.339437961578369, Clf Loss: 2.339437961578369, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3608686923980713, Test_Clf_Loss: 2.3608686923980713, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 71, Total Loss: 2.341683864593506, Clf Loss: 2.341683864593506, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361096143722534, Test_Clf_Loss: 2.361096143722534, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 72, Total Loss: 2.341454267501831, Clf Loss: 2.341454267501831, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3615200519561768, Test_Clf_Loss: 2.3615200519561768, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 73, Total Loss: 2.3427658081054688, Clf Loss: 2.3427658081054688, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3617184162139893, Test_Clf_Loss: 2.3617184162139893, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 74, Total Loss: 2.3414008617401123, Clf Loss: 2.3414008617401123, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361304521560669, Test_Clf_Loss: 2.361304521560669, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 75, Total Loss: 2.343357801437378, Clf Loss: 2.343357801437378, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361424446105957, Test_Clf_Loss: 2.361424446105957, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 76, Total Loss: 2.339613914489746, Clf Loss: 2.339613914489746, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3645942211151123, Test_Clf_Loss: 2.3645942211151123, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 77, Total Loss: 2.341529130935669, Clf Loss: 2.341529130935669, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.360936164855957, Test_Clf_Loss: 2.360936164855957, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 78, Total Loss: 2.340968370437622, Clf Loss: 2.340968370437622, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3634870052337646, Test_Clf_Loss: 2.3634870052337646, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 79, Total Loss: 2.340757131576538, Clf Loss: 2.340757131576538, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3611702919006348, Test_Clf_Loss: 2.3611702919006348, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 80, Total Loss: 2.3422985076904297, Clf Loss: 2.3422985076904297, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.362211227416992, Test_Clf_Loss: 2.362211227416992, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 81, Total Loss: 2.3395776748657227, Clf Loss: 2.3395776748657227, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361469030380249, Test_Clf_Loss: 2.361469030380249, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 82, Total Loss: 2.3399455547332764, Clf Loss: 2.3399455547332764, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.363661289215088, Test_Clf_Loss: 2.363661289215088, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 83, Total Loss: 2.341965675354004, Clf Loss: 2.341965675354004, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3603827953338623, Test_Clf_Loss: 2.3603827953338623, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 84, Total Loss: 2.339083433151245, Clf Loss: 2.339083433151245, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3637168407440186, Test_Clf_Loss: 2.3637168407440186, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 85, Total Loss: 2.3373892307281494, Clf Loss: 2.3373892307281494, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3612992763519287, Test_Clf_Loss: 2.3612992763519287, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 86, Total Loss: 2.341045379638672, Clf Loss: 2.341045379638672, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3636698722839355, Test_Clf_Loss: 2.3636698722839355, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 87, Total Loss: 2.340505838394165, Clf Loss: 2.340505838394165, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3615453243255615, Test_Clf_Loss: 2.3615453243255615, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 88, Total Loss: 2.3402414321899414, Clf Loss: 2.3402414321899414, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.360975503921509, Test_Clf_Loss: 2.360975503921509, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, Total Loss: 2.3387343883514404, Clf Loss: 2.3387343883514404, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.362525224685669, Test_Clf_Loss: 2.362525224685669, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 90, Total Loss: 2.3394598960876465, Clf Loss: 2.3394598960876465, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.362114906311035, Test_Clf_Loss: 2.362114906311035, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 91, Total Loss: 2.3398244380950928, Clf Loss: 2.3398244380950928, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.360982656478882, Test_Clf_Loss: 2.360982656478882, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 92, Total Loss: 2.3407726287841797, Clf Loss: 2.3407726287841797, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361682891845703, Test_Clf_Loss: 2.361682891845703, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 93, Total Loss: 2.3406717777252197, Clf Loss: 2.3406717777252197, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3645224571228027, Test_Clf_Loss: 2.3645224571228027, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 94, Total Loss: 2.339008331298828, Clf Loss: 2.339008331298828, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3605740070343018, Test_Clf_Loss: 2.3605740070343018, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 95, Total Loss: 2.3403894901275635, Clf Loss: 2.3403894901275635, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361396074295044, Test_Clf_Loss: 2.361396074295044, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 96, Total Loss: 2.3400185108184814, Clf Loss: 2.3400185108184814, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3608899116516113, Test_Clf_Loss: 2.3608899116516113, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 97, Total Loss: 2.339893102645874, Clf Loss: 2.339893102645874, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3637046813964844, Test_Clf_Loss: 2.3637046813964844, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 98, Total Loss: 2.341439723968506, Clf Loss: 2.341439723968506, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.36090087890625, Test_Clf_Loss: 2.36090087890625, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 99, Total Loss: 2.339299440383911, Clf Loss: 2.339299440383911, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.362069845199585, Test_Clf_Loss: 2.362069845199585, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 100, Total Loss: 2.3407235145568848, Clf Loss: 2.3407235145568848, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3603596687316895, Test_Clf_Loss: 2.3603596687316895, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 101, Total Loss: 2.3431222438812256, Clf Loss: 2.3431222438812256, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3625876903533936, Test_Clf_Loss: 2.3625876903533936, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 102, Total Loss: 2.3435494899749756, Clf Loss: 2.3435494899749756, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3609466552734375, Test_Clf_Loss: 2.3609466552734375, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 103, Total Loss: 2.337904453277588, Clf Loss: 2.337904453277588, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.362852096557617, Test_Clf_Loss: 2.362852096557617, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 104, Total Loss: 2.340902090072632, Clf Loss: 2.340902090072632, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.36242413520813, Test_Clf_Loss: 2.36242413520813, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 105, Total Loss: 2.3401451110839844, Clf Loss: 2.3401451110839844, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3617136478424072, Test_Clf_Loss: 2.3617136478424072, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 106, Total Loss: 2.3381853103637695, Clf Loss: 2.3381853103637695, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361893892288208, Test_Clf_Loss: 2.361893892288208, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 107, Total Loss: 2.3390209674835205, Clf Loss: 2.3390209674835205, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3623886108398438, Test_Clf_Loss: 2.3623886108398438, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 108, Total Loss: 2.3393728733062744, Clf Loss: 2.3393728733062744, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.360673189163208, Test_Clf_Loss: 2.360673189163208, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 109, Total Loss: 2.339359998703003, Clf Loss: 2.339359998703003, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.360664129257202, Test_Clf_Loss: 2.360664129257202, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 110, Total Loss: 2.339939832687378, Clf Loss: 2.339939832687378, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3603463172912598, Test_Clf_Loss: 2.3603463172912598, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111, Total Loss: 2.3368542194366455, Clf Loss: 2.3368542194366455, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.362868309020996, Test_Clf_Loss: 2.362868309020996, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 112, Total Loss: 2.3391385078430176, Clf Loss: 2.3391385078430176, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3617844581604004, Test_Clf_Loss: 2.3617844581604004, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 113, Total Loss: 2.340726375579834, Clf Loss: 2.340726375579834, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3606503009796143, Test_Clf_Loss: 2.3606503009796143, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 114, Total Loss: 2.3392577171325684, Clf Loss: 2.3392577171325684, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3625588417053223, Test_Clf_Loss: 2.3625588417053223, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 115, Total Loss: 2.339475154876709, Clf Loss: 2.339475154876709, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361239194869995, Test_Clf_Loss: 2.361239194869995, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 116, Total Loss: 2.3394112586975098, Clf Loss: 2.3394112586975098, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.360306739807129, Test_Clf_Loss: 2.360306739807129, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 117, Total Loss: 2.3410394191741943, Clf Loss: 2.3410394191741943, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3619871139526367, Test_Clf_Loss: 2.3619871139526367, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 118, Total Loss: 2.339566469192505, Clf Loss: 2.339566469192505, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.360264301300049, Test_Clf_Loss: 2.360264301300049, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 119, Total Loss: 2.3401906490325928, Clf Loss: 2.3401906490325928, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3612208366394043, Test_Clf_Loss: 2.3612208366394043, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 120, Total Loss: 2.3395299911499023, Clf Loss: 2.3395299911499023, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3615188598632812, Test_Clf_Loss: 2.3615188598632812, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 121, Total Loss: 2.34179949760437, Clf Loss: 2.34179949760437, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.362834930419922, Test_Clf_Loss: 2.362834930419922, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 122, Total Loss: 2.3415746688842773, Clf Loss: 2.3415746688842773, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3615188598632812, Test_Clf_Loss: 2.3615188598632812, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 123, Total Loss: 2.339395523071289, Clf Loss: 2.339395523071289, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361325263977051, Test_Clf_Loss: 2.361325263977051, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 124, Total Loss: 2.3380327224731445, Clf Loss: 2.3380327224731445, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.359971284866333, Test_Clf_Loss: 2.359971284866333, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 125, Total Loss: 2.3391270637512207, Clf Loss: 2.3391270637512207, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361684799194336, Test_Clf_Loss: 2.361684799194336, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 126, Total Loss: 2.339198350906372, Clf Loss: 2.339198350906372, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3637442588806152, Test_Clf_Loss: 2.3637442588806152, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 127, Total Loss: 2.3404464721679688, Clf Loss: 2.3404464721679688, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.360135555267334, Test_Clf_Loss: 2.360135555267334, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 128, Total Loss: 2.341365098953247, Clf Loss: 2.341365098953247, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.36246395111084, Test_Clf_Loss: 2.36246395111084, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 129, Total Loss: 2.3411202430725098, Clf Loss: 2.3411202430725098, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361588954925537, Test_Clf_Loss: 2.361588954925537, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 130, Total Loss: 2.3402416706085205, Clf Loss: 2.3402416706085205, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361753463745117, Test_Clf_Loss: 2.361753463745117, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 131, Total Loss: 2.337587833404541, Clf Loss: 2.337587833404541, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.360318899154663, Test_Clf_Loss: 2.360318899154663, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 132, Total Loss: 2.340693473815918, Clf Loss: 2.340693473815918, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.360792636871338, Test_Clf_Loss: 2.360792636871338, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133, Total Loss: 2.3402702808380127, Clf Loss: 2.3402702808380127, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3620729446411133, Test_Clf_Loss: 2.3620729446411133, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 134, Total Loss: 2.33968448638916, Clf Loss: 2.33968448638916, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.360391855239868, Test_Clf_Loss: 2.360391855239868, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 135, Total Loss: 2.3395986557006836, Clf Loss: 2.3395986557006836, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3612961769104004, Test_Clf_Loss: 2.3612961769104004, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 136, Total Loss: 2.338731527328491, Clf Loss: 2.338731527328491, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3604321479797363, Test_Clf_Loss: 2.3604321479797363, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 137, Total Loss: 2.34092116355896, Clf Loss: 2.34092116355896, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3615880012512207, Test_Clf_Loss: 2.3615880012512207, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 138, Total Loss: 2.3388354778289795, Clf Loss: 2.3388354778289795, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.3622825145721436, Test_Clf_Loss: 2.3622825145721436, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n",
      "Epoch 139, Total Loss: 2.338125467300415, Clf Loss: 2.338125467300415, Filter Loss: 0.0, Seq Loss: 1.0, Accuracy Rate: 37.72%, Ones Portion: 0.0,             Test_Total_Loss: 2.361311674118042, Test_Clf_Loss: 2.361311674118042, Test_Filter_Loss: 0.0, TEST_Seq_Loss: 1.0, Test_Accuracy_Rate: 37.17%, Test_Ones_Portion: 0.0\n",
      "===MODEL WEIGHTS SAVED=== ./model/2019110502/model1\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2000\n",
    "DateID = '2019110502'\n",
    "\n",
    "saveP1 = './model/'+DateID+'/model1'\n",
    "saveP2 = './model/'+DateID+'/model2'\n",
    "train_loss_acc = []\n",
    "train_loss_filter = []\n",
    "train_loss_seq = []\n",
    "train_weighted_loss = []\n",
    "train_acc_rate = []\n",
    "train_ones_num = []\n",
    "\n",
    "test_loss_acc = []\n",
    "test_loss_filter = []\n",
    "test_loss_seq = []\n",
    "test_weighted_loss = []\n",
    "test_acc_rate = []\n",
    "test_ones_num = []\n",
    "\n",
    "# signature_dict = {'att':model1.att}\n",
    "\n",
    "gc.collect()\n",
    "best_clf = 0.0\n",
    "for epoch in range(EPOCHS):\n",
    "    for text, labels in train_ds:\n",
    "        train_step(text, labels)\n",
    "\n",
    "    for test_text, test_labels in valid_ds:\n",
    "        test_step(test_text, test_labels)\n",
    "\n",
    "    template = 'Epoch {}, Total Loss: {}, Clf Loss: {}, Filter Loss: {}, Seq Loss: {}, Accuracy Rate: {:5.2f}%, Ones Portion: {}, \\\n",
    "            Test_Total_Loss: {}, Test_Clf_Loss: {}, Test_Filter_Loss: {}, TEST_Seq_Loss: {}, Test_Accuracy_Rate: {:5.2f}%, Test_Ones_Portion: {}'\n",
    "    print(template.format(epoch+1,train_loss.result(),\n",
    "                          train_accloss.result(),train_filloss.result(),train_seqloss.result(),\n",
    "                        train_accuracy.result()*100,train_ones.result(),\n",
    "                        test_loss.result(),\n",
    "                        test_accloss.result(),test_filloss.result(),test_seqloss.result(),\n",
    "                        test_accuracy.result()*100,test_ones.result(),\n",
    "                        ))\n",
    "\n",
    "    train_loss_acc.append( train_accloss.result().numpy())\n",
    "    train_loss_filter.append( train_filloss.result().numpy())\n",
    "    train_loss_seq.append( train_seqloss.result().numpy())\n",
    "    train_weighted_loss.append( train_loss.result().numpy())\n",
    "    train_acc_rate.append( train_accuracy.result().numpy())\n",
    "    train_ones_num.append( train_ones.result().numpy())\n",
    "    \n",
    "    test_loss_acc.append( test_accloss.result().numpy())\n",
    "    test_loss_filter.append( test_filloss.result().numpy())\n",
    "    test_loss_seq.append( test_seqloss.result().numpy())\n",
    "    test_weighted_loss.append( test_loss.result().numpy())\n",
    "    test_acc_rate.append( test_accuracy.result().numpy())\n",
    "    test_ones_num.append( test_ones.result().numpy())\n",
    "    if best_clf<=test_accuracy.result()*100:\n",
    "        #tf.saved_model.save(model1,saveP1+'_all')\n",
    "        #model1.save(saveP1,save_format='h5')\n",
    "        #model2.save(saveP2,save_format='h5')\n",
    "        #tf.saved_model.save(model2,saveP2+'_all')\n",
    "        model1.save_weights(saveP1,save_format='tf')\n",
    "        model2.save_weights(saveP2,save_format='tf')\n",
    "        best_clf = test_accuracy.result()*100\n",
    "        print('===MODEL WEIGHTS SAVED===',saveP1)\n",
    "    # Reset the metrics for the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accloss.reset_states()\n",
    "    train_filloss.reset_states()\n",
    "    train_seqloss.reset_states()\n",
    "    train_ones.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    test_loss.reset_states()\n",
    "    test_accloss.reset_states()\n",
    "    test_filloss.reset_states()\n",
    "    test_seqloss.reset_states()\n",
    "    test_ones.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveR = './results/'+DateID+'/losses_metrics.xlsx'\n",
    "data = {'train total loss':train_weighted_loss, 'train acc loss':train_loss_acc,\n",
    "        'train filter loss':train_loss_filter,'train seq loss':train_loss_seq,\n",
    "        'train acc rate':train_acc_rate, 'train ones num':train_ones_num,\n",
    "        'test total loss':test_weighted_loss, 'test acc loss':test_loss_acc,\n",
    "        'test filter loss':test_loss_filter, 'test seq loss': test_loss_seq,\n",
    "        'test acc rate':test_acc_rate, 'test ones num':test_ones_num\n",
    "       }\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel(saveR)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(None, dtype=object)"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_weighted_loss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.3583207, dtype=float32)"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk = np.array(test_accloss.result())\n",
    "kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3583207"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accloss.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1125\u001b[0m                                        \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m                                        sigcls=Signature)\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2287\u001b[0m         return _signature_from_builtin(sigcls, obj,\n\u001b[0;32m-> 2288\u001b[0;31m                                        skip_bound_arg=skip_bound_arg)\n\u001b[0m\u001b[1;32m   2289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_builtin\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no signature found for builtin {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no signature found for builtin <tensorflow.python.keras.saving.saved_model.save_impl.LayerCall object at 0x7f052aadf350>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-523-1449814dd641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model1.save('./model/emb_layer') #tf.keras.models.load_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'./model/emb_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/emb_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    868\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msignatures\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     signatures = signature_serialization.find_function_to_export(\n\u001b[0;32m--> 870\u001b[0;31m         checkpoint_graph_view)\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m   \u001b[0msignatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature_serialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_signatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_serialization.py\u001b[0m in \u001b[0;36mfind_function_to_export\u001b[0;34m(saveable_view)\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;31m# If the user did not specify signatures, check the root object for a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;31m# that can be made into a signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEFAULT_SIGNATURE_ATTR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msignature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36mlist_functions\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobj_functions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access\n\u001b[0;32m--> 141\u001b[0;31m           self._serialization_cache)\n\u001b[0m\u001b[1;32m    142\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_list_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m   2420\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_list_functions_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     return (self._trackable_saved_model_saver\n\u001b[0;32m-> 2422\u001b[0;31m             .list_functions_for_serialization(serialization_cache))\n\u001b[0m\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/base_serialization.py\u001b[0m in \u001b[0;36mlist_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mConcreteFunction\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mfns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# The parent AutoTrackable class saves all user-defined tf.functions, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36mfunctions_to_serialize\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfunctions_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     return (self._get_serialized_attributes(\n\u001b[0;32m---> 79\u001b[0;31m         serialization_cache).functions_to_serialize)\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_serialized_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     object_dict, function_dict = self._get_serialized_attributes_internal(\n\u001b[0;32m---> 94\u001b[0;31m         serialization_cache)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mserialized_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_and_validate_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/model_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# cache (i.e. this is the root level object).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKERAS_CACHE_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m       \u001b[0mdefault_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_save_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Other than the default signature function, all other attributes match with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mdefault_save_signature\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[0moriginal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reset_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m   \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_model_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m   \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m   \u001b[0m_restore_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36m_wrapped_model\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    141\u001b[0m     with base_layer_utils.call_context().enter(\n\u001b[1;32m    142\u001b[0m         model, inputs=inputs, build_graph=False, training=False, saving=True):\n\u001b[0;32m--> 143\u001b[0;31m       \u001b[0moutputs_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-498-f3457470eec4>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#x = self.rnn1(x1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#x = self.bn1(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    218\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mhas_arg\u001b[0;34m(fn, name, accept_all)\u001b[0m\n\u001b[1;32m    302\u001b[0m       \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhether\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0maccepts\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mname\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m   \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m   \u001b[0marg_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maccept_all\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvarkw\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/util/tf_inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator_argspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_maybe_argspec_to_fullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_getfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m# else. So to be fully backwards compatible, we catch all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# possible exceptions here, and reraise a TypeError.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unsupported callable'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported callable"
     ]
    }
   ],
   "source": [
    "# model1.save('./model/emb_layer') #tf.keras.models.load_model\n",
    "tf.saved_model.save(model1,'./model/emb_layer')\n",
    "model3 = tf.keras.models.load_model('./model/emb_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CheckpointLoadStatus' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-524-07c6ede4bf0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/emb_layer_weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'CheckpointLoadStatus' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "model3 = model1.load_weights('./model/emb_layer_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.emb.set_weights(model3.emb.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"base_model_1_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_58 (Masking)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "glove_emb (Embedding)        multiple                  2138112   \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You tried to call `count_params` on common_extract, but the layer isn't built. You can build it manually via: `common_extract.build(batch_input_shape)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-526-cdf54a019e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/emb_layer_weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1263\u001b[0m                               \u001b[0mline_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m                               \u001b[0mpositions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m                               print_fn=print_fn)\n\u001b[0m\u001b[1;32m   1266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_validate_graph_inputs_and_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/layer_utils.py\u001b[0m in \u001b[0;36mprint_summary\u001b[0;34m(model, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m    224\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequential_like\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m       \u001b[0mprint_layer_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m       \u001b[0mprint_layer_summary_with_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/layer_utils.py\u001b[0m in \u001b[0;36mprint_layer_summary\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mcls_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ('\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m')'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0mprint_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mcount_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1627\u001b[0m                          \u001b[0;34m', but the layer isn\\'t built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m                          \u001b[0;34m'You can build it manually via: `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m                          '.build(batch_input_shape)`.')\n\u001b[0m\u001b[1;32m   1630\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You tried to call `count_params` on common_extract, but the layer isn't built. You can build it manually via: `common_extract.build(batch_input_shape)`."
     ]
    }
   ],
   "source": [
    "model3 = model1\n",
    "model3.load_weights('./model/emb_layer_weight')\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 在某些參數的情況下0 1是train不起來的但是weight可以\n",
    "    * alpha = 0.0, beta=0.6\n",
    "    * init_w = tensorflow.keras.initializers.Constant(value=0.9), init_b = tensorflow.keras.initializers.Constant(value=0.7)\n",
    "* 0/1 with emb比較容易overfit。如果是weight的比較沒那麼嚴重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 不用sigmoid或是hard_sigmoid。改良relu + linear，並拆成兩個model，把round前面多加上clip\n",
    "    * sigmoid中間的變化太快(一瞬間就會掉到0或是1)，改成relu在>0~無限大(linear為了還在0~1)再去clip再round，可以看到每個epoch的變化\n",
    "* 1st phase的beta一定要>=0.6否則不會動，ones#都會是0\n",
    "    * beta=1 (放0 1進去): weight init設成1也沒用，但把bias設成1就會一開始都是ones#=1了。weight=1 bias=0.2都匯市0，bias=0.3會是0.87。0.6/0.3都是0。0.8/0.3差不多是0.5(但是train很慢acc進步很慢就是了)。0.5/0.5是從0.01開始往上升 (0 1放進去會比較難train是因為它的變化量太大，一下就是有或沒有，所以clf可能學不好，但如果是weight每次gradient進步的都是一小點就會比較容易上升)\n",
    "    * beta=0.6 (放0 1進去): 0.8/0.5都是0。0.9/0.8 從0.9一直到0。0.9/0.6差不多是從0.5但又有時候到0.7都是0.0(很難train，Nadam換個opt有時候沒用。EX變成adam 0.9/0.8才有0.96開始但如果0.9/0.75變成0開始。Rmsprop 0.9/0.8又是從0.95開始往下)。但如果都改成傳入weight就都沒問題。ones一開始大概0.5 weight平均，也不會卡住\n",
    "* 建議: 先訓練embedding weight matrix，但是要看goal是要怎樣的matrix\n",
    "* 其實他不管幾%都會train得很好，除非固定embedding，或是用更弱的clf\n",
    "* 若設定alpha，就像是regularizer term (penalty)，設越大drop越多\n",
    "* 一開始先很多ones，再越來越少個"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 同一個opt若加入transform就會train不起來\n",
    "* 兩個不同的opt加入transform也會train不起來 (persistent、non-persis都不行)，且與BN無關"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
