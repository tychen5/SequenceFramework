{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.text import *\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import pickle\n",
    "import gc\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_statistics(all_length):\n",
    "    '''\n",
    "    input: length list of elements e.g.[1,1,1,3,5,9,4,2,1,3,54,78,5...]\n",
    "    output1: mean、std、mode、min、q1、median(q2)、q3、max、iqr、outlier、far out\n",
    "    output2: statistics graph、10%~90% form\n",
    "    '''\n",
    "    stat_dict = {}\n",
    "    stat_dict['mean'] = np.mean(all_length)\n",
    "    stat_dict['std'] = np.std(all_length)\n",
    "    stat_dict['mode'] = np.argmax(np.bincount(all_length))\n",
    "    stat_dict['min'] = np.min(all_length)\n",
    "    stat_dict['q1'] = np.quantile(all_length,0.25)\n",
    "    stat_dict['median'] = np.quantile(all_length,0.5)\n",
    "    stat_dict['q3'] = np.quantile(all_length,0.75)\n",
    "    stat_dict['max'] = np.max(all_length)\n",
    "    stat_dict['iqr'] = stat_dict['q3'] - stat_dict['q1']\n",
    "    stat_dict['outlier'] = stat_dict['q3'] + 1.5*stat_dict['iqr']\n",
    "    stat_dict['far_out'] = stat_dict['q3'] + 3*stat_dict['iqr']\n",
    "    for i in [10,20,30,40,50,60,70,80,90,100]:\n",
    "        stat_dict[str(i)+'%'] = np.percentile(all_length,i)\n",
    "    return pd.DataFrame.from_dict(stat_dict,orient='index',columns=['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 2000 #Top most frequent words to consider. Any less frequent word will appear as oov_char value in the sequence data.\n",
    "max_length = 358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_words#: 30979\n",
      "8248 train sequences\n",
      "2063 test sequences\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "print('all_words#:',len(word_index))\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,maxlen=max_length,\n",
    "                                                         test_split=0.2)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>110.996363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>76.006433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mode</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>q1</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>median</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>q3</td>\n",
       "      <td>148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>357.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iqr</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>outlier</td>\n",
       "      <td>284.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>far_out</td>\n",
       "      <td>421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10%</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20%</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30%</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40%</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60%</td>\n",
       "      <td>102.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70%</td>\n",
       "      <td>123.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80%</td>\n",
       "      <td>172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90%</td>\n",
       "      <td>226.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100%</td>\n",
       "      <td>357.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             length\n",
       "mean     110.996363\n",
       "std       76.006433\n",
       "mode      17.000000\n",
       "min       13.000000\n",
       "q1        57.000000\n",
       "median    90.000000\n",
       "q3       148.000000\n",
       "max      357.000000\n",
       "iqr       91.000000\n",
       "outlier  284.500000\n",
       "far_out  421.000000\n",
       "10%       33.000000\n",
       "20%       51.000000\n",
       "30%       64.000000\n",
       "40%       77.000000\n",
       "50%       90.000000\n",
       "60%      102.000000\n",
       "70%      123.900000\n",
       "80%      172.000000\n",
       "90%      226.000000\n",
       "100%     357.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len = [len(x) for x in x_train]\n",
    "basic_statistics(train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8248, 358) (2063, 358)\n"
     ]
    }
   ],
   "source": [
    "trainX = tf.keras.preprocessing.sequence.pad_sequences(x_train,maxlen=max_length,padding='post',value=0)\n",
    "testX = tf.keras.preprocessing.sequence.pad_sequences(x_test,maxlen=max_length,padding='post',value=0)\n",
    "print(trainX.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "do = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph execution\n",
    "### Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_id = Input(shape=(max_length,), dtype='int32', name='int_ids') # 輸入的api funvtion name ID\n",
    "int_ids = Masking(mask_value=0)(int_id)\n",
    "sent_emb = Embedding(max_words, hidden_dim,input_length=max_length\n",
    "                    ,trainable=True,name='glove_emb')(int_ids) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = GRU(int(hidden_dim/2),return_sequences=True,return_state=False,name='common_extract'\n",
    "                      ,trainable=True)(sent_emb)\n",
    "rnn = BatchNormalization(name='bn')(rnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = TimeDistributed(Dense(1,activation='sigmoid',\n",
    "                             name='filter_out'),name='TD2')(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = Multiply()([fil,sent_emb])\n",
    "clf = LSTM(int(hidden_dim/2),dropout=do,recurrent_dropout=do,name='lstm')(mul)\n",
    "clf = BatchNormalization(name='bn3')(clf)\n",
    "clf = Dense(max(y_train)+1,activation='softmax',name='clf')(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "int_ids (InputLayer)            [(None, 358)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 358)          0           int_ids[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "glove_emb (Embedding)           (None, 358, 128)     1280000     masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "common_extract (GRU)            (None, 358, 64)      37248       glove_emb[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 358, 64)      256         common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "TD2 (TimeDistributed)           (None, 358, 1)       65          bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 358, 128)     0           TD2[0][0]                        \n",
      "                                                                 glove_emb[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           49408       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 64)           256         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "clf (Dense)                     (None, 46)           2990        bn3[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 1,370,223\n",
      "Trainable params: 1,369,967\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=int_id, outputs = clf)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-189e30c4af05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     return K.sum(layer.output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# kk = tf.keras.backend.ea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TD2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       self._track_trackable(\n\u001b[1;32m    294\u001b[0m           self.optimizer, name='optimizer', overwrite=True)\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weight_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \"\"\"\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_bool_casting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m       \u001b[0;31m# Default: V1-style Graph execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"using a `tf.Tensor` as a Python `bool`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_in_graph_mode\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    521\u001b[0m     raise errors.OperatorNotAllowedInGraphError(\n\u001b[1;32m    522\u001b[0m         \u001b[0;34m\"{} is not allowed in Graph execution. Use Eager execution or decorate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \" this function with @tf.function.\".format(task))\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
     ]
    }
   ],
   "source": [
    "# loss\n",
    "import keras.backend as K\n",
    "def custom_objective(layer):\n",
    "    return K.sum(layer.output)\n",
    "#     return K.sum(layer.output)\n",
    "# kk = tf.keras.backend.ea\n",
    "model.compile(loss=custom_objective(model.get_layer(name='TD2')),optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "do = 0\n",
    "class base_model(Model):\n",
    "    def __init__(self):\n",
    "        super(base_model, self).__init__()\n",
    "        self.mask = Masking(mask_value=0)\n",
    "        self.emb = Embedding(max_words, hidden_dim,input_length=max_length\n",
    "                    ,trainable=True,name='glove_emb')\n",
    "        self.rnn1 = GRU(int(hidden_dim/2),return_sequences=True,return_state=False,name='common_extract'\n",
    "                      ,trainable=True)\n",
    "        self.bn1 = BatchNormalization(name='bn1')\n",
    "        self.fil = TimeDistributed(Dense(1,activation='sigmoid',\n",
    "                             name='filter_out'),name='TD2')\n",
    "        self.mul = Multiply()\n",
    "        self.rnn2 = Bidirectional(GRU(int(hidden_dim/2),dropout=do,recurrent_dropout=do,name='lstm'))\n",
    "        self.rnn3 = LSTM(int(hidden_dim/2))\n",
    "        self.bn2 = BatchNormalization(name='bn2')\n",
    "        self.out = Dense(max(y_train)+1,activation='softmax',name='clf')\n",
    "    def transform(self,x):\n",
    "        return tf.math.round(x)        \n",
    "    def call(self,x):\n",
    "        x = self.mask(x)\n",
    "        x1 = self.emb(x)\n",
    "        x = self.rnn1(x1)\n",
    "        #x = self.bn1(x)\n",
    "        y = self.fil(x)\n",
    "        y1 = self.transform(y)\n",
    "        x2 = self.mul([y1,x1])\n",
    "        x = self.rnn2(x2) #x\n",
    "        x = self.bn2(x)\n",
    "        y2 = self.out(x)\n",
    "        return y,y2\n",
    "        #return y,y1,y2,x2\n",
    "        \n",
    "model = base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=264354, shape=(1, 358, 1), dtype=float32, numpy=\n",
       "array([[[0.50008374],\n",
       "        [0.50039524],\n",
       "        [0.50061977],\n",
       "        [0.50072163],\n",
       "        [0.5007394 ],\n",
       "        [0.50071514],\n",
       "        [0.5006769 ],\n",
       "        [0.50063914],\n",
       "        [0.50060797],\n",
       "        [0.5005844 ],\n",
       "        [0.50056773],\n",
       "        [0.50055635],\n",
       "        [0.5005488 ],\n",
       "        [0.5005439 ],\n",
       "        [0.50054073],\n",
       "        [0.50053877],\n",
       "        [0.5005376 ],\n",
       "        [0.5005368 ],\n",
       "        [0.5005363 ],\n",
       "        [0.500536  ],\n",
       "        [0.50053585],\n",
       "        [0.5005358 ],\n",
       "        [0.5005357 ],\n",
       "        [0.50053567],\n",
       "        [0.50053567],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ],\n",
       "        [0.5005356 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "x = tf.random.uniform((1, max_length))\n",
    "out1,out2,out3,out4 = model(x)\n",
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=259061, shape=(1, 358, 128), dtype=float32, numpy=\n",
       "array([[[ 0.        ,  0.        ,  0.        , ..., -0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.02912379,  0.03589214,  0.0456765 , ..., -0.01467606,\n",
       "          0.01763055,  0.0358587 ],\n",
       "        [ 0.02912379,  0.03589214,  0.0456765 , ..., -0.01467606,\n",
       "          0.01763055,  0.0358587 ],\n",
       "        ...,\n",
       "        [ 0.02912379,  0.03589214,  0.0456765 , ..., -0.01467606,\n",
       "          0.01763055,  0.0358587 ],\n",
       "        [ 0.02912379,  0.03589214,  0.0456765 , ..., -0.01467606,\n",
       "          0.01763055,  0.0358587 ],\n",
       "        [ 0.02912379,  0.03589214,  0.0456765 , ..., -0.01467606,\n",
       "          0.01763055,  0.0358587 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 #,reshuffle_each_iteration=True\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((trainX,y_train)).shuffle(trainX.shape[0]).batch(batch_size)\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((testX,y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_object1(predictions):\n",
    "    mask = tf.math.logical_not(tf.math.equal(predictions, 0))\n",
    "    loss_ = tf.reduce_mean(predictions)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "loss_object2 = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "optimizer1 = tf.keras.optimizers.Nadam()\n",
    "optimizer2 = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "@tf.function\n",
    "def train_step(x,yc):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        pred_imp , pred_cat = model(x)\n",
    "#         pred_cat = model(x)\n",
    "#         loss = alpha*loss_object1(pred_imp) + loss_object2(yc,pred_cat)\n",
    "        loss1 = alpha*loss_object1(pred_imp)\n",
    "        loss2 = loss_object2(yc,pred_cat)\n",
    "        loss = loss_object2(yc,pred_cat)\n",
    "#     gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    grad1 = tape.gradient(loss1, model.trainable_variables)\n",
    "    grad2 = tape.gradient(loss2, model.trainable_variables)\n",
    "#     optimizer1.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    optimizer1.apply_gradients(zip(grad1, model.trainable_variables))\n",
    "    optimizer2.apply_gradients(zip(grad2, model.trainable_variables))\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         pred_imp , pred_cat = model(x)\n",
    "#         loss2 = loss_object2(yc,pred_cat)\n",
    "#         loss = alpha*loss_object1(pred_imp) + loss_object2(yc,pred_cat)\n",
    "#     grad2 = tape.gradient(loss2, model.trainable_variables)\n",
    "#     optimizer2.apply_gradients(zip(grad2, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(yc, pred_cat)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(x,yc):\n",
    "    pred_imp, pred_cat = model(x)\n",
    "#     pred_cat = model(x)\n",
    "    t_loss = alpha*loss_object1(pred_imp) + loss_object2(yc,pred_cat) \n",
    "#     t_loss = loss_object2(yc,pred_cat)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(yc, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['base_model_29/bidirectional_29/forward_lstm/kernel:0', 'base_model_29/bidirectional_29/forward_lstm/recurrent_kernel:0', 'base_model_29/bidirectional_29/forward_lstm/bias:0', 'base_model_29/bidirectional_29/backward_lstm/kernel:0', 'base_model_29/bidirectional_29/backward_lstm/recurrent_kernel:0', 'base_model_29/bidirectional_29/backward_lstm/bias:0', 'base_model_29/bn2/gamma:0', 'base_model_29/bn2/beta:0', 'base_model_29/clf/kernel:0', 'base_model_29/clf/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['base_model_29/common_extract/kernel:0', 'base_model_29/common_extract/recurrent_kernel:0', 'base_model_29/common_extract/bias:0', 'base_model_29/TD2/kernel:0', 'base_model_29/TD2/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['base_model_29/bidirectional_29/forward_lstm/kernel:0', 'base_model_29/bidirectional_29/forward_lstm/recurrent_kernel:0', 'base_model_29/bidirectional_29/forward_lstm/bias:0', 'base_model_29/bidirectional_29/backward_lstm/kernel:0', 'base_model_29/bidirectional_29/backward_lstm/recurrent_kernel:0', 'base_model_29/bidirectional_29/backward_lstm/bias:0', 'base_model_29/bn2/gamma:0', 'base_model_29/bn2/beta:0', 'base_model_29/clf/kernel:0', 'base_model_29/clf/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['base_model_29/common_extract/kernel:0', 'base_model_29/common_extract/recurrent_kernel:0', 'base_model_29/common_extract/bias:0', 'base_model_29/TD2/kernel:0', 'base_model_29/TD2/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['base_model_29/bidirectional_29/forward_lstm/kernel:0', 'base_model_29/bidirectional_29/forward_lstm/recurrent_kernel:0', 'base_model_29/bidirectional_29/forward_lstm/bias:0', 'base_model_29/bidirectional_29/backward_lstm/kernel:0', 'base_model_29/bidirectional_29/backward_lstm/recurrent_kernel:0', 'base_model_29/bidirectional_29/backward_lstm/bias:0', 'base_model_29/bn2/gamma:0', 'base_model_29/bn2/beta:0', 'base_model_29/clf/kernel:0', 'base_model_29/clf/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['base_model_29/common_extract/kernel:0', 'base_model_29/common_extract/recurrent_kernel:0', 'base_model_29/common_extract/bias:0', 'base_model_29/TD2/kernel:0', 'base_model_29/TD2/bias:0'] when minimizing the loss.\n",
      "Epoch 1, Loss: 2.556689739227295, Accuracy: 36.821044921875, Test Loss: 2.3505802154541016, Test Accuracy: 38.730003356933594\n",
      "Epoch 2, Loss: 2.3517208099365234, Accuracy: 37.3908805847168, Test Loss: 2.3402976989746094, Test Accuracy: 38.730003356933594\n",
      "Epoch 3, Loss: 2.343385696411133, Accuracy: 37.3908805847168, Test Loss: 2.360708713531494, Test Accuracy: 38.730003356933594\n",
      "Epoch 4, Loss: 2.3441457748413086, Accuracy: 37.3908805847168, Test Loss: 2.3469791412353516, Test Accuracy: 38.730003356933594\n",
      "Epoch 5, Loss: 2.3457727432250977, Accuracy: 37.3908805847168, Test Loss: 2.3407504558563232, Test Accuracy: 38.730003356933594\n",
      "Epoch 6, Loss: 2.3440752029418945, Accuracy: 37.3908805847168, Test Loss: 2.348440170288086, Test Accuracy: 38.730003356933594\n",
      "Epoch 7, Loss: 2.34462308883667, Accuracy: 37.3908805847168, Test Loss: 2.3414554595947266, Test Accuracy: 38.730003356933594\n",
      "Epoch 8, Loss: 2.3419158458709717, Accuracy: 37.3908805847168, Test Loss: 2.344940662384033, Test Accuracy: 38.730003356933594\n",
      "Epoch 9, Loss: 2.3463873863220215, Accuracy: 37.3908805847168, Test Loss: 2.353271484375, Test Accuracy: 38.730003356933594\n",
      "Epoch 10, Loss: 2.3447697162628174, Accuracy: 37.3908805847168, Test Loss: 2.3490190505981445, Test Accuracy: 38.730003356933594\n",
      "Epoch 11, Loss: 2.3426437377929688, Accuracy: 37.3908805847168, Test Loss: 2.347209930419922, Test Accuracy: 38.730003356933594\n",
      "Epoch 12, Loss: 2.346055507659912, Accuracy: 37.3908805847168, Test Loss: 2.3515071868896484, Test Accuracy: 38.730003356933594\n",
      "Epoch 13, Loss: 2.3419957160949707, Accuracy: 37.3908805847168, Test Loss: 2.346466064453125, Test Accuracy: 38.730003356933594\n",
      "Epoch 14, Loss: 2.3406617641448975, Accuracy: 37.3908805847168, Test Loss: 2.3432226181030273, Test Accuracy: 38.730003356933594\n",
      "Epoch 15, Loss: 2.342071771621704, Accuracy: 37.3908805847168, Test Loss: 2.343623161315918, Test Accuracy: 38.730003356933594\n",
      "Epoch 16, Loss: 2.3443081378936768, Accuracy: 37.3908805847168, Test Loss: 2.3442273139953613, Test Accuracy: 38.730003356933594\n",
      "Epoch 17, Loss: 2.3414387702941895, Accuracy: 37.3908805847168, Test Loss: 2.344869613647461, Test Accuracy: 38.730003356933594\n",
      "Epoch 18, Loss: 2.3416056632995605, Accuracy: 37.3908805847168, Test Loss: 2.340420722961426, Test Accuracy: 38.730003356933594\n",
      "Epoch 19, Loss: 2.344032049179077, Accuracy: 37.3908805847168, Test Loss: 2.3471295833587646, Test Accuracy: 38.730003356933594\n",
      "Epoch 20, Loss: 2.3377318382263184, Accuracy: 37.3908805847168, Test Loss: 2.344831943511963, Test Accuracy: 38.730003356933594\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "gc.collect()\n",
    "for epoch in range(EPOCHS):\n",
    "    for text, labels in train_ds:\n",
    "        train_step(text, labels)\n",
    "\n",
    "    for test_text, test_labels in valid_ds:\n",
    "        test_step(test_text, test_labels)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch+1,\n",
    "                        train_loss.result(),\n",
    "                        train_accuracy.result()*100,\n",
    "                        test_loss.result(),\n",
    "                        test_accuracy.result()*100))\n",
    "\n",
    "    # Reset the metrics for the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 同一個opt若加入transform就會train不起來\n",
    "* 兩個不同的opt加入transform也會train不起來 (persistent、non-persis都不行)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
